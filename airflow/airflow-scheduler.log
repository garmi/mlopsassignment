2025-02-16 08:56:22,259 INFO - Starting the scheduler
2025-02-16 08:56:22,259 INFO - Processing each file at most -1 times
2025-02-16 08:56:22,261 INFO - Loaded executor: SequentialExecutor
2025-02-16 08:56:22,268 INFO - Launched DagFileProcessorManager with pid: 10269
2025-02-16 08:56:22,269 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 08:56:22,275 INFO - Configured default timezone Timezone('UTC')
2025-02-16 09:01:22,501 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 09:06:22,589 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 09:11:22,816 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 09:16:23,320 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 09:21:23,535 INFO - Resetting orphaned tasks for active dag runs
2025-02-16 09:22:11,199 INFO - Exiting gracefully upon receiving signal 15
2025-02-16 09:22:11,411 INFO - Sending Signals.SIGTERM to group 10269. PIDs of all processes in the group: []
2025-02-16 09:22:11,412 INFO - Sending the signal Signals.SIGTERM to group 10269
2025-02-16 09:22:11,412 INFO - Sending the signal Signals.SIGTERM to process 10269 as process group is missing.
2025-02-16 09:22:11,414 INFO - Sending Signals.SIGTERM to group 10269. PIDs of all processes in the group: []
2025-02-16 09:22:11,414 INFO - Sending the signal Signals.SIGTERM to group 10269
2025-02-16 09:22:11,414 INFO - Sending the signal Signals.SIGTERM to process 10269 as process group is missing.
2025-02-16 09:22:11,414 INFO - Exited execute loop
2025-02-22 09:46:43,717 INFO - Starting the scheduler
2025-02-22 09:46:43,718 INFO - Processing each file at most -1 times
2025-02-22 09:46:43,720 INFO - Loaded executor: SequentialExecutor
2025-02-22 09:46:43,726 INFO - Launched DagFileProcessorManager with pid: 12437
2025-02-22 09:46:43,727 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 09:46:43,732 INFO - Configured default timezone Timezone('UTC')
2025-02-22 09:46:43,736 INFO - Marked 4 SchedulerJob instances as failed
2025-02-22 09:51:43,864 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 09:56:44,065 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:01:44,256 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:06:44,414 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:11:44,882 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:16:45,055 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:21:45,230 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:26:45,405 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:31:45,879 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:36:46,002 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:41:46,252 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:46:46,498 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:51:46,532 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 10:56:47,006 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:00:14,058 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-21T00:00:00+00:00, run_after=2024-02-22T00:00:00+00:00
2025-02-22 11:00:14,451 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:14,451 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:00:14,452 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:00:14,452 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:14,457 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:14,458 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:14,459 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='manual__2025-02-22T10:57:08+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:14,459 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:14,549 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:17,231 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:19,825 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:19,825 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=manual__2025-02-22T10:57:08+00:00 exited with status success for try_number 1
2025-02-22 11:00:19,833 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=manual__2025-02-22T10:57:08+00:00, map_index=-1, run_start_date=2025-02-22 11:00:18.757737+00:00, run_end_date=2025-02-22 11:00:19.240777+00:00, run_duration=0.48304, state=success, executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:14.453345+00:00, queued_by_job_id=7, pid=48693
2025-02-22 11:00:19,834 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:16.090310+00:00, run_end_date=2025-02-22 11:00:16.598061+00:00, run_duration=0.507751, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:14.453345+00:00, queued_by_job_id=7, pid=48674
2025-02-22 11:00:20,161 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-22T00:00:00+00:00, run_after=2024-02-23T00:00:00+00:00
2025-02-22 11:00:20,557 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:20,558 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:00:20,558 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:00:20,558 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:00:20,558 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:20,563 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:20,564 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:20,564 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:00:20,564 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:20,565 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='manual__2025-02-22T10:57:08+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:00:20,565 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:20,633 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:23,558 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:25,897 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:28,658 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:28,659 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:28,659 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=manual__2025-02-22T10:57:08+00:00 exited with status success for try_number 1
2025-02-22 11:00:28,671 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=manual__2025-02-22T10:57:08+00:00, map_index=-1, run_start_date=2025-02-22 11:00:27.432446+00:00, run_end_date=2025-02-22 11:00:27.991026+00:00, run_duration=0.55858, state=success, executor_state=success, try_number=1, max_tries=1, job_id=12, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:00:20.559760+00:00, queued_by_job_id=7, pid=48753
2025-02-22 11:00:28,671 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:25.197907+00:00, run_end_date=2025-02-22 11:00:25.514488+00:00, run_duration=0.316581, state=success, executor_state=success, try_number=1, max_tries=1, job_id=11, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:00:20.559760+00:00, queued_by_job_id=7, pid=48735
2025-02-22 11:00:28,671 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:22.297316+00:00, run_end_date=2025-02-22 11:00:22.933256+00:00, run_duration=0.63594, state=success, executor_state=success, try_number=1, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:20.559760+00:00, queued_by_job_id=7, pid=48715
2025-02-22 11:00:29,032 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-23T00:00:00+00:00, run_after=2024-02-24T00:00:00+00:00
2025-02-22 11:00:29,515 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:29,515 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:00:29,515 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:00:29,516 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:00:29,516 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:00:29,516 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:29,520 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:29,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:29,521 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:00:29,521 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:29,522 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:00:29,522 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:29,522 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='manual__2025-02-22T10:57:08+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:00:29,522 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:29,625 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:32,294 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:35,247 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:38,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:40,697 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:40,697 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:40,697 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:40,697 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=manual__2025-02-22T10:57:08+00:00 exited with status success for try_number 1
2025-02-22 11:00:40,705 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=manual__2025-02-22T10:57:08+00:00, map_index=-1, run_start_date=2025-02-22 11:00:39.666330+00:00, run_end_date=2025-02-22 11:00:40.201710+00:00, run_duration=0.53538, state=success, executor_state=success, try_number=1, max_tries=1, job_id=16, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:00:29.517655+00:00, queued_by_job_id=7, pid=48849
2025-02-22 11:00:40,705 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:36.772453+00:00, run_end_date=2025-02-22 11:00:37.297707+00:00, run_duration=0.525254, state=success, executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:00:29.517655+00:00, queued_by_job_id=7, pid=48829
2025-02-22 11:00:40,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:33.902365+00:00, run_end_date=2025-02-22 11:00:34.531175+00:00, run_duration=0.62881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:00:29.517655+00:00, queued_by_job_id=7, pid=48796
2025-02-22 11:00:40,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:31.176695+00:00, run_end_date=2025-02-22 11:00:31.675503+00:00, run_duration=0.498808, state=success, executor_state=success, try_number=1, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:29.517655+00:00, queued_by_job_id=7, pid=48775
2025-02-22 11:00:41,066 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-24T00:00:00+00:00, run_after=2024-02-25T00:00:00+00:00
2025-02-22 11:00:41,471 INFO - 6 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:41,472 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:00:41,472 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:00:41,472 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:00:41,473 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:00:41,473 INFO - DAG lead_scoring_data_pipeline has 4/16 running and queued tasks
2025-02-22 11:00:41,473 INFO - DAG lead_scoring_data_pipeline has 5/16 running and queued tasks
2025-02-22 11:00:41,473 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T10:57:08+00:00 [scheduled]>
2025-02-22 11:00:41,477 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:41,478 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:41,478 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='manual__2025-02-22T11:00:34+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:00:41,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:41,479 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:00:41,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:41,480 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:00:41,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:41,480 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:00:41,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:41,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='manual__2025-02-22T10:57:08+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:00:41,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:42,084 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:44,731 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:47,586 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:50,538 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:53,430 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:56,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T10:57:08+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:00:59,079 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,080 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=manual__2025-02-22T11:00:34+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,080 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,080 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,080 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,080 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=manual__2025-02-22T10:57:08+00:00 exited with status success for try_number 1
2025-02-22 11:00:59,088 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=manual__2025-02-22T10:57:08+00:00, map_index=-1, run_start_date=2025-02-22 11:00:57.875591+00:00, run_end_date=2025-02-22 11:00:58.421557+00:00, run_duration=0.545966, state=success, executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48992
2025-02-22 11:00:59,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:54.925487+00:00, run_end_date=2025-02-22 11:00:55.494946+00:00, run_duration=0.569459, state=success, executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48973
2025-02-22 11:00:59,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:52.121438+00:00, run_end_date=2025-02-22 11:00:52.781802+00:00, run_duration=0.660364, state=success, executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48954
2025-02-22 11:00:59,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:49.353924+00:00, run_end_date=2025-02-22 11:00:49.875091+00:00, run_duration=0.521167, state=success, executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48934
2025-02-22 11:00:59,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=manual__2025-02-22T11:00:34+00:00, map_index=-1, run_start_date=2025-02-22 11:00:46.363550+00:00, run_end_date=2025-02-22 11:00:46.860158+00:00, run_duration=0.496608, state=success, executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48899
2025-02-22 11:00:59,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:00:43.620518+00:00, run_end_date=2025-02-22 11:00:44.143662+00:00, run_duration=0.523144, state=success, executor_state=success, try_number=1, max_tries=1, job_id=17, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:00:41.474776+00:00, queued_by_job_id=7, pid=48871
2025-02-22 11:00:59,498 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-25T00:00:00+00:00, run_after=2024-02-26T00:00:00+00:00
2025-02-22 11:00:59,980 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-20 00:00:00+00:00: scheduled__2024-02-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:00:59,981 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-20 00:00:00+00:00, run_id=scheduled__2024-02-20T00:00:00+00:00, run_start_date=2025-02-22 11:00:14.196321+00:00, run_end_date=2025-02-22 11:00:59.980995+00:00, run_duration=45.784674, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-20 00:00:00+00:00, data_interval_end=2024-02-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:00:59,987 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-21T00:00:00+00:00, run_after=2024-02-22T00:00:00+00:00
2025-02-22 11:00:59,990 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2025-02-22 10:57:08+00:00: manual__2025-02-22T10:57:08+00:00, externally triggered: True> successful
2025-02-22 11:00:59,990 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2025-02-22 10:57:08+00:00, run_id=manual__2025-02-22T10:57:08+00:00, run_start_date=2025-02-22 11:00:14.196710+00:00, run_end_date=2025-02-22 11:00:59.990922+00:00, run_duration=45.794212, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-02-21 00:00:00+00:00, data_interval_end=2025-02-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:00:59,994 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2025-02-22T00:00:00+00:00, run_after=2025-02-23T00:00:00+00:00
2025-02-22 11:01:00,026 INFO - 5 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:00,026 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:00,026 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:00,026 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:01:00,026 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:01:00,026 INFO - DAG lead_scoring_data_pipeline has 4/16 running and queued tasks
2025-02-22 11:01:00,026 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:00,028 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:01:00,028 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:00,028 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:01:00,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:00,029 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='manual__2025-02-22T11:00:34+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:01:00,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:00,029 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:01:00,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:00,029 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:00,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:00,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:03,062 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:05,765 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:08,445 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:11,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:13,937 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:13,937 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:13,937 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=manual__2025-02-22T11:00:34+00:00 exited with status success for try_number 1
2025-02-22 11:01:13,938 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:13,938 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:13,945 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:12.807632+00:00, run_end_date=2025-02-22 11:01:13.379138+00:00, run_duration=0.571506, state=success, executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:00.027271+00:00, queued_by_job_id=7, pid=49102
2025-02-22 11:01:13,945 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:10.071946+00:00, run_end_date=2025-02-22 11:01:10.599727+00:00, run_duration=0.527781, state=success, executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:01:00.027271+00:00, queued_by_job_id=7, pid=49074
2025-02-22 11:01:13,945 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=manual__2025-02-22T11:00:34+00:00, map_index=-1, run_start_date=2025-02-22 11:01:07.300414+00:00, run_end_date=2025-02-22 11:01:07.852132+00:00, run_duration=0.551718, state=success, executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:01:00.027271+00:00, queued_by_job_id=7, pid=49055
2025-02-22 11:01:13,945 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:04.635174+00:00, run_end_date=2025-02-22 11:01:05.095165+00:00, run_duration=0.459991, state=success, executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:01:00.027271+00:00, queued_by_job_id=7, pid=49035
2025-02-22 11:01:13,945 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:01.726607+00:00, run_end_date=2025-02-22 11:01:02.478296+00:00, run_duration=0.751689, state=success, executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:01:00.027271+00:00, queued_by_job_id=7, pid=49014
2025-02-22 11:01:14,575 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-21 00:00:00+00:00: scheduled__2024-02-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:01:14,575 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-21 00:00:00+00:00, run_id=scheduled__2024-02-21T00:00:00+00:00, run_start_date=2025-02-22 11:00:20.269228+00:00, run_end_date=2025-02-22 11:01:14.575484+00:00, run_duration=54.306256, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-21 00:00:00+00:00, data_interval_end=2024-02-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:14,580 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-22T00:00:00+00:00, run_after=2024-02-23T00:00:00+00:00
2025-02-22 11:01:14,739 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:14,739 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:14,740 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:14,740 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:01:14,740 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:01:14,740 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T11:00:34+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:14,744 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:01:14,745 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:14,745 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:01:14,746 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:14,746 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='manual__2025-02-22T11:00:34+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:01:14,746 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:14,747 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:14,747 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:14,808 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:17,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:20,399 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:23,192 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:25,834 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:25,834 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:25,834 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=manual__2025-02-22T11:00:34+00:00 exited with status success for try_number 1
2025-02-22 11:01:25,834 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:25,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:24.847706+00:00, run_end_date=2025-02-22 11:01:25.305699+00:00, run_duration=0.457993, state=success, executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:14.741808+00:00, queued_by_job_id=7, pid=49207
2025-02-22 11:01:25,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=manual__2025-02-22T11:00:34+00:00, map_index=-1, run_start_date=2025-02-22 11:01:21.931238+00:00, run_end_date=2025-02-22 11:01:22.520979+00:00, run_duration=0.589741, state=success, executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:01:14.741808+00:00, queued_by_job_id=7, pid=49170
2025-02-22 11:01:25,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:19.099878+00:00, run_end_date=2025-02-22 11:01:19.790191+00:00, run_duration=0.690313, state=success, executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:01:14.741808+00:00, queued_by_job_id=7, pid=49151
2025-02-22 11:01:25,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:16.257932+00:00, run_end_date=2025-02-22 11:01:16.783788+00:00, run_duration=0.525856, state=success, executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:01:14.741808+00:00, queued_by_job_id=7, pid=49131
2025-02-22 11:01:26,395 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-23T00:00:00+00:00, run_after=2024-02-24T00:00:00+00:00
2025-02-22 11:01:26,497 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-22 00:00:00+00:00: scheduled__2024-02-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:01:26,498 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-22 00:00:00+00:00, run_id=scheduled__2024-02-22T00:00:00+00:00, run_start_date=2025-02-22 11:00:29.177684+00:00, run_end_date=2025-02-22 11:01:26.498169+00:00, run_duration=57.320485, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-22 00:00:00+00:00, data_interval_end=2024-02-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:26,503 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-23T00:00:00+00:00, run_after=2024-02-24T00:00:00+00:00
2025-02-22 11:01:26,633 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T11:00:34+00:00 [scheduled]>
2025-02-22 11:01:26,633 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:26,633 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:26,634 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:01:26,634 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T11:00:34+00:00 [scheduled]>
2025-02-22 11:01:26,638 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:01:26,638 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:26,639 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:26,639 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:26,639 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='manual__2025-02-22T11:00:34+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:26,639 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:26,758 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:29,445 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:32,011 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T11:00:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:34,924 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:34,925 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:34,925 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=manual__2025-02-22T11:00:34+00:00 exited with status success for try_number 1
2025-02-22 11:01:34,932 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=manual__2025-02-22T11:00:34+00:00, map_index=-1, run_start_date=2025-02-22 11:01:33.604769+00:00, run_end_date=2025-02-22 11:01:34.363798+00:00, run_duration=0.759029, state=success, executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:26.635292+00:00, queued_by_job_id=7, pid=49276
2025-02-22 11:01:34,933 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:31.004210+00:00, run_end_date=2025-02-22 11:01:31.506086+00:00, run_duration=0.501876, state=success, executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:26.635292+00:00, queued_by_job_id=7, pid=49256
2025-02-22 11:01:34,933 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:28.343539+00:00, run_end_date=2025-02-22 11:01:28.800567+00:00, run_duration=0.457028, state=success, executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:01:26.635292+00:00, queued_by_job_id=7, pid=49236
2025-02-22 11:01:35,798 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-26T00:00:00+00:00, run_after=2024-02-27T00:00:00+00:00
2025-02-22 11:01:36,139 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-23 00:00:00+00:00: scheduled__2024-02-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:01:36,140 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-23 00:00:00+00:00, run_id=scheduled__2024-02-23T00:00:00+00:00, run_start_date=2025-02-22 11:00:41.209596+00:00, run_end_date=2025-02-22 11:01:36.140130+00:00, run_duration=54.930534, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-23 00:00:00+00:00, data_interval_end=2024-02-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:36,146 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-24T00:00:00+00:00, run_after=2024-02-25T00:00:00+00:00
2025-02-22 11:01:36,151 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2025-02-22 11:00:34+00:00: manual__2025-02-22T11:00:34+00:00, externally triggered: True> successful
2025-02-22 11:01:36,152 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2025-02-22 11:00:34+00:00, run_id=manual__2025-02-22T11:00:34+00:00, run_start_date=2025-02-22 11:00:41.211282+00:00, run_end_date=2025-02-22 11:01:36.152137+00:00, run_duration=54.940855, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-02-21 00:00:00+00:00, data_interval_end=2025-02-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:36,157 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2025-02-22T00:00:00+00:00, run_after=2025-02-23T00:00:00+00:00
2025-02-22 11:01:36,290 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:36,291 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:36,291 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:36,291 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:36,294 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:01:36,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:36,295 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:36,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:36,643 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:39,461 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:42,002 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:42,003 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:42,010 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:40.941616+00:00, run_end_date=2025-02-22 11:01:41.478946+00:00, run_duration=0.53733, state=success, executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:36.292186+00:00, queued_by_job_id=7, pid=49325
2025-02-22 11:01:42,010 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:38.135251+00:00, run_end_date=2025-02-22 11:01:38.773285+00:00, run_duration=0.638034, state=success, executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:01:36.292186+00:00, queued_by_job_id=7, pid=49305
2025-02-22 11:01:42,408 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-24 00:00:00+00:00: scheduled__2024-02-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:01:42,408 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-24 00:00:00+00:00, run_id=scheduled__2024-02-24T00:00:00+00:00, run_start_date=2025-02-22 11:00:59.718826+00:00, run_end_date=2025-02-22 11:01:42.408771+00:00, run_duration=42.689945, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-24 00:00:00+00:00, data_interval_end=2024-02-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:42,415 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-25T00:00:00+00:00, run_after=2024-02-26T00:00:00+00:00
2025-02-22 11:01:42,458 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:42,458 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:42,458 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:42,461 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:01:42,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:42,544 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:45,688 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:45,700 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:44.152677+00:00, run_end_date=2025-02-22 11:01:44.742253+00:00, run_duration=0.589576, state=success, executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:01:42.459183+00:00, queued_by_job_id=7, pid=49355
2025-02-22 11:01:45,935 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-26T00:00:00+00:00, run_after=2024-02-27T00:00:00+00:00
2025-02-22 11:01:46,183 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:46,184 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:46,184 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:46,188 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:01:46,188 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:46,266 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:49,662 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:49,669 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:48.579694+00:00, run_end_date=2025-02-22 11:01:49.075146+00:00, run_duration=0.495452, state=success, executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:01:46.185614+00:00, queued_by_job_id=7, pid=49384
2025-02-22 11:01:49,800 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:01:50,055 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-27T00:00:00+00:00, run_after=2024-02-28T00:00:00+00:00
2025-02-22 11:01:50,433 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:50,434 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:50,434 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:50,434 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:50,438 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:01:50,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:50,439 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:01:50,439 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:50,590 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:53,515 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:56,192 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:56,192 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:01:56,200 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:54.987546+00:00, run_end_date=2025-02-22 11:01:55.621015+00:00, run_duration=0.633469, state=success, executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:01:50.435575+00:00, queued_by_job_id=7, pid=49434
2025-02-22 11:01:56,200 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:52.158918+00:00, run_end_date=2025-02-22 11:01:52.648489+00:00, run_duration=0.489571, state=success, executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:01:50.435575+00:00, queued_by_job_id=7, pid=49406
2025-02-22 11:01:56,590 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-28T00:00:00+00:00, run_after=2024-02-29T00:00:00+00:00
2025-02-22 11:01:56,876 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-25 00:00:00+00:00: scheduled__2024-02-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:01:56,876 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-25 00:00:00+00:00, run_id=scheduled__2024-02-25T00:00:00+00:00, run_start_date=2025-02-22 11:01:36.004076+00:00, run_end_date=2025-02-22 11:01:56.876625+00:00, run_duration=20.872549, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-25 00:00:00+00:00, data_interval_end=2024-02-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:01:56,882 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-26T00:00:00+00:00, run_after=2024-02-27T00:00:00+00:00
2025-02-22 11:01:57,010 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:57,011 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:01:57,011 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:01:57,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:01:57,015 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:01:57,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:57,016 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:01:57,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:57,086 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:01:59,838 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:02,500 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:02,501 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:02,516 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:01.485619+00:00, run_end_date=2025-02-22 11:02:02.019900+00:00, run_duration=0.534281, state=success, executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:01:57.012635+00:00, queued_by_job_id=7, pid=49475
2025-02-22 11:02:02,517 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:01:58.667813+00:00, run_end_date=2025-02-22 11:01:59.189240+00:00, run_duration=0.521427, state=success, executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:01:57.012635+00:00, queued_by_job_id=7, pid=49455
2025-02-22 11:02:02,894 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-27T00:00:00+00:00, run_after=2024-02-28T00:00:00+00:00
2025-02-22 11:02:03,135 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:03,135 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:03,136 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:03,136 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:03,140 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:02:03,140 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:03,141 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:02:03,141 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:03,225 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:06,293 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:09,146 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:09,146 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:09,154 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:07.890448+00:00, run_end_date=2025-02-22 11:02:08.455449+00:00, run_duration=0.565001, state=success, executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:02:03.137346+00:00, queued_by_job_id=7, pid=49524
2025-02-22 11:02:09,154 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:05.069288+00:00, run_end_date=2025-02-22 11:02:05.686567+00:00, run_duration=0.617279, state=success, executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:02:03.137346+00:00, queued_by_job_id=7, pid=49497
2025-02-22 11:02:09,546 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-28T00:00:00+00:00, run_after=2024-02-29T00:00:00+00:00
2025-02-22 11:02:09,810 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:09,810 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:09,811 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:09,811 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:09,815 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:02:09,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:09,816 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:02:09,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:09,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:12,844 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:15,828 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:15,829 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:15,836 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:14.506027+00:00, run_end_date=2025-02-22 11:02:15.070852+00:00, run_duration=0.564825, state=success, executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:02:09.812585+00:00, queued_by_job_id=7, pid=49566
2025-02-22 11:02:15,837 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:11.626728+00:00, run_end_date=2025-02-22 11:02:12.179043+00:00, run_duration=0.552315, state=success, executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:02:09.812585+00:00, queued_by_job_id=7, pid=49546
2025-02-22 11:02:16,151 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-29T00:00:00+00:00, run_after=2024-03-01T00:00:00+00:00
2025-02-22 11:02:16,381 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-26 00:00:00+00:00: scheduled__2024-02-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:02:16,381 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-26 00:00:00+00:00, run_id=scheduled__2024-02-26T00:00:00+00:00, run_start_date=2025-02-22 11:01:50.174598+00:00, run_end_date=2025-02-22 11:02:16.381854+00:00, run_duration=26.207256, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-26 00:00:00+00:00, data_interval_end=2024-02-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:02:16,387 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-27T00:00:00+00:00, run_after=2024-02-28T00:00:00+00:00
2025-02-22 11:02:16,499 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:16,499 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:16,499 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:16,499 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:16,502 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:02:16,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:16,503 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:02:16,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:16,597 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:19,510 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:23,172 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:23,173 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:23,180 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:21.988579+00:00, run_end_date=2025-02-22 11:02:22.638679+00:00, run_duration=0.6501, state=success, executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:02:16.500582+00:00, queued_by_job_id=7, pid=49616
2025-02-22 11:02:23,180 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:18.268785+00:00, run_end_date=2025-02-22 11:02:18.794075+00:00, run_duration=0.52529, state=success, executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:02:16.500582+00:00, queued_by_job_id=7, pid=49596
2025-02-22 11:02:23,727 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-28T00:00:00+00:00, run_after=2024-02-29T00:00:00+00:00
2025-02-22 11:02:23,889 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-27 00:00:00+00:00: scheduled__2024-02-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:02:23,890 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-27 00:00:00+00:00, run_id=scheduled__2024-02-27T00:00:00+00:00, run_start_date=2025-02-22 11:01:56.726387+00:00, run_end_date=2025-02-22 11:02:23.890258+00:00, run_duration=27.163871, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-27 00:00:00+00:00, data_interval_end=2024-02-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:02:23,896 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-28T00:00:00+00:00, run_after=2024-02-29T00:00:00+00:00
2025-02-22 11:02:24,079 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:24,080 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:24,080 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:24,084 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:02:24,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:24,194 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:26,951 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:26,959 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:25.755967+00:00, run_end_date=2025-02-22 11:02:26.355205+00:00, run_duration=0.599238, state=success, executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:02:24.081364+00:00, queued_by_job_id=7, pid=49638
2025-02-22 11:02:27,200 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-29T00:00:00+00:00, run_after=2024-03-01T00:00:00+00:00
2025-02-22 11:02:27,650 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:27,650 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:27,651 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:27,655 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:02:27,655 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:27,749 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:30,685 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:30,692 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:29.311866+00:00, run_end_date=2025-02-22 11:02:30.180263+00:00, run_duration=0.868397, state=success, executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:02:27.652196+00:00, queued_by_job_id=7, pid=49667
2025-02-22 11:02:31,244 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-01T00:00:00+00:00, run_after=2024-03-02T00:00:00+00:00
2025-02-22 11:02:31,623 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:31,624 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:31,624 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:31,624 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:31,627 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-02-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:02:31,628 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:31,628 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:02:31,628 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:31,896 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:34,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:37,852 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-02-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:37,853 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:37,860 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:36.551359+00:00, run_end_date=2025-02-22 11:02:37.188861+00:00, run_duration=0.637502, state=success, executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:02:31.625430+00:00, queued_by_job_id=7, pid=49709
2025-02-22 11:02:37,860 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-02-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:33.590399+00:00, run_end_date=2025-02-22 11:02:34.147415+00:00, run_duration=0.557016, state=success, executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:02:31.625430+00:00, queued_by_job_id=7, pid=49689
2025-02-22 11:02:38,212 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-02T00:00:00+00:00, run_after=2024-03-03T00:00:00+00:00
2025-02-22 11:02:38,447 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-28 00:00:00+00:00: scheduled__2024-02-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:02:38,448 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-28 00:00:00+00:00, run_id=scheduled__2024-02-28T00:00:00+00:00, run_start_date=2025-02-22 11:02:16.265308+00:00, run_end_date=2025-02-22 11:02:38.448268+00:00, run_duration=22.18296, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-28 00:00:00+00:00, data_interval_end=2024-02-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:02:38,451 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-02-29T00:00:00+00:00, run_after=2024-03-01T00:00:00+00:00
2025-02-22 11:02:38,544 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:38,544 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:38,544 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:38,545 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:38,546 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:02:38,546 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:38,547 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-02-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:02:38,547 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:38,592 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:41,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:44,828 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:44,828 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-02-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:44,835 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-02-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:43.385186+00:00, run_end_date=2025-02-22 11:02:44.153969+00:00, run_duration=0.768783, state=success, executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:02:38.545393+00:00, queued_by_job_id=7, pid=49759
2025-02-22 11:02:44,835 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:40.174789+00:00, run_end_date=2025-02-22 11:02:41.160246+00:00, run_duration=0.985457, state=success, executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:02:38.545393+00:00, queued_by_job_id=7, pid=49739
2025-02-22 11:02:45,181 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-01T00:00:00+00:00, run_after=2024-03-02T00:00:00+00:00
2025-02-22 11:02:45,390 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:45,391 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:45,391 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:45,391 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:45,395 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:02:45,395 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:45,396 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-02-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:02:45,396 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:45,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:48,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:50,888 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:50,889 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-02-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:50,896 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-02-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:49.769660+00:00, run_end_date=2025-02-22 11:02:50.272407+00:00, run_duration=0.502747, state=success, executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:02:45.392657+00:00, queued_by_job_id=7, pid=49808
2025-02-22 11:02:50,896 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:46.994546+00:00, run_end_date=2025-02-22 11:02:47.486186+00:00, run_duration=0.49164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:02:45.392657+00:00, queued_by_job_id=7, pid=49780
2025-02-22 11:02:51,239 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-02T00:00:00+00:00, run_after=2024-03-03T00:00:00+00:00
2025-02-22 11:02:51,457 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:51,457 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:51,458 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:51,458 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-02-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:51,462 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:02:51,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:51,463 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-02-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:02:51,463 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:51,564 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:54,182 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-02-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:56,807 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:56,808 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-02-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:02:56,815 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-02-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:55.849658+00:00, run_end_date=2025-02-22 11:02:56.280015+00:00, run_duration=0.430357, state=success, executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:02:51.459289+00:00, queued_by_job_id=7, pid=49849
2025-02-22 11:02:56,815 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:53.139410+00:00, run_end_date=2025-02-22 11:02:53.566360+00:00, run_duration=0.42695, state=success, executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:02:51.459289+00:00, queued_by_job_id=7, pid=49829
2025-02-22 11:02:57,067 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-03T00:00:00+00:00, run_after=2024-03-04T00:00:00+00:00
2025-02-22 11:02:57,338 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-02-29 00:00:00+00:00: scheduled__2024-02-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:02:57,339 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-02-29 00:00:00+00:00, run_id=scheduled__2024-02-29T00:00:00+00:00, run_start_date=2025-02-22 11:02:31.377552+00:00, run_end_date=2025-02-22 11:02:57.339460+00:00, run_duration=25.961908, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-02-29 00:00:00+00:00, data_interval_end=2024-03-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:02:57,345 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-01T00:00:00+00:00, run_after=2024-03-02T00:00:00+00:00
2025-02-22 11:02:57,501 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:57,501 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:02:57,501 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:02:57,502 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:02:57,505 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:02:57,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:57,506 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:02:57,507 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:02:57,573 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:00,349 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:02,847 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:02,848 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:02,856 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:01.927993+00:00, run_end_date=2025-02-22 11:03:02.346279+00:00, run_duration=0.418286, state=success, executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:02:57.503050+00:00, queued_by_job_id=7, pid=49898
2025-02-22 11:03:02,856 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:02:59.216093+00:00, run_end_date=2025-02-22 11:02:59.742512+00:00, run_duration=0.526419, state=success, executor_state=success, try_number=1, max_tries=1, job_id=59, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:02:57.503050+00:00, queued_by_job_id=7, pid=49879
2025-02-22 11:03:03,168 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-02T00:00:00+00:00, run_after=2024-03-03T00:00:00+00:00
2025-02-22 11:03:03,322 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-01 00:00:00+00:00: scheduled__2024-03-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:03,323 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-01 00:00:00+00:00, run_id=scheduled__2024-03-01T00:00:00+00:00, run_start_date=2025-02-22 11:02:38.329854+00:00, run_end_date=2025-02-22 11:03:03.323051+00:00, run_duration=24.993197, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-01 00:00:00+00:00, data_interval_end=2024-03-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:03,329 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-02T00:00:00+00:00, run_after=2024-03-03T00:00:00+00:00
2025-02-22 11:03:03,433 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:03,433 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:03,433 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:03,437 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:03,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:03,507 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:06,346 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:06,353 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:05.193181+00:00, run_end_date=2025-02-22 11:03:05.719680+00:00, run_duration=0.526499, state=success, executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:03.434814+00:00, queued_by_job_id=7, pid=49920
2025-02-22 11:03:06,588 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-03T00:00:00+00:00, run_after=2024-03-04T00:00:00+00:00
2025-02-22 11:03:06,802 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:06,803 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:06,803 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:06,807 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:06,807 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:06,928 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:09,516 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:09,523 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:08.423317+00:00, run_end_date=2025-02-22 11:03:08.920054+00:00, run_duration=0.496737, state=success, executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:06.804377+00:00, queued_by_job_id=7, pid=49940
2025-02-22 11:03:09,855 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-04T00:00:00+00:00, run_after=2024-03-05T00:00:00+00:00
2025-02-22 11:03:10,205 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:10,205 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:10,205 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:10,206 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:10,209 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:10,209 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:10,209 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:10,210 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:10,446 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:13,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:15,957 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:15,957 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:15,965 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:14.684948+00:00, run_end_date=2025-02-22 11:03:15.384041+00:00, run_duration=0.699093, state=success, executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:10.206896+00:00, queued_by_job_id=7, pid=49990
2025-02-22 11:03:15,965 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:11.917480+00:00, run_end_date=2025-02-22 11:03:12.451854+00:00, run_duration=0.534374, state=success, executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:10.206896+00:00, queued_by_job_id=7, pid=49970
2025-02-22 11:03:16,316 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-05T00:00:00+00:00, run_after=2024-03-06T00:00:00+00:00
2025-02-22 11:03:16,566 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-02 00:00:00+00:00: scheduled__2024-03-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:16,567 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-02 00:00:00+00:00, run_id=scheduled__2024-03-02T00:00:00+00:00, run_start_date=2025-02-22 11:02:57.185946+00:00, run_end_date=2025-02-22 11:03:16.567406+00:00, run_duration=19.38146, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-02 00:00:00+00:00, data_interval_end=2024-03-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:16,573 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-03T00:00:00+00:00, run_after=2024-03-04T00:00:00+00:00
2025-02-22 11:03:16,695 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:16,695 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:16,696 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:16,696 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:16,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:16,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:16,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:16,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:16,756 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:18,648 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:20,659 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:20,659 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:20,667 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:20.017979+00:00, run_end_date=2025-02-22 11:03:20.166421+00:00, run_duration=0.148442, state=success, executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:16.696915+00:00, queued_by_job_id=7, pid=50038
2025-02-22 11:03:20,667 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:18.151890+00:00, run_end_date=2025-02-22 11:03:18.295865+00:00, run_duration=0.143975, state=success, executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:16.696915+00:00, queued_by_job_id=7, pid=50011
2025-02-22 11:03:20,810 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-04T00:00:00+00:00, run_after=2024-03-05T00:00:00+00:00
2025-02-22 11:03:20,902 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:20,902 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:20,902 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:20,903 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:20,906 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:20,906 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:20,906 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:20,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:20,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:22,937 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:24,700 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:24,701 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:24,708 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:24.286551+00:00, run_end_date=2025-02-22 11:03:24.421888+00:00, run_duration=0.135337, state=success, executor_state=success, try_number=1, max_tries=1, job_id=68, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:20.903687+00:00, queued_by_job_id=7, pid=50077
2025-02-22 11:03:24,709 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:22.296358+00:00, run_end_date=2025-02-22 11:03:22.562889+00:00, run_duration=0.266531, state=success, executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:20.903687+00:00, queued_by_job_id=7, pid=50058
2025-02-22 11:03:25,000 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-05T00:00:00+00:00, run_after=2024-03-06T00:00:00+00:00
2025-02-22 11:03:25,389 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:25,389 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:25,389 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:25,390 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:25,393 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:25,393 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:25,394 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:25,394 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:25,407 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:27,221 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:28,944 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:28,945 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:28,952 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:28.534065+00:00, run_end_date=2025-02-22 11:03:28.669118+00:00, run_duration=0.135053, state=success, executor_state=success, try_number=1, max_tries=1, job_id=70, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:25.390834+00:00, queued_by_job_id=7, pid=50118
2025-02-22 11:03:28,953 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:26.727610+00:00, run_end_date=2025-02-22 11:03:26.874919+00:00, run_duration=0.147309, state=success, executor_state=success, try_number=1, max_tries=1, job_id=69, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:25.390834+00:00, queued_by_job_id=7, pid=50099
2025-02-22 11:03:29,306 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-06T00:00:00+00:00, run_after=2024-03-07T00:00:00+00:00
2025-02-22 11:03:29,366 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-03 00:00:00+00:00: scheduled__2024-03-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:29,367 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-03 00:00:00+00:00, run_id=scheduled__2024-03-03T00:00:00+00:00, run_start_date=2025-02-22 11:03:09.979001+00:00, run_end_date=2025-02-22 11:03:29.367188+00:00, run_duration=19.388187, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-03 00:00:00+00:00, data_interval_end=2024-03-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:29,370 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-04T00:00:00+00:00, run_after=2024-03-05T00:00:00+00:00
2025-02-22 11:03:29,395 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:29,395 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:29,395 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:29,395 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:29,397 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:29,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:29,397 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:29,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:29,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:31,209 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:33,211 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:33,211 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:33,219 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:32.538912+00:00, run_end_date=2025-02-22 11:03:32.679478+00:00, run_duration=0.140566, state=success, executor_state=success, try_number=1, max_tries=1, job_id=72, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:29.396039+00:00, queued_by_job_id=7, pid=50156
2025-02-22 11:03:33,219 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:30.742489+00:00, run_end_date=2025-02-22 11:03:30.885453+00:00, run_duration=0.142964, state=success, executor_state=success, try_number=1, max_tries=1, job_id=71, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:29.396039+00:00, queued_by_job_id=7, pid=50138
2025-02-22 11:03:33,409 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-05T00:00:00+00:00, run_after=2024-03-06T00:00:00+00:00
2025-02-22 11:03:33,459 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-04 00:00:00+00:00: scheduled__2024-03-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:33,460 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-04 00:00:00+00:00, run_id=scheduled__2024-03-04T00:00:00+00:00, run_start_date=2025-02-22 11:03:16.432782+00:00, run_end_date=2025-02-22 11:03:33.459979+00:00, run_duration=17.027197, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-04 00:00:00+00:00, data_interval_end=2024-03-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:33,465 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-05T00:00:00+00:00, run_after=2024-03-06T00:00:00+00:00
2025-02-22 11:03:33,488 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:33,489 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:33,489 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:33,490 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:33,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:33,504 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:35,335 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:35,342 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:34.847380+00:00, run_end_date=2025-02-22 11:03:34.993693+00:00, run_duration=0.146313, state=success, executor_state=success, try_number=1, max_tries=1, job_id=73, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:33.489651+00:00, queued_by_job_id=7, pid=50176
2025-02-22 11:03:35,477 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-06T00:00:00+00:00, run_after=2024-03-07T00:00:00+00:00
2025-02-22 11:03:35,529 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:35,529 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:35,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:35,531 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:35,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:35,544 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:37,321 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:37,329 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:36.863499+00:00, run_end_date=2025-02-22 11:03:37.010400+00:00, run_duration=0.146901, state=success, executor_state=success, try_number=1, max_tries=1, job_id=74, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:35.530435+00:00, queued_by_job_id=7, pid=50197
2025-02-22 11:03:37,480 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-07T00:00:00+00:00, run_after=2024-03-08T00:00:00+00:00
2025-02-22 11:03:37,663 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:37,663 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:37,663 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:37,663 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:37,668 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:37,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:37,668 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:37,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:37,683 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:39,438 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:41,175 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:41,176 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:41,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:40.766928+00:00, run_end_date=2025-02-22 11:03:40.904152+00:00, run_duration=0.137224, state=success, executor_state=success, try_number=1, max_tries=1, job_id=76, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:37.664265+00:00, queued_by_job_id=7, pid=50243
2025-02-22 11:03:41,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:39.017688+00:00, run_end_date=2025-02-22 11:03:39.153805+00:00, run_duration=0.136117, state=success, executor_state=success, try_number=1, max_tries=1, job_id=75, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:37.664265+00:00, queued_by_job_id=7, pid=50224
2025-02-22 11:03:41,473 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-08T00:00:00+00:00, run_after=2024-03-09T00:00:00+00:00
2025-02-22 11:03:41,764 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-05 00:00:00+00:00: scheduled__2024-03-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:41,764 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-05 00:00:00+00:00, run_id=scheduled__2024-03-05T00:00:00+00:00, run_start_date=2025-02-22 11:03:29.334745+00:00, run_end_date=2025-02-22 11:03:41.764861+00:00, run_duration=12.430116, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-05 00:00:00+00:00, data_interval_end=2024-03-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:41,768 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-06T00:00:00+00:00, run_after=2024-03-07T00:00:00+00:00
2025-02-22 11:03:41,792 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:41,792 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:41,792 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:41,793 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:41,794 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:41,794 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:41,795 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:41,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:41,808 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:43,607 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:45,371 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:45,371 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:45,379 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:44.946857+00:00, run_end_date=2025-02-22 11:03:45.082781+00:00, run_duration=0.135924, state=success, executor_state=success, try_number=1, max_tries=1, job_id=78, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:41.793448+00:00, queued_by_job_id=7, pid=50282
2025-02-22 11:03:45,380 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:43.132800+00:00, run_end_date=2025-02-22 11:03:43.282770+00:00, run_duration=0.14997, state=success, executor_state=success, try_number=1, max_tries=1, job_id=77, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:41.793448+00:00, queued_by_job_id=7, pid=50263
2025-02-22 11:03:45,520 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-07T00:00:00+00:00, run_after=2024-03-08T00:00:00+00:00
2025-02-22 11:03:45,609 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:45,610 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:45,610 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:45,610 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:45,613 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:45,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:45,614 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:45,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:45,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:47,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:49,321 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:49,322 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:49,330 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:48.855693+00:00, run_end_date=2025-02-22 11:03:49.003577+00:00, run_duration=0.147884, state=success, executor_state=success, try_number=1, max_tries=1, job_id=80, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:45.611440+00:00, queued_by_job_id=7, pid=50320
2025-02-22 11:03:49,330 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:46.957452+00:00, run_end_date=2025-02-22 11:03:47.099811+00:00, run_duration=0.142359, state=success, executor_state=success, try_number=1, max_tries=1, job_id=79, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:45.611440+00:00, queued_by_job_id=7, pid=50302
2025-02-22 11:03:49,587 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-08T00:00:00+00:00, run_after=2024-03-09T00:00:00+00:00
2025-02-22 11:03:49,639 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:49,639 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:49,639 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:49,639 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:49,641 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:03:49,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:49,641 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:49,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:49,655 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:51,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:53,318 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:53,319 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:53,326 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:52.806580+00:00, run_end_date=2025-02-22 11:03:53.004482+00:00, run_duration=0.197902, state=success, executor_state=success, try_number=1, max_tries=1, job_id=82, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:49.640151+00:00, queued_by_job_id=7, pid=50374
2025-02-22 11:03:53,326 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:51.018368+00:00, run_end_date=2025-02-22 11:03:51.158759+00:00, run_duration=0.140391, state=success, executor_state=success, try_number=1, max_tries=1, job_id=81, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:03:49.640151+00:00, queued_by_job_id=7, pid=50356
2025-02-22 11:03:53,491 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-09T00:00:00+00:00, run_after=2024-03-10T00:00:00+00:00
2025-02-22 11:03:53,916 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-06 00:00:00+00:00: scheduled__2024-03-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:53,917 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-06 00:00:00+00:00, run_id=scheduled__2024-03-06T00:00:00+00:00, run_start_date=2025-02-22 11:03:37.546033+00:00, run_end_date=2025-02-22 11:03:53.917115+00:00, run_duration=16.371082, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-06 00:00:00+00:00, data_interval_end=2024-03-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:53,920 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-07T00:00:00+00:00, run_after=2024-03-08T00:00:00+00:00
2025-02-22 11:03:53,944 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:53,944 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:53,944 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:03:53,944 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:53,946 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:03:53,946 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:53,946 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:03:53,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:53,960 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:55,964 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:58,694 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:58,695 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:03:58,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:57.366394+00:00, run_end_date=2025-02-22 11:03:58.146930+00:00, run_duration=0.780536, state=success, executor_state=success, try_number=1, max_tries=1, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:03:53.945269+00:00, queued_by_job_id=7, pid=50416
2025-02-22 11:03:58,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:03:55.383064+00:00, run_end_date=2025-02-22 11:03:55.567657+00:00, run_duration=0.184593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=83, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:03:53.945269+00:00, queued_by_job_id=7, pid=50394
2025-02-22 11:03:58,863 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-08T00:00:00+00:00, run_after=2024-03-09T00:00:00+00:00
2025-02-22 11:03:58,914 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-07 00:00:00+00:00: scheduled__2024-03-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:03:58,915 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-07 00:00:00+00:00, run_id=scheduled__2024-03-07T00:00:00+00:00, run_start_date=2025-02-22 11:03:41.727195+00:00, run_end_date=2025-02-22 11:03:58.915239+00:00, run_duration=17.188044, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-07 00:00:00+00:00, data_interval_end=2024-03-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:03:58,920 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-08T00:00:00+00:00, run_after=2024-03-09T00:00:00+00:00
2025-02-22 11:03:58,943 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:58,943 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:03:58,943 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:03:58,945 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:03:58,945 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:03:58,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:00,792 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:00,800 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:00.366649+00:00, run_end_date=2025-02-22 11:04:00.499525+00:00, run_duration=0.132876, state=success, executor_state=success, try_number=1, max_tries=1, job_id=85, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:03:58.943759+00:00, queued_by_job_id=7, pid=50436
2025-02-22 11:04:00,946 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-09T00:00:00+00:00, run_after=2024-03-10T00:00:00+00:00
2025-02-22 11:04:01,023 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:01,023 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:01,023 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:01,027 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:01,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:01,041 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:02,848 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:02,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:02.371550+00:00, run_end_date=2025-02-22 11:04:02.517292+00:00, run_duration=0.145742, state=success, executor_state=success, try_number=1, max_tries=1, job_id=86, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:01.024770+00:00, queued_by_job_id=7, pid=50455
2025-02-22 11:04:03,004 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-10T00:00:00+00:00, run_after=2024-03-11T00:00:00+00:00
2025-02-22 11:04:03,086 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:03,086 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:03,087 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:03,087 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:03,088 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:03,089 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:03,089 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:03,089 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:03,102 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:05,031 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:06,868 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:06,868 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:06,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:06.350824+00:00, run_end_date=2025-02-22 11:04:06.500125+00:00, run_duration=0.149301, state=success, executor_state=success, try_number=1, max_tries=1, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:03.087548+00:00, queued_by_job_id=7, pid=50494
2025-02-22 11:04:06,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:04.474594+00:00, run_end_date=2025-02-22 11:04:04.664546+00:00, run_duration=0.189952, state=success, executor_state=success, try_number=1, max_tries=1, job_id=87, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:03.087548+00:00, queued_by_job_id=7, pid=50475
2025-02-22 11:04:07,053 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-11T00:00:00+00:00, run_after=2024-03-12T00:00:00+00:00
2025-02-22 11:04:07,118 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-08 00:00:00+00:00: scheduled__2024-03-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:07,118 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-08 00:00:00+00:00, run_id=scheduled__2024-03-08T00:00:00+00:00, run_start_date=2025-02-22 11:03:53.883133+00:00, run_end_date=2025-02-22 11:04:07.118619+00:00, run_duration=13.235486, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-08 00:00:00+00:00, data_interval_end=2024-03-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:07,121 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-09T00:00:00+00:00, run_after=2024-03-10T00:00:00+00:00
2025-02-22 11:04:07,145 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:07,145 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:07,145 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:07,145 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:07,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:07,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:07,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:07,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:07,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:08,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:10,754 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:10,755 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:10,762 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:10.321817+00:00, run_end_date=2025-02-22 11:04:10.460577+00:00, run_duration=0.13876, state=success, executor_state=success, try_number=1, max_tries=1, job_id=90, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:07.145933+00:00, queued_by_job_id=7, pid=50533
2025-02-22 11:04:10,762 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:08.518480+00:00, run_end_date=2025-02-22 11:04:08.659851+00:00, run_duration=0.141371, state=success, executor_state=success, try_number=1, max_tries=1, job_id=89, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:07.145933+00:00, queued_by_job_id=7, pid=50514
2025-02-22 11:04:10,905 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-10T00:00:00+00:00, run_after=2024-03-11T00:00:00+00:00
2025-02-22 11:04:10,991 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:10,991 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:10,991 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:10,991 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:10,993 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:10,993 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:10,993 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:10,993 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:11,013 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:12,896 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:14,695 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:14,696 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:14,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:14.234322+00:00, run_end_date=2025-02-22 11:04:14.374934+00:00, run_duration=0.140612, state=success, executor_state=success, try_number=1, max_tries=1, job_id=92, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:10.991834+00:00, queued_by_job_id=7, pid=50580
2025-02-22 11:04:14,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:12.389960+00:00, run_end_date=2025-02-22 11:04:12.533827+00:00, run_duration=0.143867, state=success, executor_state=success, try_number=1, max_tries=1, job_id=91, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:10.991834+00:00, queued_by_job_id=7, pid=50561
2025-02-22 11:04:14,866 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-11T00:00:00+00:00, run_after=2024-03-12T00:00:00+00:00
2025-02-22 11:04:14,946 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:14,946 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:14,946 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:14,947 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:14,950 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:14,950 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:14,951 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:14,951 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:14,966 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:16,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:18,523 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:18,523 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:18,531 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:18.108878+00:00, run_end_date=2025-02-22 11:04:18.246408+00:00, run_duration=0.13753, state=success, executor_state=success, try_number=1, max_tries=1, job_id=94, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:14.947829+00:00, queued_by_job_id=7, pid=50618
2025-02-22 11:04:18,531 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:16.290368+00:00, run_end_date=2025-02-22 11:04:16.431191+00:00, run_duration=0.140823, state=success, executor_state=success, try_number=1, max_tries=1, job_id=93, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:14.947829+00:00, queued_by_job_id=7, pid=50600
2025-02-22 11:04:18,687 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-12T00:00:00+00:00, run_after=2024-03-13T00:00:00+00:00
2025-02-22 11:04:18,745 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-09 00:00:00+00:00: scheduled__2024-03-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:18,745 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-09 00:00:00+00:00, run_id=scheduled__2024-03-09T00:00:00+00:00, run_start_date=2025-02-22 11:04:03.034190+00:00, run_end_date=2025-02-22 11:04:18.745379+00:00, run_duration=15.711189, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-09 00:00:00+00:00, data_interval_end=2024-03-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:18,748 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-10T00:00:00+00:00, run_after=2024-03-11T00:00:00+00:00
2025-02-22 11:04:18,783 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:18,783 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:18,783 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:18,784 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:18,786 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:18,786 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:18,787 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:18,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:18,800 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:20,610 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:22,402 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:22,403 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:22,411 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:21.968211+00:00, run_end_date=2025-02-22 11:04:22.130827+00:00, run_duration=0.162616, state=success, executor_state=success, try_number=1, max_tries=1, job_id=96, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:18.784684+00:00, queued_by_job_id=7, pid=50656
2025-02-22 11:04:22,411 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:20.149746+00:00, run_end_date=2025-02-22 11:04:20.291917+00:00, run_duration=0.142171, state=success, executor_state=success, try_number=1, max_tries=1, job_id=95, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:18.784684+00:00, queued_by_job_id=7, pid=50638
2025-02-22 11:04:22,889 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-11T00:00:00+00:00, run_after=2024-03-12T00:00:00+00:00
2025-02-22 11:04:22,926 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-10 00:00:00+00:00: scheduled__2024-03-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:22,926 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-10 00:00:00+00:00, run_id=scheduled__2024-03-10T00:00:00+00:00, run_start_date=2025-02-22 11:04:07.082491+00:00, run_end_date=2025-02-22 11:04:22.926936+00:00, run_duration=15.844445, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-10 00:00:00+00:00, data_interval_end=2024-03-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:22,930 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-11T00:00:00+00:00, run_after=2024-03-12T00:00:00+00:00
2025-02-22 11:04:22,956 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:22,956 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:22,957 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:22,959 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:22,960 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:22,973 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:24,820 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:24,826 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:24.369343+00:00, run_end_date=2025-02-22 11:04:24.510224+00:00, run_duration=0.140881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=97, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:22.957843+00:00, queued_by_job_id=7, pid=50701
2025-02-22 11:04:25,261 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-12T00:00:00+00:00, run_after=2024-03-13T00:00:00+00:00
2025-02-22 11:04:25,334 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:25,334 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:25,335 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:25,338 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:25,338 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:25,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:27,145 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:27,153 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:26.668808+00:00, run_end_date=2025-02-22 11:04:26.830784+00:00, run_duration=0.161976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=98, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:25.335806+00:00, queued_by_job_id=7, pid=50729
2025-02-22 11:04:27,605 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-13T00:00:00+00:00, run_after=2024-03-14T00:00:00+00:00
2025-02-22 11:04:27,694 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:27,694 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:27,694 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:27,694 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:27,696 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:27,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:27,696 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:27,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:27,710 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:29,670 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:31,662 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:31,662 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:31,669 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:31.000845+00:00, run_end_date=2025-02-22 11:04:31.312672+00:00, run_duration=0.311827, state=success, executor_state=success, try_number=1, max_tries=1, job_id=100, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:27.694977+00:00, queued_by_job_id=7, pid=50776
2025-02-22 11:04:31,670 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:29.038089+00:00, run_end_date=2025-02-22 11:04:29.302184+00:00, run_duration=0.264095, state=success, executor_state=success, try_number=1, max_tries=1, job_id=99, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:27.694977+00:00, queued_by_job_id=7, pid=50757
2025-02-22 11:04:31,842 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-14T00:00:00+00:00, run_after=2024-03-15T00:00:00+00:00
2025-02-22 11:04:32,064 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-11 00:00:00+00:00: scheduled__2024-03-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:32,065 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-11 00:00:00+00:00, run_id=scheduled__2024-03-11T00:00:00+00:00, run_start_date=2025-02-22 11:04:18.714771+00:00, run_end_date=2025-02-22 11:04:32.065352+00:00, run_duration=13.350581, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-11 00:00:00+00:00, data_interval_end=2024-03-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:32,070 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-12T00:00:00+00:00, run_after=2024-03-13T00:00:00+00:00
2025-02-22 11:04:32,145 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:32,145 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:32,146 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:32,146 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:32,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:32,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:32,148 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:32,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:32,166 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:34,130 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:35,956 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:35,957 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:35,964 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:35.439250+00:00, run_end_date=2025-02-22 11:04:35.607353+00:00, run_duration=0.168103, state=success, executor_state=success, try_number=1, max_tries=1, job_id=102, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:32.146584+00:00, queued_by_job_id=7, pid=50815
2025-02-22 11:04:35,964 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:33.504683+00:00, run_end_date=2025-02-22 11:04:33.666395+00:00, run_duration=0.161712, state=success, executor_state=success, try_number=1, max_tries=1, job_id=101, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:32.146584+00:00, queued_by_job_id=7, pid=50797
2025-02-22 11:04:36,104 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-13T00:00:00+00:00, run_after=2024-03-14T00:00:00+00:00
2025-02-22 11:04:36,164 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:36,164 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:36,165 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:36,165 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:36,166 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:36,167 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:36,167 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:36,167 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:36,180 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:37,984 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:41,768 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:41,768 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:41,776 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:39.318194+00:00, run_end_date=2025-02-22 11:04:40.977929+00:00, run_duration=1.659735, state=success, executor_state=success, try_number=1, max_tries=1, job_id=104, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:36.165500+00:00, queued_by_job_id=7, pid=50855
2025-02-22 11:04:41,776 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:37.505374+00:00, run_end_date=2025-02-22 11:04:37.649266+00:00, run_duration=0.143892, state=success, executor_state=success, try_number=1, max_tries=1, job_id=103, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:36.165500+00:00, queued_by_job_id=7, pid=50835
2025-02-22 11:04:41,951 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-14T00:00:00+00:00, run_after=2024-03-15T00:00:00+00:00
2025-02-22 11:04:42,128 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:42,129 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:42,129 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:42,129 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:42,133 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:42,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:42,133 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:42,134 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:42,149 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:44,042 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:45,853 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:45,854 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:45,861 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:45.394585+00:00, run_end_date=2025-02-22 11:04:45.544598+00:00, run_duration=0.150013, state=success, executor_state=success, try_number=1, max_tries=1, job_id=106, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:42.130274+00:00, queued_by_job_id=7, pid=50903
2025-02-22 11:04:45,861 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:43.564564+00:00, run_end_date=2025-02-22 11:04:43.710653+00:00, run_duration=0.146089, state=success, executor_state=success, try_number=1, max_tries=1, job_id=105, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:42.130274+00:00, queued_by_job_id=7, pid=50876
2025-02-22 11:04:46,012 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-15T00:00:00+00:00, run_after=2024-03-16T00:00:00+00:00
2025-02-22 11:04:46,071 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-12 00:00:00+00:00: scheduled__2024-03-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:46,071 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-12 00:00:00+00:00, run_id=scheduled__2024-03-12T00:00:00+00:00, run_start_date=2025-02-22 11:04:27.641633+00:00, run_end_date=2025-02-22 11:04:46.071662+00:00, run_duration=18.430029, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-12 00:00:00+00:00, data_interval_end=2024-03-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:46,074 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-13T00:00:00+00:00, run_after=2024-03-14T00:00:00+00:00
2025-02-22 11:04:46,098 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:46,098 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:46,098 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:46,098 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:46,100 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:46,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:46,100 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:46,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:46,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:47,925 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:49,727 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:49,727 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:49,734 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:49.255136+00:00, run_end_date=2025-02-22 11:04:49.404155+00:00, run_duration=0.149019, state=success, executor_state=success, try_number=1, max_tries=1, job_id=108, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:46.099111+00:00, queued_by_job_id=7, pid=50942
2025-02-22 11:04:49,735 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:47.429549+00:00, run_end_date=2025-02-22 11:04:47.589536+00:00, run_duration=0.159987, state=success, executor_state=success, try_number=1, max_tries=1, job_id=107, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:46.099111+00:00, queued_by_job_id=7, pid=50922
2025-02-22 11:04:49,891 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-14T00:00:00+00:00, run_after=2024-03-15T00:00:00+00:00
2025-02-22 11:04:49,946 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-13 00:00:00+00:00: scheduled__2024-03-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:49,947 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-13 00:00:00+00:00, run_id=scheduled__2024-03-13T00:00:00+00:00, run_start_date=2025-02-22 11:04:31.967546+00:00, run_end_date=2025-02-22 11:04:49.947327+00:00, run_duration=17.979781, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-13 00:00:00+00:00, data_interval_end=2024-03-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:49,952 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-14T00:00:00+00:00, run_after=2024-03-15T00:00:00+00:00
2025-02-22 11:04:49,974 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:49,974 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:49,975 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:49,976 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:49,976 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:49,990 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:51,792 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:51,800 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:51.312187+00:00, run_end_date=2025-02-22 11:04:51.463320+00:00, run_duration=0.151133, state=success, executor_state=success, try_number=1, max_tries=1, job_id=109, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:49.975408+00:00, queued_by_job_id=7, pid=50961
2025-02-22 11:04:51,941 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-15T00:00:00+00:00, run_after=2024-03-16T00:00:00+00:00
2025-02-22 11:04:51,994 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:51,994 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:51,994 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:51,996 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:04:51,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:52,010 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:53,835 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:53,843 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:53.332189+00:00, run_end_date=2025-02-22 11:04:53.478826+00:00, run_duration=0.146637, state=success, executor_state=success, try_number=1, max_tries=1, job_id=110, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:04:51.995052+00:00, queued_by_job_id=7, pid=50981
2025-02-22 11:04:54,010 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-16T00:00:00+00:00, run_after=2024-03-17T00:00:00+00:00
2025-02-22 11:04:54,094 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:54,095 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:54,095 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:54,095 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:54,099 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:54,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:54,099 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:04:54,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:54,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:55,881 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:57,707 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:57,708 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:04:57,721 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:57.262056+00:00, run_end_date=2025-02-22 11:04:57.417447+00:00, run_duration=0.155391, state=success, executor_state=success, try_number=1, max_tries=1, job_id=112, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:04:54.095628+00:00, queued_by_job_id=7, pid=51028
2025-02-22 11:04:57,722 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:55.431692+00:00, run_end_date=2025-02-22 11:04:55.589533+00:00, run_duration=0.157841, state=success, executor_state=success, try_number=1, max_tries=1, job_id=111, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:54.095628+00:00, queued_by_job_id=7, pid=51001
2025-02-22 11:04:57,897 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-17T00:00:00+00:00, run_after=2024-03-18T00:00:00+00:00
2025-02-22 11:04:57,961 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-14 00:00:00+00:00: scheduled__2024-03-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:04:57,962 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-14 00:00:00+00:00, run_id=scheduled__2024-03-14T00:00:00+00:00, run_start_date=2025-02-22 11:04:46.041123+00:00, run_end_date=2025-02-22 11:04:57.962023+00:00, run_duration=11.9209, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-14 00:00:00+00:00, data_interval_end=2024-03-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:04:57,964 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-15T00:00:00+00:00, run_after=2024-03-16T00:00:00+00:00
2025-02-22 11:04:57,993 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:57,993 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:04:57,993 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:04:57,994 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:04:57,995 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:04:57,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:57,995 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:04:57,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:04:58,009 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:00,436 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:02,317 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:02,318 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:02,325 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:01.880704+00:00, run_end_date=2025-02-22 11:05:02.024587+00:00, run_duration=0.143883, state=success, executor_state=success, try_number=1, max_tries=1, job_id=114, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:04:57.994341+00:00, queued_by_job_id=7, pid=51074
2025-02-22 11:05:02,325 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:04:59.394524+00:00, run_end_date=2025-02-22 11:04:59.790548+00:00, run_duration=0.396024, state=success, executor_state=success, try_number=1, max_tries=1, job_id=113, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:04:57.994341+00:00, queued_by_job_id=7, pid=51055
2025-02-22 11:05:02,466 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-16T00:00:00+00:00, run_after=2024-03-17T00:00:00+00:00
2025-02-22 11:05:02,714 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:02,714 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:02,715 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:02,715 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:02,718 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:02,718 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:02,719 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:02,719 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:02,765 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:04,815 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:06,598 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:06,599 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:06,606 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:06.136430+00:00, run_end_date=2025-02-22 11:05:06.282307+00:00, run_duration=0.145877, state=success, executor_state=success, try_number=1, max_tries=1, job_id=116, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:02.715940+00:00, queued_by_job_id=7, pid=51113
2025-02-22 11:05:06,607 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:04.324775+00:00, run_end_date=2025-02-22 11:05:04.468167+00:00, run_duration=0.143392, state=success, executor_state=success, try_number=1, max_tries=1, job_id=115, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:02.715940+00:00, queued_by_job_id=7, pid=51094
2025-02-22 11:05:06,790 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-17T00:00:00+00:00, run_after=2024-03-18T00:00:00+00:00
2025-02-22 11:05:06,874 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:06,874 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:06,874 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:06,875 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:06,878 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:06,878 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:06,878 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:06,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:06,892 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:08,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:10,483 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:10,484 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:10,491 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:10.023887+00:00, run_end_date=2025-02-22 11:05:10.159022+00:00, run_duration=0.135135, state=success, executor_state=success, try_number=1, max_tries=1, job_id=118, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:06.875732+00:00, queued_by_job_id=7, pid=51152
2025-02-22 11:05:10,491 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:08.257500+00:00, run_end_date=2025-02-22 11:05:08.392979+00:00, run_duration=0.135479, state=success, executor_state=success, try_number=1, max_tries=1, job_id=117, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:06.875732+00:00, queued_by_job_id=7, pid=51133
2025-02-22 11:05:10,640 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-18T00:00:00+00:00, run_after=2024-03-19T00:00:00+00:00
2025-02-22 11:05:10,691 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-15 00:00:00+00:00: scheduled__2024-03-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:10,691 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-15 00:00:00+00:00, run_id=scheduled__2024-03-15T00:00:00+00:00, run_start_date=2025-02-22 11:04:54.044938+00:00, run_end_date=2025-02-22 11:05:10.691201+00:00, run_duration=16.646263, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-15 00:00:00+00:00, data_interval_end=2024-03-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:10,693 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-16T00:00:00+00:00, run_after=2024-03-17T00:00:00+00:00
2025-02-22 11:05:10,714 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:10,714 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:10,714 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:10,714 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:10,715 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:10,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:10,715 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:10,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:10,729 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:12,483 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:14,216 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:14,216 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:14,223 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:13.804174+00:00, run_end_date=2025-02-22 11:05:13.939540+00:00, run_duration=0.135366, state=success, executor_state=success, try_number=1, max_tries=1, job_id=120, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:10.714657+00:00, queued_by_job_id=7, pid=51190
2025-02-22 11:05:14,224 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:12.045149+00:00, run_end_date=2025-02-22 11:05:12.182912+00:00, run_duration=0.137763, state=success, executor_state=success, try_number=1, max_tries=1, job_id=119, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:10.714657+00:00, queued_by_job_id=7, pid=51171
2025-02-22 11:05:14,382 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-17T00:00:00+00:00, run_after=2024-03-18T00:00:00+00:00
2025-02-22 11:05:14,431 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-16 00:00:00+00:00: scheduled__2024-03-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:14,431 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-16 00:00:00+00:00, run_id=scheduled__2024-03-16T00:00:00+00:00, run_start_date=2025-02-22 11:04:57.928378+00:00, run_end_date=2025-02-22 11:05:14.431814+00:00, run_duration=16.503436, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-16 00:00:00+00:00, data_interval_end=2024-03-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:14,437 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-17T00:00:00+00:00, run_after=2024-03-18T00:00:00+00:00
2025-02-22 11:05:14,459 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:14,459 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:14,459 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:14,461 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:14,461 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:14,474 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:16,292 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:16,300 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:15.822524+00:00, run_end_date=2025-02-22 11:05:15.969199+00:00, run_duration=0.146675, state=success, executor_state=success, try_number=1, max_tries=1, job_id=121, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:14.460415+00:00, queued_by_job_id=7, pid=51210
2025-02-22 11:05:16,435 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-18T00:00:00+00:00, run_after=2024-03-19T00:00:00+00:00
2025-02-22 11:05:16,512 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:16,513 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:16,513 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:16,516 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:16,516 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:16,531 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:18,320 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:18,327 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:17.853163+00:00, run_end_date=2025-02-22 11:05:17.994595+00:00, run_duration=0.141432, state=success, executor_state=success, try_number=1, max_tries=1, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:16.514130+00:00, queued_by_job_id=7, pid=51230
2025-02-22 11:05:18,482 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-19T00:00:00+00:00, run_after=2024-03-20T00:00:00+00:00
2025-02-22 11:05:18,566 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:18,566 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:18,567 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:18,567 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:18,568 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:18,568 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:18,569 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:18,569 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:18,583 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:20,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:22,294 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:22,294 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:22,302 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:21.694625+00:00, run_end_date=2025-02-22 11:05:21.927830+00:00, run_duration=0.233205, state=success, executor_state=success, try_number=1, max_tries=1, job_id=124, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:18.567534+00:00, queued_by_job_id=7, pid=51269
2025-02-22 11:05:22,302 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:19.935951+00:00, run_end_date=2025-02-22 11:05:20.072662+00:00, run_duration=0.136711, state=success, executor_state=success, try_number=1, max_tries=1, job_id=123, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:18.567534+00:00, queued_by_job_id=7, pid=51250
2025-02-22 11:05:22,473 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-20T00:00:00+00:00, run_after=2024-03-21T00:00:00+00:00
2025-02-22 11:05:22,540 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-17 00:00:00+00:00: scheduled__2024-03-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:22,541 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-17 00:00:00+00:00, run_id=scheduled__2024-03-17T00:00:00+00:00, run_start_date=2025-02-22 11:05:10.666233+00:00, run_end_date=2025-02-22 11:05:22.541226+00:00, run_duration=11.874993, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-17 00:00:00+00:00, data_interval_end=2024-03-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:22,544 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-18T00:00:00+00:00, run_after=2024-03-19T00:00:00+00:00
2025-02-22 11:05:22,571 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:22,571 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:22,571 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:22,571 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:22,573 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:22,573 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:22,573 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:22,573 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:22,587 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:24,549 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:26,681 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:26,682 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:26,699 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:25.878220+00:00, run_end_date=2025-02-22 11:05:26.288858+00:00, run_duration=0.410638, state=success, executor_state=success, try_number=1, max_tries=1, job_id=126, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:22.571795+00:00, queued_by_job_id=7, pid=51317
2025-02-22 11:05:26,699 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:24.082895+00:00, run_end_date=2025-02-22 11:05:24.246292+00:00, run_duration=0.163397, state=success, executor_state=success, try_number=1, max_tries=1, job_id=125, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:22.571795+00:00, queued_by_job_id=7, pid=51296
2025-02-22 11:05:26,858 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-19T00:00:00+00:00, run_after=2024-03-20T00:00:00+00:00
2025-02-22 11:05:26,938 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:26,938 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:26,939 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:26,939 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:26,941 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:26,942 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:26,942 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:26,942 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:26,957 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:28,867 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:30,608 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:30,608 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:30,616 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:30.192076+00:00, run_end_date=2025-02-22 11:05:30.325136+00:00, run_duration=0.13306, state=success, executor_state=success, try_number=1, max_tries=1, job_id=128, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:26.939862+00:00, queued_by_job_id=7, pid=51356
2025-02-22 11:05:30,616 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:28.391452+00:00, run_end_date=2025-02-22 11:05:28.561116+00:00, run_duration=0.169664, state=success, executor_state=success, try_number=1, max_tries=1, job_id=127, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:26.939862+00:00, queued_by_job_id=7, pid=51337
2025-02-22 11:05:30,779 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-20T00:00:00+00:00, run_after=2024-03-21T00:00:00+00:00
2025-02-22 11:05:31,006 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:31,007 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:31,007 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:31,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:31,011 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:31,012 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:31,012 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:31,012 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:31,026 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:32,801 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:34,645 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:34,645 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:34,650 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:34.166505+00:00, run_end_date=2025-02-22 11:05:34.326938+00:00, run_duration=0.160433, state=success, executor_state=success, try_number=1, max_tries=1, job_id=130, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:31.008922+00:00, queued_by_job_id=7, pid=51394
2025-02-22 11:05:34,650 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:32.357687+00:00, run_end_date=2025-02-22 11:05:32.514064+00:00, run_duration=0.156377, state=success, executor_state=success, try_number=1, max_tries=1, job_id=129, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:31.008922+00:00, queued_by_job_id=7, pid=51376
2025-02-22 11:05:34,780 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-21T00:00:00+00:00, run_after=2024-03-22T00:00:00+00:00
2025-02-22 11:05:34,827 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-18 00:00:00+00:00: scheduled__2024-03-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:34,827 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-18 00:00:00+00:00, run_id=scheduled__2024-03-18T00:00:00+00:00, run_start_date=2025-02-22 11:05:18.514209+00:00, run_end_date=2025-02-22 11:05:34.827184+00:00, run_duration=16.312975, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-18 00:00:00+00:00, data_interval_end=2024-03-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:34,829 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-19T00:00:00+00:00, run_after=2024-03-20T00:00:00+00:00
2025-02-22 11:05:34,857 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:34,857 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:34,857 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:34,857 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:34,858 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:34,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:34,858 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:34,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:34,871 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:36,713 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:38,512 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:38,513 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:38,520 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:38.037102+00:00, run_end_date=2025-02-22 11:05:38.202968+00:00, run_duration=0.165866, state=success, executor_state=success, try_number=1, max_tries=1, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:34.857846+00:00, queued_by_job_id=7, pid=51449
2025-02-22 11:05:38,521 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:36.208297+00:00, run_end_date=2025-02-22 11:05:36.365168+00:00, run_duration=0.156871, state=success, executor_state=success, try_number=1, max_tries=1, job_id=131, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:34.857846+00:00, queued_by_job_id=7, pid=51431
2025-02-22 11:05:38,683 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-20T00:00:00+00:00, run_after=2024-03-21T00:00:00+00:00
2025-02-22 11:05:38,732 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-19 00:00:00+00:00: scheduled__2024-03-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:38,733 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-19 00:00:00+00:00, run_id=scheduled__2024-03-19T00:00:00+00:00, run_start_date=2025-02-22 11:05:22.505088+00:00, run_end_date=2025-02-22 11:05:38.733240+00:00, run_duration=16.228152, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-19 00:00:00+00:00, data_interval_end=2024-03-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:38,738 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-20T00:00:00+00:00, run_after=2024-03-21T00:00:00+00:00
2025-02-22 11:05:38,759 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:38,760 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:38,760 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:38,761 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:38,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:38,774 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:40,707 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:40,714 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:40.096115+00:00, run_end_date=2025-02-22 11:05:40.250038+00:00, run_duration=0.153923, state=success, executor_state=success, try_number=1, max_tries=1, job_id=133, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:38.760690+00:00, queued_by_job_id=7, pid=51469
2025-02-22 11:05:40,959 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-21T00:00:00+00:00, run_after=2024-03-22T00:00:00+00:00
2025-02-22 11:05:41,077 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:41,078 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:41,078 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:41,081 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:41,081 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:41,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:42,991 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:42,999 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:42.525977+00:00, run_end_date=2025-02-22 11:05:42.674901+00:00, run_duration=0.148924, state=success, executor_state=success, try_number=1, max_tries=1, job_id=134, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:41.079177+00:00, queued_by_job_id=7, pid=51489
2025-02-22 11:05:43,258 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-22T00:00:00+00:00, run_after=2024-03-23T00:00:00+00:00
2025-02-22 11:05:43,351 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:43,352 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:43,352 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:43,352 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:43,355 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:43,355 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:43,355 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:43,355 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:43,371 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:45,451 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:47,247 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:47,248 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:47,261 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:46.777867+00:00, run_end_date=2025-02-22 11:05:46.929257+00:00, run_duration=0.15139, state=success, executor_state=success, try_number=1, max_tries=1, job_id=136, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:43.353101+00:00, queued_by_job_id=7, pid=51529
2025-02-22 11:05:47,262 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:44.940761+00:00, run_end_date=2025-02-22 11:05:45.099926+00:00, run_duration=0.159165, state=success, executor_state=success, try_number=1, max_tries=1, job_id=135, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:43.353101+00:00, queued_by_job_id=7, pid=51510
2025-02-22 11:05:47,439 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-23T00:00:00+00:00, run_after=2024-03-24T00:00:00+00:00
2025-02-22 11:05:47,501 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-20 00:00:00+00:00: scheduled__2024-03-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:47,502 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-20 00:00:00+00:00, run_id=scheduled__2024-03-20T00:00:00+00:00, run_start_date=2025-02-22 11:05:34.802799+00:00, run_end_date=2025-02-22 11:05:47.502059+00:00, run_duration=12.69926, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-20 00:00:00+00:00, data_interval_end=2024-03-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:47,505 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-21T00:00:00+00:00, run_after=2024-03-22T00:00:00+00:00
2025-02-22 11:05:47,529 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:47,529 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:47,529 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:47,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:47,531 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:47,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:47,532 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:47,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:47,545 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:49,534 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:51,448 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:51,449 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:51,456 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:50.855102+00:00, run_end_date=2025-02-22 11:05:51.069927+00:00, run_duration=0.214825, state=success, executor_state=success, try_number=1, max_tries=1, job_id=138, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:47.530423+00:00, queued_by_job_id=7, pid=51568
2025-02-22 11:05:51,457 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:48.950493+00:00, run_end_date=2025-02-22 11:05:49.100220+00:00, run_duration=0.149727, state=success, executor_state=success, try_number=1, max_tries=1, job_id=137, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:47.530423+00:00, queued_by_job_id=7, pid=51549
2025-02-22 11:05:51,603 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-22T00:00:00+00:00, run_after=2024-03-23T00:00:00+00:00
2025-02-22 11:05:51,684 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:51,684 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:51,684 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:51,684 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:51,687 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:05:51,687 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:51,688 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:51,688 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:51,874 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:53,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:55,785 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:55,785 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:55,792 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:55.258301+00:00, run_end_date=2025-02-22 11:05:55.408336+00:00, run_duration=0.150035, state=success, executor_state=success, try_number=1, max_tries=1, job_id=140, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:51.685464+00:00, queued_by_job_id=7, pid=51607
2025-02-22 11:05:55,792 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:53.230556+00:00, run_end_date=2025-02-22 11:05:53.539903+00:00, run_duration=0.309347, state=success, executor_state=success, try_number=1, max_tries=1, job_id=139, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:05:51.685464+00:00, queued_by_job_id=7, pid=51589
2025-02-22 11:05:55,953 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-23T00:00:00+00:00, run_after=2024-03-24T00:00:00+00:00
2025-02-22 11:05:56,042 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:56,042 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:56,042 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:56,043 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:56,046 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:05:56,046 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:56,046 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:56,047 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:56,062 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:57,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:59,686 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:59,686 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:05:59,694 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:59.208701+00:00, run_end_date=2025-02-22 11:05:59.362229+00:00, run_duration=0.153528, state=success, executor_state=success, try_number=1, max_tries=1, job_id=142, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:56.043768+00:00, queued_by_job_id=7, pid=51655
2025-02-22 11:05:59,694 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:05:57.393429+00:00, run_end_date=2025-02-22 11:05:57.543622+00:00, run_duration=0.150193, state=success, executor_state=success, try_number=1, max_tries=1, job_id=141, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:05:56.043768+00:00, queued_by_job_id=7, pid=51628
2025-02-22 11:05:59,855 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
2025-02-22 11:05:59,914 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-21 00:00:00+00:00: scheduled__2024-03-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:05:59,915 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-21 00:00:00+00:00, run_id=scheduled__2024-03-21T00:00:00+00:00, run_start_date=2025-02-22 11:05:43.291237+00:00, run_end_date=2025-02-22 11:05:59.915098+00:00, run_duration=16.623861, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-21 00:00:00+00:00, data_interval_end=2024-03-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:05:59,918 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-22T00:00:00+00:00, run_after=2024-03-23T00:00:00+00:00
2025-02-22 11:05:59,942 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:59,942 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:05:59,942 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:05:59,942 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:05:59,944 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:05:59,944 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:59,944 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:05:59,944 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:05:59,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:01,765 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:03,554 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:03,554 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:03,562 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:03.089819+00:00, run_end_date=2025-02-22 11:06:03.259287+00:00, run_duration=0.169468, state=success, executor_state=success, try_number=1, max_tries=1, job_id=144, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:05:59.943119+00:00, queued_by_job_id=7, pid=51693
2025-02-22 11:06:03,562 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:01.291344+00:00, run_end_date=2025-02-22 11:06:01.460060+00:00, run_duration=0.168716, state=success, executor_state=success, try_number=1, max_tries=1, job_id=143, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:05:59.943119+00:00, queued_by_job_id=7, pid=51675
2025-02-22 11:06:03,727 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-23T00:00:00+00:00, run_after=2024-03-24T00:00:00+00:00
2025-02-22 11:06:03,784 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-22 00:00:00+00:00: scheduled__2024-03-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:03,784 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-22 00:00:00+00:00, run_id=scheduled__2024-03-22T00:00:00+00:00, run_start_date=2025-02-22 11:05:47.469205+00:00, run_end_date=2025-02-22 11:06:03.784529+00:00, run_duration=16.315324, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-22 00:00:00+00:00, data_interval_end=2024-03-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:03,790 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-23T00:00:00+00:00, run_after=2024-03-24T00:00:00+00:00
2025-02-22 11:06:03,812 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:03,813 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:03,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:03,814 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:03,815 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:03,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:05,708 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:05,715 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:05.199249+00:00, run_end_date=2025-02-22 11:06:05.356195+00:00, run_duration=0.156946, state=success, executor_state=success, try_number=1, max_tries=1, job_id=145, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:03.813660+00:00, queued_by_job_id=7, pid=51713
2025-02-22 11:06:05,851 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
2025-02-22 11:06:05,930 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:05,930 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:05,930 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:05,933 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:05,934 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:05,948 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:07,804 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:07,811 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:07.303534+00:00, run_end_date=2025-02-22 11:06:07.461748+00:00, run_duration=0.158214, state=success, executor_state=success, try_number=1, max_tries=1, job_id=146, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:05.931587+00:00, queued_by_job_id=7, pid=51733
2025-02-22 11:06:07,958 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-25T00:00:00+00:00, run_after=2024-03-26T00:00:00+00:00
2025-02-22 11:06:08,066 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:08,066 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:08,066 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:08,066 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:08,068 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:08,068 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:08,068 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:08,068 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:08,083 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:09,916 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:11,896 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:11,897 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:11,904 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:11.319820+00:00, run_end_date=2025-02-22 11:06:11.548582+00:00, run_duration=0.228762, state=success, executor_state=success, try_number=1, max_tries=1, job_id=148, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:08.066807+00:00, queued_by_job_id=7, pid=51788
2025-02-22 11:06:11,905 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:09.426354+00:00, run_end_date=2025-02-22 11:06:09.580266+00:00, run_duration=0.153912, state=success, executor_state=success, try_number=1, max_tries=1, job_id=147, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:08.066807+00:00, queued_by_job_id=7, pid=51753
2025-02-22 11:06:12,374 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-26T00:00:00+00:00, run_after=2024-03-27T00:00:00+00:00
2025-02-22 11:06:12,438 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-23 00:00:00+00:00: scheduled__2024-03-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:12,438 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-23 00:00:00+00:00, run_id=scheduled__2024-03-23T00:00:00+00:00, run_start_date=2025-02-22 11:05:59.882731+00:00, run_end_date=2025-02-22 11:06:12.438495+00:00, run_duration=12.555764, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-23 00:00:00+00:00, data_interval_end=2024-03-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:12,441 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
2025-02-22 11:06:12,468 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:12,469 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:12,469 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:12,469 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:12,470 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:12,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:12,471 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:12,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:12,487 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:14,329 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:16,119 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:16,120 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:16,127 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:15.647420+00:00, run_end_date=2025-02-22 11:06:15.795499+00:00, run_duration=0.148079, state=success, executor_state=success, try_number=1, max_tries=1, job_id=150, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:12.469608+00:00, queued_by_job_id=7, pid=51835
2025-02-22 11:06:16,127 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:13.844161+00:00, run_end_date=2025-02-22 11:06:14.008891+00:00, run_duration=0.16473, state=success, executor_state=success, try_number=1, max_tries=1, job_id=149, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:12.469608+00:00, queued_by_job_id=7, pid=51816
2025-02-22 11:06:16,572 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-25T00:00:00+00:00, run_after=2024-03-26T00:00:00+00:00
2025-02-22 11:06:16,652 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:16,653 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:16,653 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:16,653 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:16,656 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:16,656 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:16,656 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:16,657 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:16,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:18,528 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:20,446 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:20,446 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:20,453 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:19.921001+00:00, run_end_date=2025-02-22 11:06:20.110805+00:00, run_duration=0.189804, state=success, executor_state=success, try_number=1, max_tries=1, job_id=152, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:16.654225+00:00, queued_by_job_id=7, pid=51882
2025-02-22 11:06:20,454 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:17.991051+00:00, run_end_date=2025-02-22 11:06:18.154439+00:00, run_duration=0.163388, state=success, executor_state=success, try_number=1, max_tries=1, job_id=151, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:16.654225+00:00, queued_by_job_id=7, pid=51863
2025-02-22 11:06:20,925 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-27T00:00:00+00:00, run_after=2024-03-28T00:00:00+00:00
2025-02-22 11:06:21,010 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:21,010 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:21,010 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:21,010 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:06:21,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:21,012 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:21,012 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:21,012 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:21,012 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:21,013 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:21,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:21,031 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:22,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:24,692 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:26,504 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:26,504 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:26,505 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:26,512 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:26.024756+00:00, run_end_date=2025-02-22 11:06:26.174976+00:00, run_duration=0.15022, state=success, executor_state=success, try_number=1, max_tries=1, job_id=155, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:21.011042+00:00, queued_by_job_id=7, pid=51948
2025-02-22 11:06:26,512 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:24.203067+00:00, run_end_date=2025-02-22 11:06:24.362747+00:00, run_duration=0.15968, state=success, executor_state=success, try_number=1, max_tries=1, job_id=154, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:21.011042+00:00, queued_by_job_id=7, pid=51929
2025-02-22 11:06:26,513 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:22.391248+00:00, run_end_date=2025-02-22 11:06:22.540074+00:00, run_duration=0.148826, state=success, executor_state=success, try_number=1, max_tries=1, job_id=153, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:21.011042+00:00, queued_by_job_id=7, pid=51910
2025-02-22 11:06:26,684 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-28T00:00:00+00:00, run_after=2024-03-29T00:00:00+00:00
2025-02-22 11:06:26,774 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-24 00:00:00+00:00: scheduled__2024-03-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:26,775 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-24 00:00:00+00:00, run_id=scheduled__2024-03-24T00:00:00+00:00, run_start_date=2025-02-22 11:06:08.011181+00:00, run_end_date=2025-02-22 11:06:26.775198+00:00, run_duration=18.764017, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-24 00:00:00+00:00, data_interval_end=2024-03-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:26,779 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-25T00:00:00+00:00, run_after=2024-03-26T00:00:00+00:00
2025-02-22 11:06:26,804 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:26,804 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:26,805 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:26,805 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:06:26,805 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:26,806 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:26,806 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:26,806 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:26,806 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:26,807 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:26,807 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:26,821 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:28,602 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:30,421 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:32,381 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:32,382 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:32,382 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:32,390 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:31.901434+00:00, run_end_date=2025-02-22 11:06:32.071091+00:00, run_duration=0.169657, state=success, executor_state=success, try_number=1, max_tries=1, job_id=158, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:26.805478+00:00, queued_by_job_id=7, pid=52014
2025-02-22 11:06:32,391 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:29.941465+00:00, run_end_date=2025-02-22 11:06:30.088283+00:00, run_duration=0.146818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=157, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:26.805478+00:00, queued_by_job_id=7, pid=51988
2025-02-22 11:06:32,391 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:28.150406+00:00, run_end_date=2025-02-22 11:06:28.309160+00:00, run_duration=0.158754, state=success, executor_state=success, try_number=1, max_tries=1, job_id=156, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:26.805478+00:00, queued_by_job_id=7, pid=51968
2025-02-22 11:06:32,563 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-26T00:00:00+00:00, run_after=2024-03-27T00:00:00+00:00
2025-02-22 11:06:32,629 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-25 00:00:00+00:00: scheduled__2024-03-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:32,630 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-25 00:00:00+00:00, run_id=scheduled__2024-03-25T00:00:00+00:00, run_start_date=2025-02-22 11:06:12.401830+00:00, run_end_date=2025-02-22 11:06:32.630025+00:00, run_duration=20.228195, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-25 00:00:00+00:00, data_interval_end=2024-03-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:32,634 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-26T00:00:00+00:00, run_after=2024-03-27T00:00:00+00:00
2025-02-22 11:06:32,661 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:32,661 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:32,661 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:32,662 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:32,664 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:32,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:32,665 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:32,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:32,679 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:34,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:36,890 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:36,891 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:36,898 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:36.184438+00:00, run_end_date=2025-02-22 11:06:36.505454+00:00, run_duration=0.321016, state=success, executor_state=success, try_number=1, max_tries=1, job_id=160, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:32.662634+00:00, queued_by_job_id=7, pid=52056
2025-02-22 11:06:36,898 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:34.089609+00:00, run_end_date=2025-02-22 11:06:34.318206+00:00, run_duration=0.228597, state=success, executor_state=success, try_number=1, max_tries=1, job_id=159, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:32.662634+00:00, queued_by_job_id=7, pid=52035
2025-02-22 11:06:37,036 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-27T00:00:00+00:00, run_after=2024-03-28T00:00:00+00:00
2025-02-22 11:06:37,097 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:37,097 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:37,097 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:37,097 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:37,099 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:37,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:37,100 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:37,100 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:37,115 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:38,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:41,462 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:41,462 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:41,470 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:40.285308+00:00, run_end_date=2025-02-22 11:06:40.982564+00:00, run_duration=0.697256, state=success, executor_state=success, try_number=1, max_tries=1, job_id=162, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:37.098213+00:00, queued_by_job_id=7, pid=52104
2025-02-22 11:06:41,470 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:38.482843+00:00, run_end_date=2025-02-22 11:06:38.645036+00:00, run_duration=0.162193, state=success, executor_state=success, try_number=1, max_tries=1, job_id=161, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:37.098213+00:00, queued_by_job_id=7, pid=52082
2025-02-22 11:06:41,633 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-28T00:00:00+00:00, run_after=2024-03-29T00:00:00+00:00
2025-02-22 11:06:41,668 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-26 00:00:00+00:00: scheduled__2024-03-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:41,668 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-26 00:00:00+00:00, run_id=scheduled__2024-03-26T00:00:00+00:00, run_start_date=2025-02-22 11:06:20.953582+00:00, run_end_date=2025-02-22 11:06:41.668885+00:00, run_duration=20.715303, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-26 00:00:00+00:00, data_interval_end=2024-03-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:41,672 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-27T00:00:00+00:00, run_after=2024-03-28T00:00:00+00:00
2025-02-22 11:06:41,697 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:41,697 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:41,698 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:41,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:41,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:41,714 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:43,579 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:43,587 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:43.105338+00:00, run_end_date=2025-02-22 11:06:43.256656+00:00, run_duration=0.151318, state=success, executor_state=success, try_number=1, max_tries=1, job_id=163, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:41.698536+00:00, queued_by_job_id=7, pid=52133
2025-02-22 11:06:43,738 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-28T00:00:00+00:00, run_after=2024-03-29T00:00:00+00:00
2025-02-22 11:06:43,776 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-27 00:00:00+00:00: scheduled__2024-03-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:06:43,777 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-27 00:00:00+00:00, run_id=scheduled__2024-03-27T00:00:00+00:00, run_start_date=2025-02-22 11:06:26.712491+00:00, run_end_date=2025-02-22 11:06:43.777282+00:00, run_duration=17.064791, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-27 00:00:00+00:00, data_interval_end=2024-03-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:06:43,782 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-28T00:00:00+00:00, run_after=2024-03-29T00:00:00+00:00
2025-02-22 11:06:44,951 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-29T00:00:00+00:00, run_after=2024-03-30T00:00:00+00:00
2025-02-22 11:06:45,039 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:45,039 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:45,039 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:45,040 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:45,041 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:45,055 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:46,872 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:46,879 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:46.390443+00:00, run_end_date=2025-02-22 11:06:46.552532+00:00, run_duration=0.162089, state=success, executor_state=success, try_number=1, max_tries=1, job_id=164, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:45.039780+00:00, queued_by_job_id=7, pid=52162
2025-02-22 11:06:47,049 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-30T00:00:00+00:00, run_after=2024-03-31T00:00:00+00:00
2025-02-22 11:06:47,135 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:47,136 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:47,136 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:47,136 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:47,137 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:47,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:47,137 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:47,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:47,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:49,018 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:50,974 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:50,975 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:50,988 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:50.350156+00:00, run_end_date=2025-02-22 11:06:50.645819+00:00, run_duration=0.295663, state=success, executor_state=success, try_number=1, max_tries=1, job_id=166, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:47.136479+00:00, queued_by_job_id=7, pid=52201
2025-02-22 11:06:50,989 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:48.538273+00:00, run_end_date=2025-02-22 11:06:48.685934+00:00, run_duration=0.147661, state=success, executor_state=success, try_number=1, max_tries=1, job_id=165, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:47.136479+00:00, queued_by_job_id=7, pid=52182
2025-02-22 11:06:51,006 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:06:51,151 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-31T00:00:00+00:00, run_after=2024-04-01T00:00:00+00:00
2025-02-22 11:06:51,232 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:51,233 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:51,233 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:51,233 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:06:51,233 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:51,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:51,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:51,235 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:51,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:51,235 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:51,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:51,251 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:53,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:55,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:56,904 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:56,904 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:56,904 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:06:56,912 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:56.432546+00:00, run_end_date=2025-02-22 11:06:56.596099+00:00, run_duration=0.163553, state=success, executor_state=success, try_number=1, max_tries=1, job_id=169, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:51.233650+00:00, queued_by_job_id=7, pid=52260
2025-02-22 11:06:56,913 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:54.467800+00:00, run_end_date=2025-02-22 11:06:54.626466+00:00, run_duration=0.158666, state=success, executor_state=success, try_number=1, max_tries=1, job_id=168, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:51.233650+00:00, queued_by_job_id=7, pid=52240
2025-02-22 11:06:56,913 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:52.636971+00:00, run_end_date=2025-02-22 11:06:52.793695+00:00, run_duration=0.156724, state=success, executor_state=success, try_number=1, max_tries=1, job_id=167, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:51.233650+00:00, queued_by_job_id=7, pid=52221
2025-02-22 11:06:57,135 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-01T00:00:00+00:00, run_after=2024-04-02T00:00:00+00:00
2025-02-22 11:06:57,232 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:57,232 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:06:57,232 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:06:57,232 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:06:57,232 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:06:57,232 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:06:57,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-03-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:06:57,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:57,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:06:57,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:57,235 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:06:57,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:57,235 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:06:57,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:57,252 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:06:59,142 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:01,024 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:02,906 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:04,697 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-03-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:04,698 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:04,698 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:04,698 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:04,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:04.223807+00:00, run_end_date=2025-02-22 11:07:04.383155+00:00, run_duration=0.159348, state=success, executor_state=success, try_number=1, max_tries=1, job_id=173, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:06:57.233077+00:00, queued_by_job_id=7, pid=52337
2025-02-22 11:07:04,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:02.416531+00:00, run_end_date=2025-02-22 11:07:02.587622+00:00, run_duration=0.171091, state=success, executor_state=success, try_number=1, max_tries=1, job_id=172, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:06:57.233077+00:00, queued_by_job_id=7, pid=52317
2025-02-22 11:07:04,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:00.491431+00:00, run_end_date=2025-02-22 11:07:00.638214+00:00, run_duration=0.146783, state=success, executor_state=success, try_number=1, max_tries=1, job_id=171, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:06:57.233077+00:00, queued_by_job_id=7, pid=52299
2025-02-22 11:07:04,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-03-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:06:58.659250+00:00, run_end_date=2025-02-22 11:06:58.810523+00:00, run_duration=0.151273, state=success, executor_state=success, try_number=1, max_tries=1, job_id=170, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:06:57.233077+00:00, queued_by_job_id=7, pid=52279
2025-02-22 11:07:04,895 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-02T00:00:00+00:00, run_after=2024-04-03T00:00:00+00:00
2025-02-22 11:07:04,972 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-28 00:00:00+00:00: scheduled__2024-03-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:04,972 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-28 00:00:00+00:00, run_id=scheduled__2024-03-28T00:00:00+00:00, run_start_date=2025-02-22 11:06:44.980484+00:00, run_end_date=2025-02-22 11:07:04.972647+00:00, run_duration=19.992163, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-28 00:00:00+00:00, data_interval_end=2024-03-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:04,975 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-29T00:00:00+00:00, run_after=2024-03-30T00:00:00+00:00
2025-02-22 11:07:05,000 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:05,000 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:05,000 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:05,000 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:07:05,000 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:07:05,000 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:05,002 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:05,002 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:05,002 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-03-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:05,002 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:05,002 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:05,002 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:05,002 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:05,002 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:05,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:06,947 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:08,777 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:10,582 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:12,378 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:12,379 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-03-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:12,379 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:12,379 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:12,387 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:11.904030+00:00, run_end_date=2025-02-22 11:07:12.056782+00:00, run_duration=0.152752, state=success, executor_state=success, try_number=1, max_tries=1, job_id=177, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:05.000996+00:00, queued_by_job_id=7, pid=52421
2025-02-22 11:07:12,387 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:10.096779+00:00, run_end_date=2025-02-22 11:07:10.261578+00:00, run_duration=0.164799, state=success, executor_state=success, try_number=1, max_tries=1, job_id=176, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:05.000996+00:00, queued_by_job_id=7, pid=52402
2025-02-22 11:07:12,387 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-03-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:08.277426+00:00, run_end_date=2025-02-22 11:07:08.438189+00:00, run_duration=0.160763, state=success, executor_state=success, try_number=1, max_tries=1, job_id=175, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:05.000996+00:00, queued_by_job_id=7, pid=52384
2025-02-22 11:07:12,388 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:06.436130+00:00, run_end_date=2025-02-22 11:07:06.582789+00:00, run_duration=0.146659, state=success, executor_state=success, try_number=1, max_tries=1, job_id=174, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:05.000996+00:00, queued_by_job_id=7, pid=52365
2025-02-22 11:07:12,550 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-30T00:00:00+00:00, run_after=2024-03-31T00:00:00+00:00
2025-02-22 11:07:12,615 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-29 00:00:00+00:00: scheduled__2024-03-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:12,615 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-29 00:00:00+00:00, run_id=scheduled__2024-03-29T00:00:00+00:00, run_start_date=2025-02-22 11:06:47.082054+00:00, run_end_date=2025-02-22 11:07:12.615745+00:00, run_duration=25.533691, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-29 00:00:00+00:00, data_interval_end=2024-03-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:12,620 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-30T00:00:00+00:00, run_after=2024-03-31T00:00:00+00:00
2025-02-22 11:07:12,737 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:12,737 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:12,737 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:12,737 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:07:12,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:12,739 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:12,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:12,740 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-03-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:12,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:12,740 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:12,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:13,078 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:15,055 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:17,627 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:19,427 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:19,427 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-03-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:19,427 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:19,435 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:18.948232+00:00, run_end_date=2025-02-22 11:07:19.101235+00:00, run_duration=0.153003, state=success, executor_state=success, try_number=1, max_tries=1, job_id=180, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:12.738395+00:00, queued_by_job_id=7, pid=52504
2025-02-22 11:07:19,436 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-03-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:16.451922+00:00, run_end_date=2025-02-22 11:07:17.327398+00:00, run_duration=0.875476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=179, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:12.738395+00:00, queued_by_job_id=7, pid=52469
2025-02-22 11:07:19,436 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:14.516864+00:00, run_end_date=2025-02-22 11:07:14.666965+00:00, run_duration=0.150101, state=success, executor_state=success, try_number=1, max_tries=1, job_id=178, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:12.738395+00:00, queued_by_job_id=7, pid=52444
2025-02-22 11:07:19,788 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-31T00:00:00+00:00, run_after=2024-04-01T00:00:00+00:00
2025-02-22 11:07:19,850 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-30 00:00:00+00:00: scheduled__2024-03-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:19,850 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-30 00:00:00+00:00, run_id=scheduled__2024-03-30T00:00:00+00:00, run_start_date=2025-02-22 11:06:51.176554+00:00, run_end_date=2025-02-22 11:07:19.850631+00:00, run_duration=28.674077, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-30 00:00:00+00:00, data_interval_end=2024-03-31 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:19,853 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-03-31T00:00:00+00:00, run_after=2024-04-01T00:00:00+00:00
2025-02-22 11:07:19,878 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T11:07:15+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:19,878 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:19,878 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:19,878 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:07:19,879 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs manual__2025-02-22T11:07:15+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-03-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:19,880 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='manual__2025-02-22T11:07:15+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:19,880 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:19,881 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:19,881 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:19,881 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-03-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:19,881 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:19,895 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:21,689 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:23,492 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-03-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:25,299 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=manual__2025-02-22T11:07:15+00:00 exited with status success for try_number 1
2025-02-22 11:07:25,299 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:25,299 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-03-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:25,307 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-03-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:24.843442+00:00, run_end_date=2025-02-22 11:07:24.988948+00:00, run_duration=0.145506, state=success, executor_state=success, try_number=1, max_tries=1, job_id=183, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:19.879411+00:00, queued_by_job_id=7, pid=52562
2025-02-22 11:07:25,307 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:23.027367+00:00, run_end_date=2025-02-22 11:07:23.177614+00:00, run_duration=0.150247, state=success, executor_state=success, try_number=1, max_tries=1, job_id=182, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:19.879411+00:00, queued_by_job_id=7, pid=52543
2025-02-22 11:07:25,307 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=manual__2025-02-22T11:07:15+00:00, map_index=-1, run_start_date=2025-02-22 11:07:21.222335+00:00, run_end_date=2025-02-22 11:07:21.371183+00:00, run_duration=0.148848, state=success, executor_state=success, try_number=1, max_tries=1, job_id=181, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:19.879411+00:00, queued_by_job_id=7, pid=52525
2025-02-22 11:07:25,472 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-01T00:00:00+00:00, run_after=2024-04-02T00:00:00+00:00
2025-02-22 11:07:25,528 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-03-31 00:00:00+00:00: scheduled__2024-03-31T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:25,528 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-03-31 00:00:00+00:00, run_id=scheduled__2024-03-31T00:00:00+00:00, run_start_date=2025-02-22 11:06:57.163385+00:00, run_end_date=2025-02-22 11:07:25.528688+00:00, run_duration=28.365303, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-03-31 00:00:00+00:00, data_interval_end=2024-04-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:25,533 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-01T00:00:00+00:00, run_after=2024-04-02T00:00:00+00:00
2025-02-22 11:07:25,556 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T11:07:15+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:25,556 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:25,556 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:25,556 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db manual__2025-02-22T11:07:15+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:25,558 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='manual__2025-02-22T11:07:15+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:25,558 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:25,559 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:25,559 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:25,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:27,390 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:29,178 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=manual__2025-02-22T11:07:15+00:00 exited with status success for try_number 1
2025-02-22 11:07:29,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:29,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:28.705925+00:00, run_end_date=2025-02-22 11:07:28.871353+00:00, run_duration=0.165428, state=success, executor_state=success, try_number=1, max_tries=1, job_id=185, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:25.557311+00:00, queued_by_job_id=7, pid=52600
2025-02-22 11:07:29,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=manual__2025-02-22T11:07:15+00:00, map_index=-1, run_start_date=2025-02-22 11:07:26.909015+00:00, run_end_date=2025-02-22 11:07:27.074037+00:00, run_duration=0.165022, state=success, executor_state=success, try_number=1, max_tries=1, job_id=184, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:25.557311+00:00, queued_by_job_id=7, pid=52582
2025-02-22 11:07:29,321 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-02T00:00:00+00:00, run_after=2024-04-03T00:00:00+00:00
2025-02-22 11:07:29,373 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-01 00:00:00+00:00: scheduled__2024-04-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:29,373 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-01 00:00:00+00:00, run_id=scheduled__2024-04-01T00:00:00+00:00, run_start_date=2025-02-22 11:07:04.928738+00:00, run_end_date=2025-02-22 11:07:29.373630+00:00, run_duration=24.444892, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-01 00:00:00+00:00, data_interval_end=2024-04-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:29,379 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-02T00:00:00+00:00, run_after=2024-04-03T00:00:00+00:00
2025-02-22 11:07:29,404 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T11:07:15+00:00 [scheduled]>
2025-02-22 11:07:29,404 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:29,404 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier manual__2025-02-22T11:07:15+00:00 [scheduled]>
2025-02-22 11:07:29,407 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='manual__2025-02-22T11:07:15+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:29,407 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:29,422 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:31,204 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=manual__2025-02-22T11:07:15+00:00 exited with status success for try_number 1
2025-02-22 11:07:31,212 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=manual__2025-02-22T11:07:15+00:00, map_index=-1, run_start_date=2025-02-22 11:07:30.741656+00:00, run_end_date=2025-02-22 11:07:30.889786+00:00, run_duration=0.14813, state=success, executor_state=success, try_number=1, max_tries=1, job_id=186, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:29.405551+00:00, queued_by_job_id=7, pid=52621
2025-02-22 11:07:31,385 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-03T00:00:00+00:00, run_after=2024-04-04T00:00:00+00:00
2025-02-22 11:07:31,466 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T11:07:15+00:00 [scheduled]>
2025-02-22 11:07:31,466 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:31,467 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:31,467 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars manual__2025-02-22T11:07:15+00:00 [scheduled]>
2025-02-22 11:07:31,468 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:31,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:31,469 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='manual__2025-02-22T11:07:15+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:31,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:31,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:33,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'manual__2025-02-22T11:07:15+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:35,094 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:35,095 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=manual__2025-02-22T11:07:15+00:00 exited with status success for try_number 1
2025-02-22 11:07:35,102 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=manual__2025-02-22T11:07:15+00:00, map_index=-1, run_start_date=2025-02-22 11:07:34.627030+00:00, run_end_date=2025-02-22 11:07:34.781831+00:00, run_duration=0.154801, state=success, executor_state=success, try_number=1, max_tries=1, job_id=188, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:31.467446+00:00, queued_by_job_id=7, pid=52660
2025-02-22 11:07:35,103 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:32.820768+00:00, run_end_date=2025-02-22 11:07:32.972970+00:00, run_duration=0.152202, state=success, executor_state=success, try_number=1, max_tries=1, job_id=187, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:31.467446+00:00, queued_by_job_id=7, pid=52641
2025-02-22 11:07:35,263 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-04T00:00:00+00:00, run_after=2024-04-05T00:00:00+00:00
2025-02-22 11:07:35,329 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2025-02-22 11:07:15+00:00: manual__2025-02-22T11:07:15+00:00, externally triggered: True> successful
2025-02-22 11:07:35,329 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2025-02-22 11:07:15+00:00, run_id=manual__2025-02-22T11:07:15+00:00, run_start_date=2025-02-22 11:07:19.811278+00:00, run_end_date=2025-02-22 11:07:35.329291+00:00, run_duration=15.518013, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-02-21 00:00:00+00:00, data_interval_end=2025-02-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:35,332 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2025-02-22T00:00:00+00:00, run_after=2025-02-23T00:00:00+00:00
2025-02-22 11:07:35,356 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:35,356 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:35,356 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:35,356 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:35,358 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:35,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:35,358 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:35,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:35,371 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:37,240 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:39,071 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:39,072 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:39,080 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:38.552152+00:00, run_end_date=2025-02-22 11:07:38.710859+00:00, run_duration=0.158707, state=success, executor_state=success, try_number=1, max_tries=1, job_id=190, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:35.357110+00:00, queued_by_job_id=7, pid=52699
2025-02-22 11:07:39,080 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:36.698963+00:00, run_end_date=2025-02-22 11:07:36.857792+00:00, run_duration=0.158829, state=success, executor_state=success, try_number=1, max_tries=1, job_id=189, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:35.357110+00:00, queued_by_job_id=7, pid=52680
2025-02-22 11:07:39,301 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:39,301 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:39,301 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:39,301 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:39,303 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:39,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:39,304 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:39,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:39,317 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:41,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:43,025 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:43,026 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:43,033 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:42.516188+00:00, run_end_date=2025-02-22 11:07:42.668299+00:00, run_duration=0.152111, state=success, executor_state=success, try_number=1, max_tries=1, job_id=192, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:39.302215+00:00, queued_by_job_id=7, pid=52746
2025-02-22 11:07:43,033 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:40.693778+00:00, run_end_date=2025-02-22 11:07:40.836481+00:00, run_duration=0.142703, state=success, executor_state=success, try_number=1, max_tries=1, job_id=191, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:39.302215+00:00, queued_by_job_id=7, pid=52726
2025-02-22 11:07:43,237 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:43,237 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:43,237 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:43,237 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:43,240 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:43,240 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:43,241 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:43,241 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:43,255 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:45,729 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:47,785 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:47,785 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:47,793 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:47.186536+00:00, run_end_date=2025-02-22 11:07:47.418350+00:00, run_duration=0.231814, state=success, executor_state=success, try_number=1, max_tries=1, job_id=194, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:43.238532+00:00, queued_by_job_id=7, pid=52785
2025-02-22 11:07:47,793 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:44.605570+00:00, run_end_date=2025-02-22 11:07:44.827599+00:00, run_duration=0.222029, state=success, executor_state=success, try_number=1, max_tries=1, job_id=193, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:43.238532+00:00, queued_by_job_id=7, pid=52765
2025-02-22 11:07:47,985 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-02 00:00:00+00:00: scheduled__2024-04-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:47,986 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-02 00:00:00+00:00, run_id=scheduled__2024-04-02T00:00:00+00:00, run_start_date=2025-02-22 11:07:31.411787+00:00, run_end_date=2025-02-22 11:07:47.986330+00:00, run_duration=16.574543, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-02 00:00:00+00:00, data_interval_end=2024-04-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:47,992 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-03T00:00:00+00:00, run_after=2024-04-04T00:00:00+00:00
2025-02-22 11:07:48,017 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:48,017 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:48,017 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:48,019 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:07:48,019 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:48,033 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:49,914 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:49,921 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:49.437593+00:00, run_end_date=2025-02-22 11:07:49.597508+00:00, run_duration=0.159915, state=success, executor_state=success, try_number=1, max_tries=1, job_id=195, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:07:48.017820+00:00, queued_by_job_id=7, pid=52805
2025-02-22 11:07:50,155 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-04T00:00:00+00:00, run_after=2024-04-05T00:00:00+00:00
2025-02-22 11:07:50,195 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-03 00:00:00+00:00: scheduled__2024-04-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:07:50,195 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-03 00:00:00+00:00, run_id=scheduled__2024-04-03T00:00:00+00:00, run_start_date=2025-02-22 11:07:35.293485+00:00, run_end_date=2025-02-22 11:07:50.195848+00:00, run_duration=14.902363, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-03 00:00:00+00:00, data_interval_end=2024-04-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:07:50,201 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-04T00:00:00+00:00, run_after=2024-04-05T00:00:00+00:00
2025-02-22 11:07:51,564 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-05T00:00:00+00:00, run_after=2024-04-06T00:00:00+00:00
2025-02-22 11:07:51,636 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:51,636 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:51,636 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:51,637 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:51,638 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:51,652 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:53,435 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:53,443 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:52.971107+00:00, run_end_date=2025-02-22 11:07:53.151695+00:00, run_duration=0.180588, state=success, executor_state=success, try_number=1, max_tries=1, job_id=196, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:51.636873+00:00, queued_by_job_id=7, pid=52843
2025-02-22 11:07:53,621 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-06T00:00:00+00:00, run_after=2024-04-07T00:00:00+00:00
2025-02-22 11:07:53,710 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:53,710 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:53,710 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:53,711 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:53,712 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:53,712 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:53,713 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:53,713 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:53,726 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:55,576 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:57,516 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:57,517 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:07:57,524 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:56.907091+00:00, run_end_date=2025-02-22 11:07:57.136452+00:00, run_duration=0.229361, state=success, executor_state=success, try_number=1, max_tries=1, job_id=198, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:53.711427+00:00, queued_by_job_id=7, pid=52881
2025-02-22 11:07:57,525 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:55.054578+00:00, run_end_date=2025-02-22 11:07:55.225920+00:00, run_duration=0.171342, state=success, executor_state=success, try_number=1, max_tries=1, job_id=197, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:53.711427+00:00, queued_by_job_id=7, pid=52862
2025-02-22 11:07:57,668 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-07T00:00:00+00:00, run_after=2024-04-08T00:00:00+00:00
2025-02-22 11:07:57,759 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:57,759 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:07:57,760 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:07:57,760 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:07:57,760 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:07:57,761 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:07:57,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:57,762 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:07:57,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:57,762 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:07:57,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:57,780 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:07:59,577 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:01,404 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:03,194 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:03,194 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:03,195 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:03,202 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:02.708362+00:00, run_end_date=2025-02-22 11:08:02.892435+00:00, run_duration=0.184073, state=success, executor_state=success, try_number=1, max_tries=1, job_id=201, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:07:57.760614+00:00, queued_by_job_id=7, pid=52939
2025-02-22 11:08:03,203 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:00.911223+00:00, run_end_date=2025-02-22 11:08:01.053349+00:00, run_duration=0.142126, state=success, executor_state=success, try_number=1, max_tries=1, job_id=200, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:07:57.760614+00:00, queued_by_job_id=7, pid=52921
2025-02-22 11:08:03,203 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:07:59.101613+00:00, run_end_date=2025-02-22 11:07:59.256387+00:00, run_duration=0.154774, state=success, executor_state=success, try_number=1, max_tries=1, job_id=199, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:07:57.760614+00:00, queued_by_job_id=7, pid=52901
2025-02-22 11:08:03,456 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-08T00:00:00+00:00, run_after=2024-04-09T00:00:00+00:00
2025-02-22 11:08:03,649 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:03,650 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:03,650 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:03,650 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:03,650 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:08:03,651 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:03,654 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:03,654 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:03,655 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:03,655 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:03,655 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:03,655 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:03,656 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:03,656 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:03,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:05,579 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:07,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:09,390 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:11,185 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:11,185 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:11,185 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:11,186 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:11,193 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:10.755702+00:00, run_end_date=2025-02-22 11:08:10.909282+00:00, run_duration=0.15358, state=success, executor_state=success, try_number=1, max_tries=1, job_id=205, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:03.651786+00:00, queued_by_job_id=7, pid=53025
2025-02-22 11:08:11,194 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:08.789627+00:00, run_end_date=2025-02-22 11:08:08.999859+00:00, run_duration=0.210232, state=success, executor_state=success, try_number=1, max_tries=1, job_id=204, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:03.651786+00:00, queued_by_job_id=7, pid=53000
2025-02-22 11:08:11,194 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:06.894087+00:00, run_end_date=2025-02-22 11:08:07.044662+00:00, run_duration=0.150575, state=success, executor_state=success, try_number=1, max_tries=1, job_id=203, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:03.651786+00:00, queued_by_job_id=7, pid=52979
2025-02-22 11:08:11,194 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:05.043546+00:00, run_end_date=2025-02-22 11:08:05.204315+00:00, run_duration=0.160769, state=success, executor_state=success, try_number=1, max_tries=1, job_id=202, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:03.651786+00:00, queued_by_job_id=7, pid=52960
2025-02-22 11:08:11,388 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-09T00:00:00+00:00, run_after=2024-04-10T00:00:00+00:00
2025-02-22 11:08:11,460 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-04 00:00:00+00:00: scheduled__2024-04-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:11,461 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-04 00:00:00+00:00, run_id=scheduled__2024-04-04T00:00:00+00:00, run_start_date=2025-02-22 11:07:51.587774+00:00, run_end_date=2025-02-22 11:08:11.461137+00:00, run_duration=19.873363, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-04 00:00:00+00:00, data_interval_end=2024-04-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:11,464 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-05T00:00:00+00:00, run_after=2024-04-06T00:00:00+00:00
2025-02-22 11:08:11,489 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:11,489 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:11,489 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:11,489 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:11,489 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:08:11,490 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:11,491 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:11,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:11,492 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:11,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:11,492 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:11,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:11,492 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:11,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:11,506 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:13,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:15,158 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:16,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:18,825 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:18,826 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:18,826 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:18,827 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:18,840 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:18.347297+00:00, run_end_date=2025-02-22 11:08:18.497040+00:00, run_duration=0.149743, state=success, executor_state=success, try_number=1, max_tries=1, job_id=209, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:11.490352+00:00, queued_by_job_id=7, pid=53109
2025-02-22 11:08:18,841 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:16.471804+00:00, run_end_date=2025-02-22 11:08:16.625167+00:00, run_duration=0.153363, state=success, executor_state=success, try_number=1, max_tries=1, job_id=208, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:11.490352+00:00, queued_by_job_id=7, pid=53090
2025-02-22 11:08:18,841 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:14.651941+00:00, run_end_date=2025-02-22 11:08:14.813230+00:00, run_duration=0.161289, state=success, executor_state=success, try_number=1, max_tries=1, job_id=207, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:11.490352+00:00, queued_by_job_id=7, pid=53071
2025-02-22 11:08:18,841 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:12.832531+00:00, run_end_date=2025-02-22 11:08:12.995931+00:00, run_duration=0.1634, state=success, executor_state=success, try_number=1, max_tries=1, job_id=206, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:11.490352+00:00, queued_by_job_id=7, pid=53052
2025-02-22 11:08:19,016 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-06T00:00:00+00:00, run_after=2024-04-07T00:00:00+00:00
2025-02-22 11:08:19,082 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-05 00:00:00+00:00: scheduled__2024-04-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:19,083 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-05 00:00:00+00:00, run_id=scheduled__2024-04-05T00:00:00+00:00, run_start_date=2025-02-22 11:07:53.648396+00:00, run_end_date=2025-02-22 11:08:19.083307+00:00, run_duration=25.434911, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-05 00:00:00+00:00, data_interval_end=2024-04-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:19,087 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-06T00:00:00+00:00, run_after=2024-04-07T00:00:00+00:00
2025-02-22 11:08:19,113 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:19,113 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:19,113 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:19,113 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:19,113 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:19,115 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:19,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:19,116 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:19,116 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:19,116 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:19,116 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:19,130 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:20,931 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:22,705 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:24,551 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:24,551 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:24,551 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:24,557 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:24.083479+00:00, run_end_date=2025-02-22 11:08:24.237823+00:00, run_duration=0.154344, state=success, executor_state=success, try_number=1, max_tries=1, job_id=212, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:19.114073+00:00, queued_by_job_id=7, pid=53182
2025-02-22 11:08:24,557 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:22.252989+00:00, run_end_date=2025-02-22 11:08:22.397384+00:00, run_duration=0.144395, state=success, executor_state=success, try_number=1, max_tries=1, job_id=211, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:19.114073+00:00, queued_by_job_id=7, pid=53156
2025-02-22 11:08:24,557 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:20.453585+00:00, run_end_date=2025-02-22 11:08:20.609023+00:00, run_duration=0.155438, state=success, executor_state=success, try_number=1, max_tries=1, job_id=210, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:19.114073+00:00, queued_by_job_id=7, pid=53129
2025-02-22 11:08:24,717 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-07T00:00:00+00:00, run_after=2024-04-08T00:00:00+00:00
2025-02-22 11:08:24,778 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-06 00:00:00+00:00: scheduled__2024-04-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:24,779 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-06 00:00:00+00:00, run_id=scheduled__2024-04-06T00:00:00+00:00, run_start_date=2025-02-22 11:07:57.699614+00:00, run_end_date=2025-02-22 11:08:24.779106+00:00, run_duration=27.079492, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-06 00:00:00+00:00, data_interval_end=2024-04-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:24,784 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-07T00:00:00+00:00, run_after=2024-04-08T00:00:00+00:00
2025-02-22 11:08:24,806 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:24,807 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:24,807 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:24,807 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:24,809 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:24,809 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:24,809 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:24,809 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:24,823 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:26,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:28,590 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:28,591 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:28,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:28.098658+00:00, run_end_date=2025-02-22 11:08:28.247175+00:00, run_duration=0.148517, state=success, executor_state=success, try_number=1, max_tries=1, job_id=214, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:24.807738+00:00, queued_by_job_id=7, pid=53221
2025-02-22 11:08:28,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:26.189990+00:00, run_end_date=2025-02-22 11:08:26.417154+00:00, run_duration=0.227164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=213, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:24.807738+00:00, queued_by_job_id=7, pid=53202
2025-02-22 11:08:28,733 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-08T00:00:00+00:00, run_after=2024-04-09T00:00:00+00:00
2025-02-22 11:08:28,818 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-07 00:00:00+00:00: scheduled__2024-04-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:28,818 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-07 00:00:00+00:00, run_id=scheduled__2024-04-07T00:00:00+00:00, run_start_date=2025-02-22 11:08:03.483599+00:00, run_end_date=2025-02-22 11:08:28.818695+00:00, run_duration=25.335096, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-07 00:00:00+00:00, data_interval_end=2024-04-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:28,825 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-08T00:00:00+00:00, run_after=2024-04-09T00:00:00+00:00
2025-02-22 11:08:28,855 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:28,855 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:28,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:28,858 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:28,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:28,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:30,868 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:30,875 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:30.274084+00:00, run_end_date=2025-02-22 11:08:30.524930+00:00, run_duration=0.250846, state=success, executor_state=success, try_number=1, max_tries=1, job_id=215, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:28.856568+00:00, queued_by_job_id=7, pid=53241
2025-02-22 11:08:31,340 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-09T00:00:00+00:00, run_after=2024-04-10T00:00:00+00:00
2025-02-22 11:08:31,371 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-08 00:00:00+00:00: scheduled__2024-04-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:31,372 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-08 00:00:00+00:00, run_id=scheduled__2024-04-08T00:00:00+00:00, run_start_date=2025-02-22 11:08:11.416107+00:00, run_end_date=2025-02-22 11:08:31.372041+00:00, run_duration=19.955934, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-08 00:00:00+00:00, data_interval_end=2024-04-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:31,375 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-09T00:00:00+00:00, run_after=2024-04-10T00:00:00+00:00
2025-02-22 11:08:32,844 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-10T00:00:00+00:00, run_after=2024-04-11T00:00:00+00:00
2025-02-22 11:08:33,065 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:33,065 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:33,065 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:33,066 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:33,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:33,078 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:34,938 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:34,946 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:34.433449+00:00, run_end_date=2025-02-22 11:08:34.586422+00:00, run_duration=0.152973, state=success, executor_state=success, try_number=1, max_tries=1, job_id=216, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:33.065605+00:00, queued_by_job_id=7, pid=53280
2025-02-22 11:08:35,395 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-11T00:00:00+00:00, run_after=2024-04-12T00:00:00+00:00
2025-02-22 11:08:35,470 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:35,470 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:35,470 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:35,470 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:35,472 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:35,472 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:35,472 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:35,473 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:35,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:37,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:39,138 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:39,138 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:39,146 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:38.667861+00:00, run_end_date=2025-02-22 11:08:38.828301+00:00, run_duration=0.16044, state=success, executor_state=success, try_number=1, max_tries=1, job_id=218, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:35.471310+00:00, queued_by_job_id=7, pid=53327
2025-02-22 11:08:39,146 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:36.874480+00:00, run_end_date=2025-02-22 11:08:37.041601+00:00, run_duration=0.167121, state=success, executor_state=success, try_number=1, max_tries=1, job_id=217, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:35.471310+00:00, queued_by_job_id=7, pid=53308
2025-02-22 11:08:39,312 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-12T00:00:00+00:00, run_after=2024-04-13T00:00:00+00:00
2025-02-22 11:08:39,407 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:39,407 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:39,407 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:39,407 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:39,408 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:39,409 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:39,409 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:39,410 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:39,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:39,410 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:39,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:39,425 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:41,217 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:43,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:44,817 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:44,817 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:44,817 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:44,825 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:44.349002+00:00, run_end_date=2025-02-22 11:08:44.508252+00:00, run_duration=0.15925, state=success, executor_state=success, try_number=1, max_tries=1, job_id=221, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:39.408361+00:00, queued_by_job_id=7, pid=53385
2025-02-22 11:08:44,825 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:42.532922+00:00, run_end_date=2025-02-22 11:08:42.687877+00:00, run_duration=0.154955, state=success, executor_state=success, try_number=1, max_tries=1, job_id=220, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:39.408361+00:00, queued_by_job_id=7, pid=53366
2025-02-22 11:08:44,825 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:40.763253+00:00, run_end_date=2025-02-22 11:08:40.919271+00:00, run_duration=0.156018, state=success, executor_state=success, try_number=1, max_tries=1, job_id=219, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:39.408361+00:00, queued_by_job_id=7, pid=53347
2025-02-22 11:08:45,011 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-13T00:00:00+00:00, run_after=2024-04-14T00:00:00+00:00
2025-02-22 11:08:45,107 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:45,107 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:45,107 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:45,107 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:45,107 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:08:45,107 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:45,110 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:45,110 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:45,110 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:45,110 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:45,111 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:45,111 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:45,111 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:45,111 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:45,126 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:46,939 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:48,772 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:50,916 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:52,945 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:52,945 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:52,945 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:52,946 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:08:52,953 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:52.378167+00:00, run_end_date=2025-02-22 11:08:52.608992+00:00, run_duration=0.230825, state=success, executor_state=success, try_number=1, max_tries=1, job_id=225, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:45.108370+00:00, queued_by_job_id=7, pid=53471
2025-02-22 11:08:52,954 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:50.136626+00:00, run_end_date=2025-02-22 11:08:50.513706+00:00, run_duration=0.37708, state=success, executor_state=success, try_number=1, max_tries=1, job_id=224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:45.108370+00:00, queued_by_job_id=7, pid=53450
2025-02-22 11:08:52,954 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:48.288503+00:00, run_end_date=2025-02-22 11:08:48.436113+00:00, run_duration=0.14761, state=success, executor_state=success, try_number=1, max_tries=1, job_id=223, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:45.108370+00:00, queued_by_job_id=7, pid=53432
2025-02-22 11:08:52,954 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:46.466981+00:00, run_end_date=2025-02-22 11:08:46.613230+00:00, run_duration=0.146249, state=success, executor_state=success, try_number=1, max_tries=1, job_id=222, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:45.108370+00:00, queued_by_job_id=7, pid=53413
2025-02-22 11:08:53,135 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-14T00:00:00+00:00, run_after=2024-04-15T00:00:00+00:00
2025-02-22 11:08:53,201 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-09 00:00:00+00:00: scheduled__2024-04-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:08:53,201 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-09 00:00:00+00:00, run_id=scheduled__2024-04-09T00:00:00+00:00, run_start_date=2025-02-22 11:08:33.008603+00:00, run_end_date=2025-02-22 11:08:53.201751+00:00, run_duration=20.193148, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-09 00:00:00+00:00, data_interval_end=2024-04-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:08:53,204 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-10T00:00:00+00:00, run_after=2024-04-11T00:00:00+00:00
2025-02-22 11:08:53,231 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:53,231 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:08:53,231 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:08:53,231 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:08:53,232 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:08:53,232 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:08:53,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:08:53,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:53,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:08:53,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:53,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:08:53,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:53,234 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:08:53,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:53,249 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:55,068 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:56,885 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:08:58,730 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:00,533 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:00,533 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:00,533 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:00,533 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:00,541 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:00.068016+00:00, run_end_date=2025-02-22 11:09:00.225068+00:00, run_duration=0.157052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=229, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:08:53.232519+00:00, queued_by_job_id=7, pid=53563
2025-02-22 11:09:00,541 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:58.216670+00:00, run_end_date=2025-02-22 11:08:58.370375+00:00, run_duration=0.153705, state=success, executor_state=success, try_number=1, max_tries=1, job_id=228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:08:53.232519+00:00, queued_by_job_id=7, pid=53544
2025-02-22 11:09:00,542 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:56.415340+00:00, run_end_date=2025-02-22 11:08:56.583751+00:00, run_duration=0.168411, state=success, executor_state=success, try_number=1, max_tries=1, job_id=227, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:08:53.232519+00:00, queued_by_job_id=7, pid=53526
2025-02-22 11:09:00,542 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:08:54.576554+00:00, run_end_date=2025-02-22 11:08:54.732560+00:00, run_duration=0.156006, state=success, executor_state=success, try_number=1, max_tries=1, job_id=226, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:08:53.232519+00:00, queued_by_job_id=7, pid=53492
2025-02-22 11:09:00,703 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-11T00:00:00+00:00, run_after=2024-04-12T00:00:00+00:00
2025-02-22 11:09:00,775 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-10 00:00:00+00:00: scheduled__2024-04-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:00,775 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-10 00:00:00+00:00, run_id=scheduled__2024-04-10T00:00:00+00:00, run_start_date=2025-02-22 11:08:35.420305+00:00, run_end_date=2025-02-22 11:09:00.775545+00:00, run_duration=25.35524, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-10 00:00:00+00:00, data_interval_end=2024-04-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:00,780 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-11T00:00:00+00:00, run_after=2024-04-12T00:00:00+00:00
2025-02-22 11:09:00,808 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:00,808 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:00,808 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:00,808 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:09:00,808 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:00,811 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:00,811 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:00,812 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:00,812 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:00,812 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:00,812 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:00,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:02,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:04,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:06,366 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:06,366 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:06,366 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:06,374 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:05.892863+00:00, run_end_date=2025-02-22 11:09:06.039542+00:00, run_duration=0.146679, state=success, executor_state=success, try_number=1, max_tries=1, job_id=232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:00.809335+00:00, queued_by_job_id=7, pid=53621
2025-02-22 11:09:06,374 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:04.008973+00:00, run_end_date=2025-02-22 11:09:04.158349+00:00, run_duration=0.149376, state=success, executor_state=success, try_number=1, max_tries=1, job_id=231, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:00.809335+00:00, queued_by_job_id=7, pid=53603
2025-02-22 11:09:06,374 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:02.180036+00:00, run_end_date=2025-02-22 11:09:02.329527+00:00, run_duration=0.149491, state=success, executor_state=success, try_number=1, max_tries=1, job_id=230, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:00.809335+00:00, queued_by_job_id=7, pid=53584
2025-02-22 11:09:06,541 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-12T00:00:00+00:00, run_after=2024-04-13T00:00:00+00:00
2025-02-22 11:09:06,578 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-11 00:00:00+00:00: scheduled__2024-04-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:06,578 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-11 00:00:00+00:00, run_id=scheduled__2024-04-11T00:00:00+00:00, run_start_date=2025-02-22 11:08:39.344716+00:00, run_end_date=2025-02-22 11:09:06.578590+00:00, run_duration=27.233874, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-11 00:00:00+00:00, data_interval_end=2024-04-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:06,581 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-12T00:00:00+00:00, run_after=2024-04-13T00:00:00+00:00
2025-02-22 11:09:06,603 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:06,603 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:06,603 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:06,603 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:06,605 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:06,605 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:06,605 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:06,605 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:06,618 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:08,428 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:10,259 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:10,259 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:10,267 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:09.756609+00:00, run_end_date=2025-02-22 11:09:09.905593+00:00, run_duration=0.148984, state=success, executor_state=success, try_number=1, max_tries=1, job_id=234, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:06.603746+00:00, queued_by_job_id=7, pid=53660
2025-02-22 11:09:10,267 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:07.947573+00:00, run_end_date=2025-02-22 11:09:08.105857+00:00, run_duration=0.158284, state=success, executor_state=success, try_number=1, max_tries=1, job_id=233, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:06.603746+00:00, queued_by_job_id=7, pid=53642
2025-02-22 11:09:10,411 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-13T00:00:00+00:00, run_after=2024-04-14T00:00:00+00:00
2025-02-22 11:09:10,466 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-12 00:00:00+00:00: scheduled__2024-04-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:10,467 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-12 00:00:00+00:00, run_id=scheduled__2024-04-12T00:00:00+00:00, run_start_date=2025-02-22 11:08:45.043045+00:00, run_end_date=2025-02-22 11:09:10.467005+00:00, run_duration=25.42396, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-12 00:00:00+00:00, data_interval_end=2024-04-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:10,472 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-13T00:00:00+00:00, run_after=2024-04-14T00:00:00+00:00
2025-02-22 11:09:10,494 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:10,494 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:10,494 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:10,496 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:10,496 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:10,509 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:12,310 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:12,323 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:11.839405+00:00, run_end_date=2025-02-22 11:09:11.988980+00:00, run_duration=0.149575, state=success, executor_state=success, try_number=1, max_tries=1, job_id=235, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:10.495208+00:00, queued_by_job_id=7, pid=53680
2025-02-22 11:09:12,495 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-14T00:00:00+00:00, run_after=2024-04-15T00:00:00+00:00
2025-02-22 11:09:12,539 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-13 00:00:00+00:00: scheduled__2024-04-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:12,540 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-13 00:00:00+00:00, run_id=scheduled__2024-04-13T00:00:00+00:00, run_start_date=2025-02-22 11:08:53.160393+00:00, run_end_date=2025-02-22 11:09:12.540461+00:00, run_duration=19.380068, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-13 00:00:00+00:00, data_interval_end=2024-04-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:12,546 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-14T00:00:00+00:00, run_after=2024-04-15T00:00:00+00:00
2025-02-22 11:09:13,722 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-15T00:00:00+00:00, run_after=2024-04-16T00:00:00+00:00
2025-02-22 11:09:13,801 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:13,801 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:13,801 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:13,803 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:13,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:13,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:15,894 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:15,906 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:15.157798+00:00, run_end_date=2025-02-22 11:09:15.553689+00:00, run_duration=0.395891, state=success, executor_state=success, try_number=1, max_tries=1, job_id=236, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:13.802085+00:00, queued_by_job_id=7, pid=53702
2025-02-22 11:09:16,080 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-16T00:00:00+00:00, run_after=2024-04-17T00:00:00+00:00
2025-02-22 11:09:16,186 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:16,187 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:16,187 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:16,187 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:16,189 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:16,189 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:16,189 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:16,189 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:16,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:18,054 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:20,264 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:20,265 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:20,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:19.368887+00:00, run_end_date=2025-02-22 11:09:19.867697+00:00, run_duration=0.49881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=238, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:16.187646+00:00, queued_by_job_id=7, pid=53749
2025-02-22 11:09:20,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:17.560523+00:00, run_end_date=2025-02-22 11:09:17.717563+00:00, run_duration=0.15704, state=success, executor_state=success, try_number=1, max_tries=1, job_id=237, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:16.187646+00:00, queued_by_job_id=7, pid=53731
2025-02-22 11:09:20,448 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-17T00:00:00+00:00, run_after=2024-04-18T00:00:00+00:00
2025-02-22 11:09:20,530 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:20,530 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:20,530 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:20,530 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:09:20,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:20,532 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:20,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:20,532 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:20,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:20,532 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:20,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:20,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:22,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:24,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:26,589 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:26,590 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:26,590 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:26,597 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:26.120883+00:00, run_end_date=2025-02-22 11:09:26.273856+00:00, run_duration=0.152973, state=success, executor_state=success, try_number=1, max_tries=1, job_id=241, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:20.530929+00:00, queued_by_job_id=7, pid=53808
2025-02-22 11:09:26,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:24.319950+00:00, run_end_date=2025-02-22 11:09:24.490506+00:00, run_duration=0.170556, state=success, executor_state=success, try_number=1, max_tries=1, job_id=240, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:20.530929+00:00, queued_by_job_id=7, pid=53789
2025-02-22 11:09:26,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:21.932886+00:00, run_end_date=2025-02-22 11:09:22.196770+00:00, run_duration=0.263884, state=success, executor_state=success, try_number=1, max_tries=1, job_id=239, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:20.530929+00:00, queued_by_job_id=7, pid=53770
2025-02-22 11:09:26,771 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-18T00:00:00+00:00, run_after=2024-04-19T00:00:00+00:00
2025-02-22 11:09:26,850 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:26,850 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:26,850 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:26,850 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:09:26,850 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:09:26,850 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:26,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:26,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:26,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:26,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:26,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:26,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:26,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:26,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:26,867 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:28,892 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:30,937 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:32,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:34,544 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:34,545 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:34,545 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:34,545 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:34,553 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:34.076538+00:00, run_end_date=2025-02-22 11:09:34.227471+00:00, run_duration=0.150933, state=success, executor_state=success, try_number=1, max_tries=1, job_id=245, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:26.851066+00:00, queued_by_job_id=7, pid=53893
2025-02-22 11:09:34,553 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:32.259139+00:00, run_end_date=2025-02-22 11:09:32.406125+00:00, run_duration=0.146986, state=success, executor_state=success, try_number=1, max_tries=1, job_id=244, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:26.851066+00:00, queued_by_job_id=7, pid=53874
2025-02-22 11:09:34,553 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:30.426999+00:00, run_end_date=2025-02-22 11:09:30.630767+00:00, run_duration=0.203768, state=success, executor_state=success, try_number=1, max_tries=1, job_id=243, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:26.851066+00:00, queued_by_job_id=7, pid=53854
2025-02-22 11:09:34,554 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:28.235625+00:00, run_end_date=2025-02-22 11:09:28.573164+00:00, run_duration=0.337539, state=success, executor_state=success, try_number=1, max_tries=1, job_id=242, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:26.851066+00:00, queued_by_job_id=7, pid=53835
2025-02-22 11:09:34,722 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-19T00:00:00+00:00, run_after=2024-04-20T00:00:00+00:00
2025-02-22 11:09:34,796 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-14 00:00:00+00:00: scheduled__2024-04-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:34,797 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-14 00:00:00+00:00, run_id=scheduled__2024-04-14T00:00:00+00:00, run_start_date=2025-02-22 11:09:13.752200+00:00, run_end_date=2025-02-22 11:09:34.797075+00:00, run_duration=21.044875, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-14 00:00:00+00:00, data_interval_end=2024-04-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:34,800 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-15T00:00:00+00:00, run_after=2024-04-16T00:00:00+00:00
2025-02-22 11:09:34,823 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:34,823 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:34,823 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:34,823 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:09:34,823 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:09:34,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:34,825 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:34,825 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:34,826 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:34,826 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:34,826 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:34,826 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:34,826 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:34,826 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:34,840 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:37,021 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:38,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:40,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:42,630 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:42,631 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:42,631 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:42,631 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:42,639 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:42.100429+00:00, run_end_date=2025-02-22 11:09:42.314022+00:00, run_duration=0.213593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=249, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:34.824325+00:00, queued_by_job_id=7, pid=53978
2025-02-22 11:09:42,640 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:40.299981+00:00, run_end_date=2025-02-22 11:09:40.454284+00:00, run_duration=0.154303, state=success, executor_state=success, try_number=1, max_tries=1, job_id=248, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:34.824325+00:00, queued_by_job_id=7, pid=53959
2025-02-22 11:09:42,640 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:38.436116+00:00, run_end_date=2025-02-22 11:09:38.586801+00:00, run_duration=0.150685, state=success, executor_state=success, try_number=1, max_tries=1, job_id=247, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:34.824325+00:00, queued_by_job_id=7, pid=53940
2025-02-22 11:09:42,640 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:36.181276+00:00, run_end_date=2025-02-22 11:09:36.660497+00:00, run_duration=0.479221, state=success, executor_state=success, try_number=1, max_tries=1, job_id=246, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:34.824325+00:00, queued_by_job_id=7, pid=53921
2025-02-22 11:09:42,806 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-16T00:00:00+00:00, run_after=2024-04-17T00:00:00+00:00
2025-02-22 11:09:42,883 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-15 00:00:00+00:00: scheduled__2024-04-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:42,884 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-15 00:00:00+00:00, run_id=scheduled__2024-04-15T00:00:00+00:00, run_start_date=2025-02-22 11:09:16.131777+00:00, run_end_date=2025-02-22 11:09:42.883949+00:00, run_duration=26.752172, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-15 00:00:00+00:00, data_interval_end=2024-04-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:42,888 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-16T00:00:00+00:00, run_after=2024-04-17T00:00:00+00:00
2025-02-22 11:09:42,921 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:42,921 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:42,921 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:42,921 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:09:42,921 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:42,924 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:42,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:42,925 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:42,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:42,925 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:42,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:42,940 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:44,772 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:46,625 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:48,442 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:48,443 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:48,443 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:48,450 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:47.961925+00:00, run_end_date=2025-02-22 11:09:48.112915+00:00, run_duration=0.15099, state=success, executor_state=success, try_number=1, max_tries=1, job_id=252, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:42.922333+00:00, queued_by_job_id=7, pid=54043
2025-02-22 11:09:48,451 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:46.138709+00:00, run_end_date=2025-02-22 11:09:46.306359+00:00, run_duration=0.16765, state=success, executor_state=success, try_number=1, max_tries=1, job_id=251, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:42.922333+00:00, queued_by_job_id=7, pid=54016
2025-02-22 11:09:48,451 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:44.292090+00:00, run_end_date=2025-02-22 11:09:44.445068+00:00, run_duration=0.152978, state=success, executor_state=success, try_number=1, max_tries=1, job_id=250, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:42.922333+00:00, queued_by_job_id=7, pid=53997
2025-02-22 11:09:48,631 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-17T00:00:00+00:00, run_after=2024-04-18T00:00:00+00:00
2025-02-22 11:09:48,697 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-16 00:00:00+00:00: scheduled__2024-04-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:48,697 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-16 00:00:00+00:00, run_id=scheduled__2024-04-16T00:00:00+00:00, run_start_date=2025-02-22 11:09:20.472664+00:00, run_end_date=2025-02-22 11:09:48.697687+00:00, run_duration=28.225023, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-16 00:00:00+00:00, data_interval_end=2024-04-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:48,702 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-17T00:00:00+00:00, run_after=2024-04-18T00:00:00+00:00
2025-02-22 11:09:48,726 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:48,726 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:48,726 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:48,726 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:48,728 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:09:48,728 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:48,729 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:48,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:48,747 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:50,597 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:52,670 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:52,670 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:52,678 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:51.928216+00:00, run_end_date=2025-02-22 11:09:52.112266+00:00, run_duration=0.18405, state=success, executor_state=success, try_number=1, max_tries=1, job_id=254, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:48.727124+00:00, queued_by_job_id=7, pid=54081
2025-02-22 11:09:52,678 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:50.082289+00:00, run_end_date=2025-02-22 11:09:50.230794+00:00, run_duration=0.148505, state=success, executor_state=success, try_number=1, max_tries=1, job_id=253, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:09:48.727124+00:00, queued_by_job_id=7, pid=54063
2025-02-22 11:09:52,817 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-18T00:00:00+00:00, run_after=2024-04-19T00:00:00+00:00
2025-02-22 11:09:52,880 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-17 00:00:00+00:00: scheduled__2024-04-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:52,881 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-17 00:00:00+00:00, run_id=scheduled__2024-04-17T00:00:00+00:00, run_start_date=2025-02-22 11:09:26.797624+00:00, run_end_date=2025-02-22 11:09:52.881232+00:00, run_duration=26.083608, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-17 00:00:00+00:00, data_interval_end=2024-04-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:52,887 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-18T00:00:00+00:00, run_after=2024-04-19T00:00:00+00:00
2025-02-22 11:09:52,921 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:52,921 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:52,921 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:52,923 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:09:52,923 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:52,940 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:55,365 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:55,373 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:54.473534+00:00, run_end_date=2025-02-22 11:09:54.963484+00:00, run_duration=0.48995, state=success, executor_state=success, try_number=1, max_tries=1, job_id=255, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:09:52.922184+00:00, queued_by_job_id=7, pid=54102
2025-02-22 11:09:55,547 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-19T00:00:00+00:00, run_after=2024-04-20T00:00:00+00:00
2025-02-22 11:09:55,592 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-18 00:00:00+00:00: scheduled__2024-04-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:09:55,593 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-18 00:00:00+00:00, run_id=scheduled__2024-04-18T00:00:00+00:00, run_start_date=2025-02-22 11:09:34.752408+00:00, run_end_date=2025-02-22 11:09:55.593425+00:00, run_duration=20.841017, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-18 00:00:00+00:00, data_interval_end=2024-04-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:09:55,599 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-19T00:00:00+00:00, run_after=2024-04-20T00:00:00+00:00
2025-02-22 11:09:56,775 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-20T00:00:00+00:00, run_after=2024-04-21T00:00:00+00:00
2025-02-22 11:09:56,849 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:56,850 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:56,850 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:56,851 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:56,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:56,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:58,710 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:09:58,718 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:09:58.211838+00:00, run_end_date=2025-02-22 11:09:58.362568+00:00, run_duration=0.15073, state=success, executor_state=success, try_number=1, max_tries=1, job_id=256, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:56.850679+00:00, queued_by_job_id=7, pid=54124
2025-02-22 11:09:58,865 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-21T00:00:00+00:00, run_after=2024-04-22T00:00:00+00:00
2025-02-22 11:09:58,946 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:58,946 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:09:58,946 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:09:58,946 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:09:58,948 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:09:58,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:58,948 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:09:58,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:09:58,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:00,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:02,749 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:02,750 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:02,757 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:02.153409+00:00, run_end_date=2025-02-22 11:10:02.397383+00:00, run_duration=0.243974, state=success, executor_state=success, try_number=1, max_tries=1, job_id=258, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:09:58.947171+00:00, queued_by_job_id=7, pid=54173
2025-02-22 11:10:02,758 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:00.331198+00:00, run_end_date=2025-02-22 11:10:00.477821+00:00, run_duration=0.146623, state=success, executor_state=success, try_number=1, max_tries=1, job_id=257, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:09:58.947171+00:00, queued_by_job_id=7, pid=54153
2025-02-22 11:10:02,927 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-22T00:00:00+00:00, run_after=2024-04-23T00:00:00+00:00
2025-02-22 11:10:03,030 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:03,030 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:03,030 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:03,031 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:03,031 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:03,033 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:03,034 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:03,034 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:03,034 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:03,034 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:03,034 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:03,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:04,931 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:06,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:08,697 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:08,698 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:08,698 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:08,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:08.139933+00:00, run_end_date=2025-02-22 11:10:08.328180+00:00, run_duration=0.188247, state=success, executor_state=success, try_number=1, max_tries=1, job_id=261, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:03.031738+00:00, queued_by_job_id=7, pid=54238
2025-02-22 11:10:08,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:06.298751+00:00, run_end_date=2025-02-22 11:10:06.446544+00:00, run_duration=0.147793, state=success, executor_state=success, try_number=1, max_tries=1, job_id=260, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:03.031738+00:00, queued_by_job_id=7, pid=54211
2025-02-22 11:10:08,706 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:04.463094+00:00, run_end_date=2025-02-22 11:10:04.614892+00:00, run_duration=0.151798, state=success, executor_state=success, try_number=1, max_tries=1, job_id=259, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:03.031738+00:00, queued_by_job_id=7, pid=54193
2025-02-22 11:10:09,036 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-23T00:00:00+00:00, run_after=2024-04-24T00:00:00+00:00
2025-02-22 11:10:09,281 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:09,281 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:09,281 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:09,281 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:09,281 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:10:09,282 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:09,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:09,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:09,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:09,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:09,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:09,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:09,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:09,285 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:09,333 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:11,777 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:14,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:17,209 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:19,624 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:19,624 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:19,624 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:19,624 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:19,632 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:18.726021+00:00, run_end_date=2025-02-22 11:10:19.174685+00:00, run_duration=0.448664, state=success, executor_state=success, try_number=1, max_tries=1, job_id=265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:09.282470+00:00, queued_by_job_id=7, pid=54316
2025-02-22 11:10:19,632 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:15.755379+00:00, run_end_date=2025-02-22 11:10:16.675825+00:00, run_duration=0.920446, state=success, executor_state=success, try_number=1, max_tries=1, job_id=264, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:09.282470+00:00, queued_by_job_id=7, pid=54296
2025-02-22 11:10:19,632 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:13.238799+00:00, run_end_date=2025-02-22 11:10:13.621172+00:00, run_duration=0.382373, state=success, executor_state=success, try_number=1, max_tries=1, job_id=263, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:09.282470+00:00, queued_by_job_id=7, pid=54277
2025-02-22 11:10:19,632 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:10.784499+00:00, run_end_date=2025-02-22 11:10:11.252562+00:00, run_duration=0.468063, state=success, executor_state=success, try_number=1, max_tries=1, job_id=262, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:09.282470+00:00, queued_by_job_id=7, pid=54258
2025-02-22 11:10:19,975 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-24T00:00:00+00:00, run_after=2024-04-25T00:00:00+00:00
2025-02-22 11:10:20,173 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-19 00:00:00+00:00: scheduled__2024-04-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:10:20,174 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-19 00:00:00+00:00, run_id=scheduled__2024-04-19T00:00:00+00:00, run_start_date=2025-02-22 11:09:56.804357+00:00, run_end_date=2025-02-22 11:10:20.174345+00:00, run_duration=23.369988, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-19 00:00:00+00:00, data_interval_end=2024-04-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:10:20,179 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-20T00:00:00+00:00, run_after=2024-04-21T00:00:00+00:00
2025-02-22 11:10:20,457 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:20,457 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:20,457 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:20,457 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:20,457 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:10:20,457 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:20,459 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:20,459 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:20,460 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:20,460 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:20,460 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:20,460 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:20,460 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:20,460 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:20,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:22,876 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:25,287 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:28,272 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:30,944 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:30,944 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:30,945 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:30,945 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:30,952 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:29.729599+00:00, run_end_date=2025-02-22 11:10:30.185005+00:00, run_duration=0.455406, state=success, executor_state=success, try_number=1, max_tries=1, job_id=269, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:20.458239+00:00, queued_by_job_id=7, pid=54404
2025-02-22 11:10:30,952 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:26.802280+00:00, run_end_date=2025-02-22 11:10:27.740554+00:00, run_duration=0.938274, state=success, executor_state=success, try_number=1, max_tries=1, job_id=268, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:20.458239+00:00, queued_by_job_id=7, pid=54385
2025-02-22 11:10:30,952 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:24.342982+00:00, run_end_date=2025-02-22 11:10:24.696620+00:00, run_duration=0.353638, state=success, executor_state=success, try_number=1, max_tries=1, job_id=267, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:20.458239+00:00, queued_by_job_id=7, pid=54365
2025-02-22 11:10:30,953 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:21.952444+00:00, run_end_date=2025-02-22 11:10:22.330412+00:00, run_duration=0.377968, state=success, executor_state=success, try_number=1, max_tries=1, job_id=266, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:20.458239+00:00, queued_by_job_id=7, pid=54345
2025-02-22 11:10:31,276 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-21T00:00:00+00:00, run_after=2024-04-22T00:00:00+00:00
2025-02-22 11:10:31,397 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-20 00:00:00+00:00: scheduled__2024-04-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:10:31,397 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-20 00:00:00+00:00, run_id=scheduled__2024-04-20T00:00:00+00:00, run_start_date=2025-02-22 11:09:58.893206+00:00, run_end_date=2025-02-22 11:10:31.397476+00:00, run_duration=32.50427, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-20 00:00:00+00:00, data_interval_end=2024-04-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:10:31,402 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-21T00:00:00+00:00, run_after=2024-04-22T00:00:00+00:00
2025-02-22 11:10:31,478 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:31,478 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:31,479 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:31,479 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:31,479 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:31,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:31,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:31,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:31,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:31,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:31,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:31,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:33,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:35,826 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:37,719 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:37,719 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:37,719 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:37,727 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:37.148595+00:00, run_end_date=2025-02-22 11:10:37.296500+00:00, run_duration=0.147905, state=success, executor_state=success, try_number=1, max_tries=1, job_id=272, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:31.479576+00:00, queued_by_job_id=7, pid=54473
2025-02-22 11:10:37,728 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:35.345197+00:00, run_end_date=2025-02-22 11:10:35.495183+00:00, run_duration=0.149986, state=success, executor_state=success, try_number=1, max_tries=1, job_id=271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:31.479576+00:00, queued_by_job_id=7, pid=54454
2025-02-22 11:10:37,728 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:32.993618+00:00, run_end_date=2025-02-22 11:10:33.371350+00:00, run_duration=0.377732, state=success, executor_state=success, try_number=1, max_tries=1, job_id=270, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:31.479576+00:00, queued_by_job_id=7, pid=54435
2025-02-22 11:10:37,893 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-22T00:00:00+00:00, run_after=2024-04-23T00:00:00+00:00
2025-02-22 11:10:37,956 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-21 00:00:00+00:00: scheduled__2024-04-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:10:37,956 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-21 00:00:00+00:00, run_id=scheduled__2024-04-21T00:00:00+00:00, run_start_date=2025-02-22 11:10:02.955075+00:00, run_end_date=2025-02-22 11:10:37.956459+00:00, run_duration=35.001384, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-21 00:00:00+00:00, data_interval_end=2024-04-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:10:37,961 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-22T00:00:00+00:00, run_after=2024-04-23T00:00:00+00:00
2025-02-22 11:10:37,985 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:37,985 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:37,985 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:37,985 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:37,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:37,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:37,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:37,988 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:38,001 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:39,914 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:41,711 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:41,712 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:41,719 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:41.238640+00:00, run_end_date=2025-02-22 11:10:41.400447+00:00, run_duration=0.161807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=274, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:37.986087+00:00, queued_by_job_id=7, pid=54520
2025-02-22 11:10:41,720 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:39.370565+00:00, run_end_date=2025-02-22 11:10:39.521046+00:00, run_duration=0.150481, state=success, executor_state=success, try_number=1, max_tries=1, job_id=273, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:37.986087+00:00, queued_by_job_id=7, pid=54492
2025-02-22 11:10:41,863 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-23T00:00:00+00:00, run_after=2024-04-24T00:00:00+00:00
2025-02-22 11:10:41,915 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-22 00:00:00+00:00: scheduled__2024-04-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:10:41,916 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-22 00:00:00+00:00, run_id=scheduled__2024-04-22T00:00:00+00:00, run_start_date=2025-02-22 11:10:09.094783+00:00, run_end_date=2025-02-22 11:10:41.916349+00:00, run_duration=32.821566, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-22 00:00:00+00:00, data_interval_end=2024-04-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:10:41,922 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-23T00:00:00+00:00, run_after=2024-04-24T00:00:00+00:00
2025-02-22 11:10:41,990 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:41,990 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:41,990 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:41,994 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:41,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:42,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:43,847 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:43,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:43.382162+00:00, run_end_date=2025-02-22 11:10:43.528667+00:00, run_duration=0.146505, state=success, executor_state=success, try_number=1, max_tries=1, job_id=275, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:41.991962+00:00, queued_by_job_id=7, pid=54540
2025-02-22 11:10:44,019 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-24T00:00:00+00:00, run_after=2024-04-25T00:00:00+00:00
2025-02-22 11:10:44,048 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-23 00:00:00+00:00: scheduled__2024-04-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:10:44,048 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-23 00:00:00+00:00, run_id=scheduled__2024-04-23T00:00:00+00:00, run_start_date=2025-02-22 11:10:20.054192+00:00, run_end_date=2025-02-22 11:10:44.048321+00:00, run_duration=23.994129, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-23 00:00:00+00:00, data_interval_end=2024-04-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:10:44,051 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-24T00:00:00+00:00, run_after=2024-04-25T00:00:00+00:00
2025-02-22 11:10:45,320 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-25T00:00:00+00:00, run_after=2024-04-26T00:00:00+00:00
2025-02-22 11:10:45,395 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:45,396 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:45,396 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:45,397 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:45,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:45,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:47,240 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:47,247 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:46.751070+00:00, run_end_date=2025-02-22 11:10:46.897073+00:00, run_duration=0.146003, state=success, executor_state=success, try_number=1, max_tries=1, job_id=276, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:45.396662+00:00, queued_by_job_id=7, pid=54562
2025-02-22 11:10:47,397 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-26T00:00:00+00:00, run_after=2024-04-27T00:00:00+00:00
2025-02-22 11:10:47,481 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:47,481 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:47,481 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:47,481 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:47,483 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:47,483 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:47,484 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:47,484 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:47,497 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:49,358 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:51,367 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:51,368 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:51,375 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:50.739300+00:00, run_end_date=2025-02-22 11:10:50.967592+00:00, run_duration=0.228292, state=success, executor_state=success, try_number=1, max_tries=1, job_id=278, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:47.482307+00:00, queued_by_job_id=7, pid=54601
2025-02-22 11:10:51,376 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:48.861717+00:00, run_end_date=2025-02-22 11:10:49.011600+00:00, run_duration=0.149883, state=success, executor_state=success, try_number=1, max_tries=1, job_id=277, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:47.482307+00:00, queued_by_job_id=7, pid=54582
2025-02-22 11:10:51,561 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-27T00:00:00+00:00, run_after=2024-04-28T00:00:00+00:00
2025-02-22 11:10:51,643 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:51,644 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:51,644 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:51,644 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:51,644 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:51,646 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:51,646 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:51,646 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:51,646 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:51,646 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:51,646 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:51,663 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:53,569 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:55,913 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:57,720 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:57,721 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:57,721 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:10:57,729 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:57.256381+00:00, run_end_date=2025-02-22 11:10:57.411548+00:00, run_duration=0.155167, state=success, executor_state=success, try_number=1, max_tries=1, job_id=281, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:51.644670+00:00, queued_by_job_id=7, pid=54659
2025-02-22 11:10:57,729 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:55.006569+00:00, run_end_date=2025-02-22 11:10:55.284900+00:00, run_duration=0.278331, state=success, executor_state=success, try_number=1, max_tries=1, job_id=280, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:51.644670+00:00, queued_by_job_id=7, pid=54640
2025-02-22 11:10:57,730 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:53.040865+00:00, run_end_date=2025-02-22 11:10:53.195728+00:00, run_duration=0.154863, state=success, executor_state=success, try_number=1, max_tries=1, job_id=279, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:51.644670+00:00, queued_by_job_id=7, pid=54621
2025-02-22 11:10:57,982 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-28T00:00:00+00:00, run_after=2024-04-29T00:00:00+00:00
2025-02-22 11:10:58,070 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:58,071 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:10:58,071 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:10:58,071 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:10:58,071 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:10:58,071 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:10:58,073 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:10:58,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:58,073 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:10:58,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:58,074 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:10:58,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:58,074 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:10:58,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:10:58,086 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:00,218 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:02,158 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:04,149 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:05,984 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:05,985 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:05,985 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:05,985 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:05,993 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:05.510647+00:00, run_end_date=2025-02-22 11:11:05.670200+00:00, run_duration=0.159553, state=success, executor_state=success, try_number=1, max_tries=1, job_id=285, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:10:58.071791+00:00, queued_by_job_id=7, pid=54780
2025-02-22 11:11:05,993 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:03.671662+00:00, run_end_date=2025-02-22 11:11:03.825283+00:00, run_duration=0.153621, state=success, executor_state=success, try_number=1, max_tries=1, job_id=284, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:10:58.071791+00:00, queued_by_job_id=7, pid=54748
2025-02-22 11:11:05,993 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:01.692768+00:00, run_end_date=2025-02-22 11:11:01.865564+00:00, run_duration=0.172796, state=success, executor_state=success, try_number=1, max_tries=1, job_id=283, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:10:58.071791+00:00, queued_by_job_id=7, pid=54727
2025-02-22 11:11:05,994 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:10:59.439976+00:00, run_end_date=2025-02-22 11:10:59.888614+00:00, run_duration=0.448638, state=success, executor_state=success, try_number=1, max_tries=1, job_id=282, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:10:58.071791+00:00, queued_by_job_id=7, pid=54694
2025-02-22 11:11:06,164 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-29T00:00:00+00:00, run_after=2024-04-30T00:00:00+00:00
2025-02-22 11:11:06,236 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-24 00:00:00+00:00: scheduled__2024-04-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:06,236 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-24 00:00:00+00:00, run_id=scheduled__2024-04-24T00:00:00+00:00, run_start_date=2025-02-22 11:10:45.352257+00:00, run_end_date=2025-02-22 11:11:06.236659+00:00, run_duration=20.884402, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-24 00:00:00+00:00, data_interval_end=2024-04-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:06,239 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-25T00:00:00+00:00, run_after=2024-04-26T00:00:00+00:00
2025-02-22 11:11:06,264 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:06,264 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:06,264 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:06,264 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:11:06,264 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:11:06,265 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:06,266 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:11:06,266 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:06,267 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:06,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:06,267 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:06,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:06,267 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:06,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:06,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:08,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:10,012 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:11,862 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:13,640 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:13,640 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:13,640 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:13,640 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:13,649 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:13.174850+00:00, run_end_date=2025-02-22 11:11:13.337250+00:00, run_duration=0.1624, state=success, executor_state=success, try_number=1, max_tries=1, job_id=289, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:06.265427+00:00, queued_by_job_id=7, pid=54887
2025-02-22 11:11:13,649 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:11.392917+00:00, run_end_date=2025-02-22 11:11:11.541215+00:00, run_duration=0.148298, state=success, executor_state=success, try_number=1, max_tries=1, job_id=288, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:06.265427+00:00, queued_by_job_id=7, pid=54869
2025-02-22 11:11:13,649 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:09.524202+00:00, run_end_date=2025-02-22 11:11:09.673904+00:00, run_duration=0.149702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=287, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:06.265427+00:00, queued_by_job_id=7, pid=54836
2025-02-22 11:11:13,649 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:07.685116+00:00, run_end_date=2025-02-22 11:11:07.844474+00:00, run_duration=0.159358, state=success, executor_state=success, try_number=1, max_tries=1, job_id=286, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:11:06.265427+00:00, queued_by_job_id=7, pid=54815
2025-02-22 11:11:13,828 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-26T00:00:00+00:00, run_after=2024-04-27T00:00:00+00:00
2025-02-22 11:11:13,871 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-25 00:00:00+00:00: scheduled__2024-04-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:13,871 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-25 00:00:00+00:00, run_id=scheduled__2024-04-25T00:00:00+00:00, run_start_date=2025-02-22 11:10:47.426036+00:00, run_end_date=2025-02-22 11:11:13.871933+00:00, run_duration=26.445897, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-25 00:00:00+00:00, data_interval_end=2024-04-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:13,875 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-26T00:00:00+00:00, run_after=2024-04-27T00:00:00+00:00
2025-02-22 11:11:13,899 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:13,900 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:13,900 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:13,900 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:11:13,900 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:13,902 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:13,902 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:13,903 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:13,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:13,903 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:13,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:13,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:15,733 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:17,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:19,696 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:19,697 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:19,697 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:19,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:18.950923+00:00, run_end_date=2025-02-22 11:11:19.346984+00:00, run_duration=0.396061, state=success, executor_state=success, try_number=1, max_tries=1, job_id=292, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:13.900981+00:00, queued_by_job_id=7, pid=54961
2025-02-22 11:11:19,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:17.059701+00:00, run_end_date=2025-02-22 11:11:17.211116+00:00, run_duration=0.151415, state=success, executor_state=success, try_number=1, max_tries=1, job_id=291, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:13.900981+00:00, queued_by_job_id=7, pid=54934
2025-02-22 11:11:19,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:15.244033+00:00, run_end_date=2025-02-22 11:11:15.390716+00:00, run_duration=0.146683, state=success, executor_state=success, try_number=1, max_tries=1, job_id=290, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:13.900981+00:00, queued_by_job_id=7, pid=54907
2025-02-22 11:11:20,169 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-27T00:00:00+00:00, run_after=2024-04-28T00:00:00+00:00
2025-02-22 11:11:20,235 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-26 00:00:00+00:00: scheduled__2024-04-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:20,236 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-26 00:00:00+00:00, run_id=scheduled__2024-04-26T00:00:00+00:00, run_start_date=2025-02-22 11:10:51.588110+00:00, run_end_date=2025-02-22 11:11:20.236384+00:00, run_duration=28.648274, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-26 00:00:00+00:00, data_interval_end=2024-04-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:20,241 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-27T00:00:00+00:00, run_after=2024-04-28T00:00:00+00:00
2025-02-22 11:11:20,272 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:20,272 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:20,273 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:20,273 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:20,276 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:20,277 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:20,277 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:20,277 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:20,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:22,104 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:23,919 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:23,920 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:23,927 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:23.441446+00:00, run_end_date=2025-02-22 11:11:23.589944+00:00, run_duration=0.148498, state=success, executor_state=success, try_number=1, max_tries=1, job_id=294, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:20.273942+00:00, queued_by_job_id=7, pid=55007
2025-02-22 11:11:23,928 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:21.631741+00:00, run_end_date=2025-02-22 11:11:21.795172+00:00, run_duration=0.163431, state=success, executor_state=success, try_number=1, max_tries=1, job_id=293, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:20.273942+00:00, queued_by_job_id=7, pid=54989
2025-02-22 11:11:24,388 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-28T00:00:00+00:00, run_after=2024-04-29T00:00:00+00:00
2025-02-22 11:11:24,435 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-27 00:00:00+00:00: scheduled__2024-04-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:24,436 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-27 00:00:00+00:00, run_id=scheduled__2024-04-27T00:00:00+00:00, run_start_date=2025-02-22 11:10:58.007851+00:00, run_end_date=2025-02-22 11:11:24.436341+00:00, run_duration=26.42849, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-27 00:00:00+00:00, data_interval_end=2024-04-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:24,442 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-28T00:00:00+00:00, run_after=2024-04-29T00:00:00+00:00
2025-02-22 11:11:24,465 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:24,465 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:24,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:24,467 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:24,467 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:24,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:26,444 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:26,451 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:25.975400+00:00, run_end_date=2025-02-22 11:11:26.129307+00:00, run_duration=0.153907, state=success, executor_state=success, try_number=1, max_tries=1, job_id=295, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:24.466369+00:00, queued_by_job_id=7, pid=55037
2025-02-22 11:11:26,917 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-30T00:00:00+00:00, run_after=2024-05-01T00:00:00+00:00
2025-02-22 11:11:26,976 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-28 00:00:00+00:00: scheduled__2024-04-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:26,976 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-28 00:00:00+00:00, run_id=scheduled__2024-04-28T00:00:00+00:00, run_start_date=2025-02-22 11:11:06.191680+00:00, run_end_date=2025-02-22 11:11:26.976358+00:00, run_duration=20.784678, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-28 00:00:00+00:00, data_interval_end=2024-04-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:26,979 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-29T00:00:00+00:00, run_after=2024-04-30T00:00:00+00:00
2025-02-22 11:11:27,002 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:27,003 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:27,003 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:27,004 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:11:27,004 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:27,019 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:28,910 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:28,918 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:28.388188+00:00, run_end_date=2025-02-22 11:11:28.542767+00:00, run_duration=0.154579, state=success, executor_state=success, try_number=1, max_tries=1, job_id=296, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:11:27.003636+00:00, queued_by_job_id=7, pid=55065
2025-02-22 11:11:29,059 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-30T00:00:00+00:00, run_after=2024-05-01T00:00:00+00:00
2025-02-22 11:11:29,140 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:29,140 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:29,141 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:29,144 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:29,144 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:29,159 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:31,046 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:31,054 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:30.537815+00:00, run_end_date=2025-02-22 11:11:30.688534+00:00, run_duration=0.150719, state=success, executor_state=success, try_number=1, max_tries=1, job_id=297, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:29.142072+00:00, queued_by_job_id=7, pid=55084
2025-02-22 11:11:31,203 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-01T00:00:00+00:00, run_after=2024-05-02T00:00:00+00:00
2025-02-22 11:11:31,288 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:31,288 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:31,289 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:31,289 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:31,290 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:11:31,291 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:31,291 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:31,291 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:31,304 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:33,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:35,117 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-04-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:35,118 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:35,123 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:34.649952+00:00, run_end_date=2025-02-22 11:11:34.805072+00:00, run_duration=0.15512, state=success, executor_state=success, try_number=1, max_tries=1, job_id=299, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:31.289495+00:00, queued_by_job_id=7, pid=55124
2025-02-22 11:11:35,123 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-04-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:32.710793+00:00, run_end_date=2025-02-22 11:11:32.966069+00:00, run_duration=0.255276, state=success, executor_state=success, try_number=1, max_tries=1, job_id=298, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:11:31.289495+00:00, queued_by_job_id=7, pid=55104
2025-02-22 11:11:35,294 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-02T00:00:00+00:00, run_after=2024-05-03T00:00:00+00:00
2025-02-22 11:11:35,370 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:35,370 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:35,370 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:35,370 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:11:35,370 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:35,372 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:11:35,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:35,372 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:35,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:35,372 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:35,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:35,384 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:37,414 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:39,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:41,074 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:41,074 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-04-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:41,074 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:41,082 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:40.585419+00:00, run_end_date=2025-02-22 11:11:40.760765+00:00, run_duration=0.175346, state=success, executor_state=success, try_number=1, max_tries=1, job_id=302, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:35.371104+00:00, queued_by_job_id=7, pid=55189
2025-02-22 11:11:41,083 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-04-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:38.758078+00:00, run_end_date=2025-02-22 11:11:38.909314+00:00, run_duration=0.151236, state=success, executor_state=success, try_number=1, max_tries=1, job_id=301, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:35.371104+00:00, queued_by_job_id=7, pid=55171
2025-02-22 11:11:41,083 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:36.743799+00:00, run_end_date=2025-02-22 11:11:37.007209+00:00, run_duration=0.26341, state=success, executor_state=success, try_number=1, max_tries=1, job_id=300, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:11:35.371104+00:00, queued_by_job_id=7, pid=55152
2025-02-22 11:11:41,254 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-03T00:00:00+00:00, run_after=2024-05-04T00:00:00+00:00
2025-02-22 11:11:41,315 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-29 00:00:00+00:00: scheduled__2024-04-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:41,315 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-29 00:00:00+00:00, run_id=scheduled__2024-04-29T00:00:00+00:00, run_start_date=2025-02-22 11:11:26.945021+00:00, run_end_date=2025-02-22 11:11:41.315782+00:00, run_duration=14.370761, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-29 00:00:00+00:00, data_interval_end=2024-04-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:41,318 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-04-30T00:00:00+00:00, run_after=2024-05-01T00:00:00+00:00
2025-02-22 11:11:41,343 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:41,343 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:41,343 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:41,343 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:11:41,343 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:41,345 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:11:41,345 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:41,345 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:41,345 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:41,346 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:41,346 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:41,359 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:43,300 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:45,098 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:46,880 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:46,881 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:46,881 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-04-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:46,889 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-04-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:46.421537+00:00, run_end_date=2025-02-22 11:11:46.581374+00:00, run_duration=0.159837, state=success, executor_state=success, try_number=1, max_tries=1, job_id=305, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:41.344129+00:00, queued_by_job_id=7, pid=55247
2025-02-22 11:11:46,889 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:44.630715+00:00, run_end_date=2025-02-22 11:11:44.780805+00:00, run_duration=0.15009, state=success, executor_state=success, try_number=1, max_tries=1, job_id=304, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:41.344129+00:00, queued_by_job_id=7, pid=55227
2025-02-22 11:11:46,889 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:42.743745+00:00, run_end_date=2025-02-22 11:11:42.929623+00:00, run_duration=0.185878, state=success, executor_state=success, try_number=1, max_tries=1, job_id=303, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:11:41.344129+00:00, queued_by_job_id=7, pid=55209
2025-02-22 11:11:47,059 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-01T00:00:00+00:00, run_after=2024-05-02T00:00:00+00:00
2025-02-22 11:11:47,151 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:47,151 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:47,151 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:47,152 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:11:47,152 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-04-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:47,155 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:11:47,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:47,156 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:47,156 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:47,156 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:47,156 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:47,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:49,391 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:51,545 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:53,362 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:53,363 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:53,363 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-04-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:53,379 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-04-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:52.893260+00:00, run_end_date=2025-02-22 11:11:53.044521+00:00, run_duration=0.151261, state=success, executor_state=success, try_number=1, max_tries=1, job_id=308, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:47.152973+00:00, queued_by_job_id=7, pid=55321
2025-02-22 11:11:53,380 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:50.712713+00:00, run_end_date=2025-02-22 11:11:51.127327+00:00, run_duration=0.414614, state=success, executor_state=success, try_number=1, max_tries=1, job_id=307, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:47.152973+00:00, queued_by_job_id=7, pid=55295
2025-02-22 11:11:53,380 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:48.846959+00:00, run_end_date=2025-02-22 11:11:48.997684+00:00, run_duration=0.150725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=306, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:11:47.152973+00:00, queued_by_job_id=7, pid=55268
2025-02-22 11:11:53,441 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:11:53,575 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-02T00:00:00+00:00, run_after=2024-05-03T00:00:00+00:00
2025-02-22 11:11:53,637 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-04-30 00:00:00+00:00: scheduled__2024-04-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:53,637 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-04-30 00:00:00+00:00, run_id=scheduled__2024-04-30T00:00:00+00:00, run_start_date=2025-02-22 11:11:31.233207+00:00, run_end_date=2025-02-22 11:11:53.637790+00:00, run_duration=22.404583, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-04-30 00:00:00+00:00, data_interval_end=2024-05-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:53,642 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-01T00:00:00+00:00, run_after=2024-05-02T00:00:00+00:00
2025-02-22 11:11:53,665 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:53,666 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:53,666 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:11:53,666 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:53,668 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:11:53,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:53,668 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:53,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:53,682 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:55,507 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:57,356 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:57,356 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:57,364 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:56.836866+00:00, run_end_date=2025-02-22 11:11:57.056504+00:00, run_duration=0.219638, state=success, executor_state=success, try_number=1, max_tries=1, job_id=310, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:53.666641+00:00, queued_by_job_id=7, pid=55360
2025-02-22 11:11:57,364 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:55.018786+00:00, run_end_date=2025-02-22 11:11:55.216639+00:00, run_duration=0.197853, state=success, executor_state=success, try_number=1, max_tries=1, job_id=309, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:11:53.666641+00:00, queued_by_job_id=7, pid=55341
2025-02-22 11:11:57,537 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-02T00:00:00+00:00, run_after=2024-05-03T00:00:00+00:00
2025-02-22 11:11:57,584 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-01 00:00:00+00:00: scheduled__2024-05-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:57,585 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-01 00:00:00+00:00, run_id=scheduled__2024-05-01T00:00:00+00:00, run_start_date=2025-02-22 11:11:35.320655+00:00, run_end_date=2025-02-22 11:11:57.585345+00:00, run_duration=22.26469, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-01 00:00:00+00:00, data_interval_end=2024-05-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:57,591 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-02T00:00:00+00:00, run_after=2024-05-03T00:00:00+00:00
2025-02-22 11:11:57,622 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:57,623 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:11:57,623 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:11:57,626 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:11:57,626 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:57,640 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:11:59,561 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:11:59,569 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:11:58.986286+00:00, run_end_date=2025-02-22 11:11:59.205856+00:00, run_duration=0.21957, state=success, executor_state=success, try_number=1, max_tries=1, job_id=311, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:11:57.624243+00:00, queued_by_job_id=7, pid=55379
2025-02-22 11:11:59,733 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-03T00:00:00+00:00, run_after=2024-05-04T00:00:00+00:00
2025-02-22 11:11:59,772 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-02 00:00:00+00:00: scheduled__2024-05-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:11:59,773 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-02 00:00:00+00:00, run_id=scheduled__2024-05-02T00:00:00+00:00, run_start_date=2025-02-22 11:11:41.277994+00:00, run_end_date=2025-02-22 11:11:59.773042+00:00, run_duration=18.495048, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-02 00:00:00+00:00, data_interval_end=2024-05-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:11:59,778 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-03T00:00:00+00:00, run_after=2024-05-04T00:00:00+00:00
2025-02-22 11:12:00,949 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-04T00:00:00+00:00, run_after=2024-05-05T00:00:00+00:00
2025-02-22 11:12:01,029 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:01,030 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:01,030 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:01,031 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:01,031 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:01,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:02,879 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:02,887 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:02.411730+00:00, run_end_date=2025-02-22 11:12:02.562930+00:00, run_duration=0.1512, state=success, executor_state=success, try_number=1, max_tries=1, job_id=312, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:01.030479+00:00, queued_by_job_id=7, pid=55402
2025-02-22 11:12:03,037 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-05T00:00:00+00:00, run_after=2024-05-06T00:00:00+00:00
2025-02-22 11:12:03,218 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:03,219 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:03,219 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:03,219 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:03,220 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:03,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:03,221 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:03,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:03,234 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:05,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:07,013 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:07,013 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:07,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:06.442881+00:00, run_end_date=2025-02-22 11:12:06.626250+00:00, run_duration=0.183369, state=success, executor_state=success, try_number=1, max_tries=1, job_id=314, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:03.219596+00:00, queued_by_job_id=7, pid=55441
2025-02-22 11:12:07,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:04.602224+00:00, run_end_date=2025-02-22 11:12:04.772542+00:00, run_duration=0.170318, state=success, executor_state=success, try_number=1, max_tries=1, job_id=313, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:03.219596+00:00, queued_by_job_id=7, pid=55422
2025-02-22 11:12:07,185 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-06T00:00:00+00:00, run_after=2024-05-07T00:00:00+00:00
2025-02-22 11:12:07,271 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:07,271 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:07,271 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:07,271 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:07,271 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:07,273 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:07,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:07,273 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:07,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:07,274 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:07,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:07,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:09,126 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:10,944 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:13,143 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:13,144 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:13,144 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:13,151 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:12.365684+00:00, run_end_date=2025-02-22 11:12:12.749633+00:00, run_duration=0.383949, state=success, executor_state=success, try_number=1, max_tries=1, job_id=317, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:07.272288+00:00, queued_by_job_id=7, pid=55498
2025-02-22 11:12:13,151 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:10.449775+00:00, run_end_date=2025-02-22 11:12:10.597188+00:00, run_duration=0.147413, state=success, executor_state=success, try_number=1, max_tries=1, job_id=316, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:07.272288+00:00, queued_by_job_id=7, pid=55480
2025-02-22 11:12:13,151 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:08.628707+00:00, run_end_date=2025-02-22 11:12:08.777517+00:00, run_duration=0.14881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=315, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:07.272288+00:00, queued_by_job_id=7, pid=55461
2025-02-22 11:12:13,427 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-07T00:00:00+00:00, run_after=2024-05-08T00:00:00+00:00
2025-02-22 11:12:13,521 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:13,521 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:13,521 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:13,522 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:13,522 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:12:13,522 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:13,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:13,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:13,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:13,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:13,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:13,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:13,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:13,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:13,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:15,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:17,263 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:19,093 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:20,884 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:20,885 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:20,885 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:20,885 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:20,893 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:20.416870+00:00, run_end_date=2025-02-22 11:12:20.565272+00:00, run_duration=0.148402, state=success, executor_state=success, try_number=1, max_tries=1, job_id=321, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:13.522571+00:00, queued_by_job_id=7, pid=55584
2025-02-22 11:12:20,893 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:18.588653+00:00, run_end_date=2025-02-22 11:12:18.741173+00:00, run_duration=0.15252, state=success, executor_state=success, try_number=1, max_tries=1, job_id=320, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:13.522571+00:00, queued_by_job_id=7, pid=55565
2025-02-22 11:12:20,893 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:16.790915+00:00, run_end_date=2025-02-22 11:12:16.939142+00:00, run_duration=0.148227, state=success, executor_state=success, try_number=1, max_tries=1, job_id=319, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:13.522571+00:00, queued_by_job_id=7, pid=55546
2025-02-22 11:12:20,893 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:14.895247+00:00, run_end_date=2025-02-22 11:12:15.074906+00:00, run_duration=0.179659, state=success, executor_state=success, try_number=1, max_tries=1, job_id=318, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:13.522571+00:00, queued_by_job_id=7, pid=55526
2025-02-22 11:12:21,066 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-08T00:00:00+00:00, run_after=2024-05-09T00:00:00+00:00
2025-02-22 11:12:21,141 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-03 00:00:00+00:00: scheduled__2024-05-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:12:21,142 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-03 00:00:00+00:00, run_id=scheduled__2024-05-03T00:00:00+00:00, run_start_date=2025-02-22 11:12:00.979888+00:00, run_end_date=2025-02-22 11:12:21.142240+00:00, run_duration=20.162352, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-03 00:00:00+00:00, data_interval_end=2024-05-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:12:21,145 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-04T00:00:00+00:00, run_after=2024-05-05T00:00:00+00:00
2025-02-22 11:12:21,174 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:21,174 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:21,174 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:21,175 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:21,175 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:12:21,175 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:21,177 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:21,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:21,177 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:21,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:21,177 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:21,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:21,178 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:21,178 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:21,193 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:23,027 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:24,908 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:26,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:28,550 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:28,551 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:28,551 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:28,551 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:28,558 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:28.057663+00:00, run_end_date=2025-02-22 11:12:28.210365+00:00, run_duration=0.152702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=325, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:21.175622+00:00, queued_by_job_id=7, pid=55676
2025-02-22 11:12:28,558 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:26.234137+00:00, run_end_date=2025-02-22 11:12:26.382655+00:00, run_duration=0.148518, state=success, executor_state=success, try_number=1, max_tries=1, job_id=324, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:21.175622+00:00, queued_by_job_id=7, pid=55656
2025-02-22 11:12:28,559 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:24.391727+00:00, run_end_date=2025-02-22 11:12:24.554488+00:00, run_duration=0.162761, state=success, executor_state=success, try_number=1, max_tries=1, job_id=323, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:21.175622+00:00, queued_by_job_id=7, pid=55630
2025-02-22 11:12:28,559 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:22.529412+00:00, run_end_date=2025-02-22 11:12:22.679403+00:00, run_duration=0.149991, state=success, executor_state=success, try_number=1, max_tries=1, job_id=322, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:21.175622+00:00, queued_by_job_id=7, pid=55604
2025-02-22 11:12:28,738 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-05T00:00:00+00:00, run_after=2024-05-06T00:00:00+00:00
2025-02-22 11:12:28,786 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-04 00:00:00+00:00: scheduled__2024-05-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:12:28,787 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-04 00:00:00+00:00, run_id=scheduled__2024-05-04T00:00:00+00:00, run_start_date=2025-02-22 11:12:03.062520+00:00, run_end_date=2025-02-22 11:12:28.787112+00:00, run_duration=25.724592, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-04 00:00:00+00:00, data_interval_end=2024-05-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:12:28,790 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-05T00:00:00+00:00, run_after=2024-05-06T00:00:00+00:00
2025-02-22 11:12:28,813 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:28,813 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:28,813 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:28,813 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:28,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:28,815 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:28,815 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:28,816 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:28,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:28,816 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:28,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:28,830 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:30,633 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:32,586 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:34,384 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:34,385 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:34,386 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:34,402 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:33.902264+00:00, run_end_date=2025-02-22 11:12:34.054866+00:00, run_duration=0.152602, state=success, executor_state=success, try_number=1, max_tries=1, job_id=328, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:28.814185+00:00, queued_by_job_id=7, pid=55733
2025-02-22 11:12:34,403 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:31.950301+00:00, run_end_date=2025-02-22 11:12:32.105621+00:00, run_duration=0.15532, state=success, executor_state=success, try_number=1, max_tries=1, job_id=327, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:28.814185+00:00, queued_by_job_id=7, pid=55714
2025-02-22 11:12:34,403 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:30.150904+00:00, run_end_date=2025-02-22 11:12:30.314640+00:00, run_duration=0.163736, state=success, executor_state=success, try_number=1, max_tries=1, job_id=326, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:28.814185+00:00, queued_by_job_id=7, pid=55696
2025-02-22 11:12:34,570 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-06T00:00:00+00:00, run_after=2024-05-07T00:00:00+00:00
2025-02-22 11:12:34,634 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-05 00:00:00+00:00: scheduled__2024-05-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:12:34,634 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-05 00:00:00+00:00, run_id=scheduled__2024-05-05T00:00:00+00:00, run_start_date=2025-02-22 11:12:07.210921+00:00, run_end_date=2025-02-22 11:12:34.634563+00:00, run_duration=27.423642, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-05 00:00:00+00:00, data_interval_end=2024-05-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:12:34,639 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-06T00:00:00+00:00, run_after=2024-05-07T00:00:00+00:00
2025-02-22 11:12:34,671 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:34,671 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:34,671 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:34,671 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:34,674 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:34,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:34,674 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:34,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:34,689 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:36,869 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:38,805 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:38,806 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:38,813 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:38.313841+00:00, run_end_date=2025-02-22 11:12:38.469485+00:00, run_duration=0.155644, state=success, executor_state=success, try_number=1, max_tries=1, job_id=330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:34.672146+00:00, queued_by_job_id=7, pid=55774
2025-02-22 11:12:38,813 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:36.054974+00:00, run_end_date=2025-02-22 11:12:36.234572+00:00, run_duration=0.179598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=329, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:34.672146+00:00, queued_by_job_id=7, pid=55754
2025-02-22 11:12:39,061 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-07T00:00:00+00:00, run_after=2024-05-08T00:00:00+00:00
2025-02-22 11:12:39,109 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-06 00:00:00+00:00: scheduled__2024-05-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:12:39,110 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-06 00:00:00+00:00, run_id=scheduled__2024-05-06T00:00:00+00:00, run_start_date=2025-02-22 11:12:13.458518+00:00, run_end_date=2025-02-22 11:12:39.110085+00:00, run_duration=25.651567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-06 00:00:00+00:00, data_interval_end=2024-05-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:12:39,116 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-07T00:00:00+00:00, run_after=2024-05-08T00:00:00+00:00
2025-02-22 11:12:39,150 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:39,150 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:39,150 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:39,152 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:39,152 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:39,166 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:40,968 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:40,976 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:40.498248+00:00, run_end_date=2025-02-22 11:12:40.669508+00:00, run_duration=0.17126, state=success, executor_state=success, try_number=1, max_tries=1, job_id=331, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:39.151130+00:00, queued_by_job_id=7, pid=55794
2025-02-22 11:12:41,138 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-08T00:00:00+00:00, run_after=2024-05-09T00:00:00+00:00
2025-02-22 11:12:41,166 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-07 00:00:00+00:00: scheduled__2024-05-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:12:41,167 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-07 00:00:00+00:00, run_id=scheduled__2024-05-07T00:00:00+00:00, run_start_date=2025-02-22 11:12:21.097234+00:00, run_end_date=2025-02-22 11:12:41.167320+00:00, run_duration=20.070086, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-07 00:00:00+00:00, data_interval_end=2024-05-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:12:41,170 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-08T00:00:00+00:00, run_after=2024-05-09T00:00:00+00:00
2025-02-22 11:12:42,339 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-09T00:00:00+00:00, run_after=2024-05-10T00:00:00+00:00
2025-02-22 11:12:42,407 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:42,407 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:42,407 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:42,409 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:42,409 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:42,423 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:44,294 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:44,302 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:43.817199+00:00, run_end_date=2025-02-22 11:12:43.972628+00:00, run_duration=0.155429, state=success, executor_state=success, try_number=1, max_tries=1, job_id=332, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:42.408216+00:00, queued_by_job_id=7, pid=55816
2025-02-22 11:12:44,451 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-10T00:00:00+00:00, run_after=2024-05-11T00:00:00+00:00
2025-02-22 11:12:44,541 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:44,541 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:44,541 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:44,541 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:44,543 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:44,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:44,543 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:44,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:44,651 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:46,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:48,311 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:48,311 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:48,318 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:47.831054+00:00, run_end_date=2025-02-22 11:12:47.988502+00:00, run_duration=0.157448, state=success, executor_state=success, try_number=1, max_tries=1, job_id=334, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:44.541943+00:00, queued_by_job_id=7, pid=55864
2025-02-22 11:12:48,318 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:45.983972+00:00, run_end_date=2025-02-22 11:12:46.136063+00:00, run_duration=0.152091, state=success, executor_state=success, try_number=1, max_tries=1, job_id=333, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:44.541943+00:00, queued_by_job_id=7, pid=55844
2025-02-22 11:12:48,569 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-11T00:00:00+00:00, run_after=2024-05-12T00:00:00+00:00
2025-02-22 11:12:48,748 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:48,748 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:48,748 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:48,748 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:48,748 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:48,750 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:48,750 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:48,750 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:48,751 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:48,751 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:48,751 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:48,773 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:50,639 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:52,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:54,567 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:54,567 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:54,567 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:12:54,575 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:54.067545+00:00, run_end_date=2025-02-22 11:12:54.223410+00:00, run_duration=0.155865, state=success, executor_state=success, try_number=1, max_tries=1, job_id=337, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:48.749118+00:00, queued_by_job_id=7, pid=55966
2025-02-22 11:12:54,576 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:52.049340+00:00, run_end_date=2025-02-22 11:12:52.218576+00:00, run_duration=0.169236, state=success, executor_state=success, try_number=1, max_tries=1, job_id=336, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:48.749118+00:00, queued_by_job_id=7, pid=55932
2025-02-22 11:12:54,576 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:50.136757+00:00, run_end_date=2025-02-22 11:12:50.311798+00:00, run_duration=0.175041, state=success, executor_state=success, try_number=1, max_tries=1, job_id=335, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:48.749118+00:00, queued_by_job_id=7, pid=55898
2025-02-22 11:12:54,772 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-12T00:00:00+00:00, run_after=2024-05-13T00:00:00+00:00
2025-02-22 11:12:54,854 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:54,855 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:12:54,855 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:12:54,855 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:12:54,855 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:12:54,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:12:54,856 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:12:54,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:54,856 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:12:54,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:54,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:12:54,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:54,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:12:54,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:54,870 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:56,754 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:12:58,886 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:00,764 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:02,601 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:02,602 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:02,602 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:02,602 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:02,610 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:02.150905+00:00, run_end_date=2025-02-22 11:13:02.316488+00:00, run_duration=0.165583, state=success, executor_state=success, try_number=1, max_tries=1, job_id=341, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:12:54.855640+00:00, queued_by_job_id=7, pid=56075
2025-02-22 11:13:02,610 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:00.230827+00:00, run_end_date=2025-02-22 11:13:00.389995+00:00, run_duration=0.159168, state=success, executor_state=success, try_number=1, max_tries=1, job_id=340, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:12:54.855640+00:00, queued_by_job_id=7, pid=56040
2025-02-22 11:13:02,610 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:58.103354+00:00, run_end_date=2025-02-22 11:12:58.252877+00:00, run_duration=0.149523, state=success, executor_state=success, try_number=1, max_tries=1, job_id=339, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:12:54.855640+00:00, queued_by_job_id=7, pid=56021
2025-02-22 11:13:02,610 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:12:56.261644+00:00, run_end_date=2025-02-22 11:12:56.433908+00:00, run_duration=0.172264, state=success, executor_state=success, try_number=1, max_tries=1, job_id=338, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:12:54.855640+00:00, queued_by_job_id=7, pid=55988
2025-02-22 11:13:02,849 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-13T00:00:00+00:00, run_after=2024-05-14T00:00:00+00:00
2025-02-22 11:13:02,912 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-08 00:00:00+00:00: scheduled__2024-05-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:02,912 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-08 00:00:00+00:00, run_id=scheduled__2024-05-08T00:00:00+00:00, run_start_date=2025-02-22 11:12:42.363892+00:00, run_end_date=2025-02-22 11:13:02.912324+00:00, run_duration=20.548432, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-08 00:00:00+00:00, data_interval_end=2024-05-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:02,914 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-09T00:00:00+00:00, run_after=2024-05-10T00:00:00+00:00
2025-02-22 11:13:02,935 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:02,935 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:02,936 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:02,936 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:02,936 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:13:02,936 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:02,937 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:02,937 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:02,937 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:02,938 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:02,938 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:02,938 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:02,938 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:02,938 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:02,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:04,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:06,828 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:08,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:10,480 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:10,481 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:10,481 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:10,481 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:10,488 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:09.992730+00:00, run_end_date=2025-02-22 11:13:10.146218+00:00, run_duration=0.153488, state=success, executor_state=success, try_number=1, max_tries=1, job_id=345, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:02.936503+00:00, queued_by_job_id=7, pid=56151
2025-02-22 11:13:10,489 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:08.183147+00:00, run_end_date=2025-02-22 11:13:08.343110+00:00, run_duration=0.159963, state=success, executor_state=success, try_number=1, max_tries=1, job_id=344, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:02.936503+00:00, queued_by_job_id=7, pid=56132
2025-02-22 11:13:10,489 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:06.212833+00:00, run_end_date=2025-02-22 11:13:06.382655+00:00, run_duration=0.169822, state=success, executor_state=success, try_number=1, max_tries=1, job_id=343, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:02.936503+00:00, queued_by_job_id=7, pid=56114
2025-02-22 11:13:10,489 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:04.420343+00:00, run_end_date=2025-02-22 11:13:04.588109+00:00, run_duration=0.167766, state=success, executor_state=success, try_number=1, max_tries=1, job_id=342, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:02.936503+00:00, queued_by_job_id=7, pid=56094
2025-02-22 11:13:10,651 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-10T00:00:00+00:00, run_after=2024-05-11T00:00:00+00:00
2025-02-22 11:13:10,694 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-09 00:00:00+00:00: scheduled__2024-05-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:10,694 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-09 00:00:00+00:00, run_id=scheduled__2024-05-09T00:00:00+00:00, run_start_date=2025-02-22 11:12:44.483502+00:00, run_end_date=2025-02-22 11:13:10.694448+00:00, run_duration=26.210946, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-09 00:00:00+00:00, data_interval_end=2024-05-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:10,697 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-10T00:00:00+00:00, run_after=2024-05-11T00:00:00+00:00
2025-02-22 11:13:10,721 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:10,722 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:10,722 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:10,722 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:10,722 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:10,725 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:10,725 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:10,725 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:10,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:10,726 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:10,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:10,739 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:12,639 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:14,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:16,516 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:16,517 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:16,517 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:16,524 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:15.956526+00:00, run_end_date=2025-02-22 11:13:16.152608+00:00, run_duration=0.196082, state=success, executor_state=success, try_number=1, max_tries=1, job_id=348, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:10.722876+00:00, queued_by_job_id=7, pid=56209
2025-02-22 11:13:16,524 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:14.115637+00:00, run_end_date=2025-02-22 11:13:14.266186+00:00, run_duration=0.150549, state=success, executor_state=success, try_number=1, max_tries=1, job_id=347, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:10.722876+00:00, queued_by_job_id=7, pid=56190
2025-02-22 11:13:16,525 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:12.145638+00:00, run_end_date=2025-02-22 11:13:12.297595+00:00, run_duration=0.151957, state=success, executor_state=success, try_number=1, max_tries=1, job_id=346, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:10.722876+00:00, queued_by_job_id=7, pid=56171
2025-02-22 11:13:16,679 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-11T00:00:00+00:00, run_after=2024-05-12T00:00:00+00:00
2025-02-22 11:13:16,741 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-10 00:00:00+00:00: scheduled__2024-05-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:16,742 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-10 00:00:00+00:00, run_id=scheduled__2024-05-10T00:00:00+00:00, run_start_date=2025-02-22 11:12:48.616602+00:00, run_end_date=2025-02-22 11:13:16.742085+00:00, run_duration=28.125483, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-10 00:00:00+00:00, data_interval_end=2024-05-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:16,747 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-11T00:00:00+00:00, run_after=2024-05-12T00:00:00+00:00
2025-02-22 11:13:16,771 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:16,771 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:16,771 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:16,772 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:16,773 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:16,774 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:16,774 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:16,774 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:16,787 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:18,628 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:20,431 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:20,432 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:20,439 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:19.957213+00:00, run_end_date=2025-02-22 11:13:20.106100+00:00, run_duration=0.148887, state=success, executor_state=success, try_number=1, max_tries=1, job_id=350, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:16.772399+00:00, queued_by_job_id=7, pid=56255
2025-02-22 11:13:20,440 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:18.161641+00:00, run_end_date=2025-02-22 11:13:18.313009+00:00, run_duration=0.151368, state=success, executor_state=success, try_number=1, max_tries=1, job_id=349, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:16.772399+00:00, queued_by_job_id=7, pid=56237
2025-02-22 11:13:20,580 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-12T00:00:00+00:00, run_after=2024-05-13T00:00:00+00:00
2025-02-22 11:13:20,634 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-11 00:00:00+00:00: scheduled__2024-05-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:20,634 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-11 00:00:00+00:00, run_id=scheduled__2024-05-11T00:00:00+00:00, run_start_date=2025-02-22 11:12:54.804124+00:00, run_end_date=2025-02-22 11:13:20.634793+00:00, run_duration=25.830669, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-11 00:00:00+00:00, data_interval_end=2024-05-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:20,640 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-12T00:00:00+00:00, run_after=2024-05-13T00:00:00+00:00
2025-02-22 11:13:20,664 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:20,664 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:20,664 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:20,666 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:20,666 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:20,680 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:22,523 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:22,531 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:22.018987+00:00, run_end_date=2025-02-22 11:13:22.165561+00:00, run_duration=0.146574, state=success, executor_state=success, try_number=1, max_tries=1, job_id=351, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:20.665309+00:00, queued_by_job_id=7, pid=56276
2025-02-22 11:13:22,799 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-13T00:00:00+00:00, run_after=2024-05-14T00:00:00+00:00
2025-02-22 11:13:22,843 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-12 00:00:00+00:00: scheduled__2024-05-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:22,844 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-12 00:00:00+00:00, run_id=scheduled__2024-05-12T00:00:00+00:00, run_start_date=2025-02-22 11:13:02.872966+00:00, run_end_date=2025-02-22 11:13:22.844553+00:00, run_duration=19.971587, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-12 00:00:00+00:00, data_interval_end=2024-05-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:22,850 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-13T00:00:00+00:00, run_after=2024-05-14T00:00:00+00:00
2025-02-22 11:13:24,021 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-14T00:00:00+00:00, run_after=2024-05-15T00:00:00+00:00
2025-02-22 11:13:24,099 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:24,100 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:24,100 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:24,101 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:24,102 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:24,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:25,969 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:25,976 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:25.462614+00:00, run_end_date=2025-02-22 11:13:25.625778+00:00, run_duration=0.163164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=352, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:24.100659+00:00, queued_by_job_id=7, pid=56298
2025-02-22 11:13:26,121 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-15T00:00:00+00:00, run_after=2024-05-16T00:00:00+00:00
2025-02-22 11:13:26,197 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:26,198 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:26,198 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:26,198 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:26,200 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:26,200 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:26,200 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:26,200 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:26,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:28,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:30,004 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:30,004 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:30,012 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:29.535027+00:00, run_end_date=2025-02-22 11:13:29.708215+00:00, run_duration=0.173188, state=success, executor_state=success, try_number=1, max_tries=1, job_id=354, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:26.198702+00:00, queued_by_job_id=7, pid=56337
2025-02-22 11:13:30,012 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:27.545535+00:00, run_end_date=2025-02-22 11:13:27.846228+00:00, run_duration=0.300693, state=success, executor_state=success, try_number=1, max_tries=1, job_id=353, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:26.198702+00:00, queued_by_job_id=7, pid=56318
2025-02-22 11:13:30,177 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-16T00:00:00+00:00, run_after=2024-05-17T00:00:00+00:00
2025-02-22 11:13:30,265 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:30,266 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:30,266 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:30,266 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:30,266 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:30,268 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:30,268 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:30,268 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:30,268 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:30,268 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:30,268 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:30,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:32,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:33,954 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:35,875 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:35,876 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:35,876 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:35,883 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:35.371046+00:00, run_end_date=2025-02-22 11:13:35.530026+00:00, run_duration=0.15898, state=success, executor_state=success, try_number=1, max_tries=1, job_id=357, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:30.266643+00:00, queued_by_job_id=7, pid=56394
2025-02-22 11:13:35,883 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:33.471402+00:00, run_end_date=2025-02-22 11:13:33.635995+00:00, run_duration=0.164593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=356, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:30.266643+00:00, queued_by_job_id=7, pid=56376
2025-02-22 11:13:35,883 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:31.637779+00:00, run_end_date=2025-02-22 11:13:31.785407+00:00, run_duration=0.147628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=355, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:30.266643+00:00, queued_by_job_id=7, pid=56357
2025-02-22 11:13:36,072 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-17T00:00:00+00:00, run_after=2024-05-18T00:00:00+00:00
2025-02-22 11:13:36,168 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:36,169 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:36,169 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:36,169 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:36,169 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:13:36,169 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:36,171 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:36,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:36,171 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:36,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:36,171 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:36,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:36,172 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:36,172 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:36,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:37,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:39,792 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:41,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:43,594 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:43,595 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:43,595 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:43,595 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:43,602 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:43.102512+00:00, run_end_date=2025-02-22 11:13:43.255794+00:00, run_duration=0.153282, state=success, executor_state=success, try_number=1, max_tries=1, job_id=361, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:36.169764+00:00, queued_by_job_id=7, pid=56486
2025-02-22 11:13:43,603 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:41.175385+00:00, run_end_date=2025-02-22 11:13:41.444475+00:00, run_duration=0.26909, state=success, executor_state=success, try_number=1, max_tries=1, job_id=360, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:36.169764+00:00, queued_by_job_id=7, pid=56468
2025-02-22 11:13:43,603 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:39.318911+00:00, run_end_date=2025-02-22 11:13:39.488149+00:00, run_duration=0.169238, state=success, executor_state=success, try_number=1, max_tries=1, job_id=359, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:36.169764+00:00, queued_by_job_id=7, pid=56448
2025-02-22 11:13:43,603 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:37.540047+00:00, run_end_date=2025-02-22 11:13:37.692649+00:00, run_duration=0.152602, state=success, executor_state=success, try_number=1, max_tries=1, job_id=358, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:36.169764+00:00, queued_by_job_id=7, pid=56430
2025-02-22 11:13:43,772 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-18T00:00:00+00:00, run_after=2024-05-19T00:00:00+00:00
2025-02-22 11:13:43,847 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-13 00:00:00+00:00: scheduled__2024-05-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:43,847 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-13 00:00:00+00:00, run_id=scheduled__2024-05-13T00:00:00+00:00, run_start_date=2025-02-22 11:13:24.049212+00:00, run_end_date=2025-02-22 11:13:43.847363+00:00, run_duration=19.798151, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-13 00:00:00+00:00, data_interval_end=2024-05-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:43,850 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-14T00:00:00+00:00, run_after=2024-05-15T00:00:00+00:00
2025-02-22 11:13:43,876 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:43,876 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:43,877 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:43,877 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:43,877 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:13:43,877 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:43,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:13:43,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:43,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:43,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:43,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:43,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:43,880 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:43,880 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:43,894 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:45,709 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:47,579 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:49,374 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:51,175 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:51,176 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:51,176 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:51,176 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:51,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:50.700626+00:00, run_end_date=2025-02-22 11:13:50.848793+00:00, run_duration=0.148167, state=success, executor_state=success, try_number=1, max_tries=1, job_id=365, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:43.877705+00:00, queued_by_job_id=7, pid=56562
2025-02-22 11:13:51,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:48.911653+00:00, run_end_date=2025-02-22 11:13:49.060991+00:00, run_duration=0.149338, state=success, executor_state=success, try_number=1, max_tries=1, job_id=364, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:43.877705+00:00, queued_by_job_id=7, pid=56544
2025-02-22 11:13:51,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:47.086021+00:00, run_end_date=2025-02-22 11:13:47.244001+00:00, run_duration=0.15798, state=success, executor_state=success, try_number=1, max_tries=1, job_id=363, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:43.877705+00:00, queued_by_job_id=7, pid=56525
2025-02-22 11:13:51,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:45.212992+00:00, run_end_date=2025-02-22 11:13:45.361045+00:00, run_duration=0.148053, state=success, executor_state=success, try_number=1, max_tries=1, job_id=362, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:13:43.877705+00:00, queued_by_job_id=7, pid=56506
2025-02-22 11:13:51,342 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-15T00:00:00+00:00, run_after=2024-05-16T00:00:00+00:00
2025-02-22 11:13:51,413 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-14 00:00:00+00:00: scheduled__2024-05-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:51,414 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-14 00:00:00+00:00, run_id=scheduled__2024-05-14T00:00:00+00:00, run_start_date=2025-02-22 11:13:26.145769+00:00, run_end_date=2025-02-22 11:13:51.413948+00:00, run_duration=25.268179, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-14 00:00:00+00:00, data_interval_end=2024-05-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:51,418 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-15T00:00:00+00:00, run_after=2024-05-16T00:00:00+00:00
2025-02-22 11:13:51,441 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:51,441 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:51,441 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:51,442 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:13:51,442 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:51,444 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:13:51,444 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:51,444 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:51,444 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:51,444 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:51,444 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:51,458 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:53,312 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:55,453 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:57,340 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:57,341 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:57,341 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:13:57,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:56.859262+00:00, run_end_date=2025-02-22 11:13:57.016136+00:00, run_duration=0.156874, state=success, executor_state=success, try_number=1, max_tries=1, job_id=368, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:51.442492+00:00, queued_by_job_id=7, pid=56636
2025-02-22 11:13:57,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:54.793431+00:00, run_end_date=2025-02-22 11:13:54.946204+00:00, run_duration=0.152773, state=success, executor_state=success, try_number=1, max_tries=1, job_id=367, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:51.442492+00:00, queued_by_job_id=7, pid=56602
2025-02-22 11:13:57,359 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:52.822249+00:00, run_end_date=2025-02-22 11:13:52.969815+00:00, run_duration=0.147566, state=success, executor_state=success, try_number=1, max_tries=1, job_id=366, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:13:51.442492+00:00, queued_by_job_id=7, pid=56584
2025-02-22 11:13:57,835 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-16T00:00:00+00:00, run_after=2024-05-17T00:00:00+00:00
2025-02-22 11:13:57,898 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-15 00:00:00+00:00: scheduled__2024-05-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:13:57,899 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-15 00:00:00+00:00, run_id=scheduled__2024-05-15T00:00:00+00:00, run_start_date=2025-02-22 11:13:30.204520+00:00, run_end_date=2025-02-22 11:13:57.899016+00:00, run_duration=27.694496, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-15 00:00:00+00:00, data_interval_end=2024-05-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:13:57,904 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-16T00:00:00+00:00, run_after=2024-05-17T00:00:00+00:00
2025-02-22 11:13:57,927 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:57,928 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:13:57,928 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:13:57,928 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:13:57,930 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:13:57,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:57,930 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:13:57,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:57,946 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:13:59,946 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:01,951 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:01,951 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:01,959 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:01.471285+00:00, run_end_date=2025-02-22 11:14:01.646940+00:00, run_duration=0.175655, state=success, executor_state=success, try_number=1, max_tries=1, job_id=370, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:13:57.928683+00:00, queued_by_job_id=7, pid=56701
2025-02-22 11:14:01,959 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:13:59.385446+00:00, run_end_date=2025-02-22 11:13:59.576920+00:00, run_duration=0.191474, state=success, executor_state=success, try_number=1, max_tries=1, job_id=369, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:13:57.928683+00:00, queued_by_job_id=7, pid=56672
2025-02-22 11:14:02,413 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-17T00:00:00+00:00, run_after=2024-05-18T00:00:00+00:00
2025-02-22 11:14:02,447 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-16 00:00:00+00:00: scheduled__2024-05-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:02,448 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-16 00:00:00+00:00, run_id=scheduled__2024-05-16T00:00:00+00:00, run_start_date=2025-02-22 11:13:36.103934+00:00, run_end_date=2025-02-22 11:14:02.448109+00:00, run_duration=26.344175, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-16 00:00:00+00:00, data_interval_end=2024-05-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:02,451 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-17T00:00:00+00:00, run_after=2024-05-18T00:00:00+00:00
2025-02-22 11:14:02,474 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:02,474 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:02,474 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:02,476 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:02,476 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:02,489 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:04,437 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:04,445 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:03.888234+00:00, run_end_date=2025-02-22 11:14:04.071707+00:00, run_duration=0.183473, state=success, executor_state=success, try_number=1, max_tries=1, job_id=371, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:02.474919+00:00, queued_by_job_id=7, pid=56743
2025-02-22 11:14:05,001 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-19T00:00:00+00:00, run_after=2024-05-20T00:00:00+00:00
2025-02-22 11:14:05,051 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-17 00:00:00+00:00: scheduled__2024-05-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:05,051 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-17 00:00:00+00:00, run_id=scheduled__2024-05-17T00:00:00+00:00, run_start_date=2025-02-22 11:13:43.804225+00:00, run_end_date=2025-02-22 11:14:05.051948+00:00, run_duration=21.247723, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-17 00:00:00+00:00, data_interval_end=2024-05-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:05,054 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-18T00:00:00+00:00, run_after=2024-05-19T00:00:00+00:00
2025-02-22 11:14:05,074 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:05,074 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:05,074 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:05,075 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:05,075 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:05,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:06,984 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:06,991 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:06.491920+00:00, run_end_date=2025-02-22 11:14:06.658572+00:00, run_duration=0.166652, state=success, executor_state=success, try_number=1, max_tries=1, job_id=372, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:05.074567+00:00, queued_by_job_id=7, pid=56794
2025-02-22 11:14:07,141 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-19T00:00:00+00:00, run_after=2024-05-20T00:00:00+00:00
2025-02-22 11:14:07,212 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:07,212 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:07,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:07,216 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:07,216 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:07,230 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:09,056 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:09,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:08.567947+00:00, run_end_date=2025-02-22 11:14:08.732649+00:00, run_duration=0.164702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=373, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:07.213844+00:00, queued_by_job_id=7, pid=56814
2025-02-22 11:14:09,207 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-20T00:00:00+00:00, run_after=2024-05-21T00:00:00+00:00
2025-02-22 11:14:09,293 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:09,293 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:09,293 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:09,293 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:09,295 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:09,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:09,295 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:09,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:09,311 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:11,201 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:13,050 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:13,050 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:13,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:12.596257+00:00, run_end_date=2025-02-22 11:14:12.765935+00:00, run_duration=0.169678, state=success, executor_state=success, try_number=1, max_tries=1, job_id=375, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:09.294156+00:00, queued_by_job_id=7, pid=56853
2025-02-22 11:14:13,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:10.708654+00:00, run_end_date=2025-02-22 11:14:10.869809+00:00, run_duration=0.161155, state=success, executor_state=success, try_number=1, max_tries=1, job_id=374, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:09.294156+00:00, queued_by_job_id=7, pid=56834
2025-02-22 11:14:13,251 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-21T00:00:00+00:00, run_after=2024-05-22T00:00:00+00:00
2025-02-22 11:14:13,334 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:13,335 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:13,335 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:13,335 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:13,335 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:13,337 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:13,337 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:13,337 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:13,337 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:13,337 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:13,337 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:13,583 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:15,452 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:17,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:19,268 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:19,269 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:19,269 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:19,282 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:18.744891+00:00, run_end_date=2025-02-22 11:14:18.924125+00:00, run_duration=0.179234, state=success, executor_state=success, try_number=1, max_tries=1, job_id=378, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:13.335700+00:00, queued_by_job_id=7, pid=56910
2025-02-22 11:14:19,283 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:16.787932+00:00, run_end_date=2025-02-22 11:14:16.967100+00:00, run_duration=0.179168, state=success, executor_state=success, try_number=1, max_tries=1, job_id=377, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:13.335700+00:00, queued_by_job_id=7, pid=56892
2025-02-22 11:14:19,283 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:14.936878+00:00, run_end_date=2025-02-22 11:14:15.110766+00:00, run_duration=0.173888, state=success, executor_state=success, try_number=1, max_tries=1, job_id=376, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:13.335700+00:00, queued_by_job_id=7, pid=56873
2025-02-22 11:14:19,461 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-22T00:00:00+00:00, run_after=2024-05-23T00:00:00+00:00
2025-02-22 11:14:19,522 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-18 00:00:00+00:00: scheduled__2024-05-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:19,522 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-18 00:00:00+00:00, run_id=scheduled__2024-05-18T00:00:00+00:00, run_start_date=2025-02-22 11:14:05.026376+00:00, run_end_date=2025-02-22 11:14:19.522676+00:00, run_duration=14.4963, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-18 00:00:00+00:00, data_interval_end=2024-05-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:19,525 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-19T00:00:00+00:00, run_after=2024-05-20T00:00:00+00:00
2025-02-22 11:14:19,548 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:19,548 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:19,548 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:19,548 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:19,548 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:19,550 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:19,550 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:19,550 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:19,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:19,551 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:19,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:19,567 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:21,520 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:23,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:25,190 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:25,190 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:25,190 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:25,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:24.723975+00:00, run_end_date=2025-02-22 11:14:24.887684+00:00, run_duration=0.163709, state=success, executor_state=success, try_number=1, max_tries=1, job_id=381, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:19.549167+00:00, queued_by_job_id=7, pid=56984
2025-02-22 11:14:25,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:22.841945+00:00, run_end_date=2025-02-22 11:14:22.995531+00:00, run_duration=0.153586, state=success, executor_state=success, try_number=1, max_tries=1, job_id=380, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:19.549167+00:00, queued_by_job_id=7, pid=56949
2025-02-22 11:14:25,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:20.903046+00:00, run_end_date=2025-02-22 11:14:21.170951+00:00, run_duration=0.267905, state=success, executor_state=success, try_number=1, max_tries=1, job_id=379, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:19.549167+00:00, queued_by_job_id=7, pid=56931
2025-02-22 11:14:25,365 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-20T00:00:00+00:00, run_after=2024-05-21T00:00:00+00:00
2025-02-22 11:14:25,430 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:25,431 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:25,431 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:25,431 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:25,431 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:25,433 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:25,433 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:25,433 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:25,433 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:25,434 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:25,434 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:25,447 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:27,322 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:29,142 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:30,963 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:30,963 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:30,963 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:30,971 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:30.476173+00:00, run_end_date=2025-02-22 11:14:30.622284+00:00, run_duration=0.146111, state=success, executor_state=success, try_number=1, max_tries=1, job_id=384, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:25.431825+00:00, queued_by_job_id=7, pid=57042
2025-02-22 11:14:30,972 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:28.652987+00:00, run_end_date=2025-02-22 11:14:28.804329+00:00, run_duration=0.151342, state=success, executor_state=success, try_number=1, max_tries=1, job_id=383, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:25.431825+00:00, queued_by_job_id=7, pid=57023
2025-02-22 11:14:30,972 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:26.782291+00:00, run_end_date=2025-02-22 11:14:26.970636+00:00, run_duration=0.188345, state=success, executor_state=success, try_number=1, max_tries=1, job_id=382, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:25.431825+00:00, queued_by_job_id=7, pid=57004
2025-02-22 11:14:31,137 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-21T00:00:00+00:00, run_after=2024-05-22T00:00:00+00:00
2025-02-22 11:14:31,200 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-19 00:00:00+00:00: scheduled__2024-05-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:31,200 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-19 00:00:00+00:00, run_id=scheduled__2024-05-19T00:00:00+00:00, run_start_date=2025-02-22 11:14:09.239740+00:00, run_end_date=2025-02-22 11:14:31.200496+00:00, run_duration=21.960756, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-19 00:00:00+00:00, data_interval_end=2024-05-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:31,205 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-20T00:00:00+00:00, run_after=2024-05-21T00:00:00+00:00
2025-02-22 11:14:31,234 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:31,234 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:31,234 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:31,235 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:31,238 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:31,238 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:31,238 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:31,238 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:31,251 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:33,062 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:34,869 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:34,869 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:34,877 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:34.396506+00:00, run_end_date=2025-02-22 11:14:34.563375+00:00, run_duration=0.166869, state=success, executor_state=success, try_number=1, max_tries=1, job_id=386, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:31.235646+00:00, queued_by_job_id=7, pid=57081
2025-02-22 11:14:34,878 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:32.578724+00:00, run_end_date=2025-02-22 11:14:32.734431+00:00, run_duration=0.155707, state=success, executor_state=success, try_number=1, max_tries=1, job_id=385, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:31.235646+00:00, queued_by_job_id=7, pid=57062
2025-02-22 11:14:35,021 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-21T00:00:00+00:00, run_after=2024-05-22T00:00:00+00:00
2025-02-22 11:14:35,068 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-20 00:00:00+00:00: scheduled__2024-05-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:35,068 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-20 00:00:00+00:00, run_id=scheduled__2024-05-20T00:00:00+00:00, run_start_date=2025-02-22 11:14:13.280322+00:00, run_end_date=2025-02-22 11:14:35.068605+00:00, run_duration=21.788283, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-20 00:00:00+00:00, data_interval_end=2024-05-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:35,074 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-21T00:00:00+00:00, run_after=2024-05-22T00:00:00+00:00
2025-02-22 11:14:35,095 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:35,095 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:35,095 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:35,097 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:35,097 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:35,149 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:37,203 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:37,211 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:36.525321+00:00, run_end_date=2025-02-22 11:14:36.848308+00:00, run_duration=0.322987, state=success, executor_state=success, try_number=1, max_tries=1, job_id=387, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:35.096229+00:00, queued_by_job_id=7, pid=57101
2025-02-22 11:14:37,392 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-22T00:00:00+00:00, run_after=2024-05-23T00:00:00+00:00
2025-02-22 11:14:37,436 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-21 00:00:00+00:00: scheduled__2024-05-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:37,436 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-21 00:00:00+00:00, run_id=scheduled__2024-05-21T00:00:00+00:00, run_start_date=2025-02-22 11:14:19.486167+00:00, run_end_date=2025-02-22 11:14:37.436617+00:00, run_duration=17.95045, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-21 00:00:00+00:00, data_interval_end=2024-05-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:37,442 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-22T00:00:00+00:00, run_after=2024-05-23T00:00:00+00:00
2025-02-22 11:14:38,613 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-23T00:00:00+00:00, run_after=2024-05-24T00:00:00+00:00
2025-02-22 11:14:38,687 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:38,687 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:38,687 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:38,689 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:38,689 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:38,702 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:40,527 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:40,535 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:40.020742+00:00, run_end_date=2025-02-22 11:14:40.169958+00:00, run_duration=0.149216, state=success, executor_state=success, try_number=1, max_tries=1, job_id=388, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:38.688173+00:00, queued_by_job_id=7, pid=57126
2025-02-22 11:14:40,684 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-24T00:00:00+00:00, run_after=2024-05-25T00:00:00+00:00
2025-02-22 11:14:40,774 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:40,775 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:40,775 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:40,775 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:40,777 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:40,777 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:40,777 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:40,777 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:40,790 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:42,653 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:44,586 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:44,587 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:44,595 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:43.975473+00:00, run_end_date=2025-02-22 11:14:44.126839+00:00, run_duration=0.151366, state=success, executor_state=success, try_number=1, max_tries=1, job_id=390, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:40.775660+00:00, queued_by_job_id=7, pid=57175
2025-02-22 11:14:44,595 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:42.167650+00:00, run_end_date=2025-02-22 11:14:42.327412+00:00, run_duration=0.159762, state=success, executor_state=success, try_number=1, max_tries=1, job_id=389, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:40.775660+00:00, queued_by_job_id=7, pid=57146
2025-02-22 11:14:44,761 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-25T00:00:00+00:00, run_after=2024-05-26T00:00:00+00:00
2025-02-22 11:14:44,879 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:44,879 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:44,880 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:44,880 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:44,880 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:44,883 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:44,883 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:44,884 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:44,884 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:44,884 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:44,884 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:44,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:46,990 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:48,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:50,791 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:50,792 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:50,792 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:50,799 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:50.268396+00:00, run_end_date=2025-02-22 11:14:50.421223+00:00, run_duration=0.152827, state=success, executor_state=success, try_number=1, max_tries=1, job_id=393, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:44.881141+00:00, queued_by_job_id=7, pid=57233
2025-02-22 11:14:50,800 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:48.326545+00:00, run_end_date=2025-02-22 11:14:48.474684+00:00, run_duration=0.148139, state=success, executor_state=success, try_number=1, max_tries=1, job_id=392, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:44.881141+00:00, queued_by_job_id=7, pid=57215
2025-02-22 11:14:50,800 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:46.440429+00:00, run_end_date=2025-02-22 11:14:46.657234+00:00, run_duration=0.216805, state=success, executor_state=success, try_number=1, max_tries=1, job_id=391, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:44.881141+00:00, queued_by_job_id=7, pid=57196
2025-02-22 11:14:51,071 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-26T00:00:00+00:00, run_after=2024-05-27T00:00:00+00:00
2025-02-22 11:14:51,155 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:51,156 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:51,156 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:51,156 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:51,156 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:14:51,156 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:51,158 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:51,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:51,158 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:51,159 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:51,159 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:51,159 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:51,159 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:51,159 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:51,174 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:53,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:55,055 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:56,881 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:58,712 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:58,713 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:58,713 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:58,713 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:14:58,718 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:58.278202+00:00, run_end_date=2025-02-22 11:14:58.434505+00:00, run_duration=0.156303, state=success, executor_state=success, try_number=1, max_tries=1, job_id=397, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:51.157024+00:00, queued_by_job_id=7, pid=57325
2025-02-22 11:14:58,719 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:56.419994+00:00, run_end_date=2025-02-22 11:14:56.567256+00:00, run_duration=0.147262, state=success, executor_state=success, try_number=1, max_tries=1, job_id=396, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:51.157024+00:00, queued_by_job_id=7, pid=57307
2025-02-22 11:14:58,719 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:54.568866+00:00, run_end_date=2025-02-22 11:14:54.719528+00:00, run_duration=0.150662, state=success, executor_state=success, try_number=1, max_tries=1, job_id=395, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:51.157024+00:00, queued_by_job_id=7, pid=57273
2025-02-22 11:14:58,719 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:14:52.646095+00:00, run_end_date=2025-02-22 11:14:52.824719+00:00, run_duration=0.178624, state=success, executor_state=success, try_number=1, max_tries=1, job_id=394, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:51.157024+00:00, queued_by_job_id=7, pid=57254
2025-02-22 11:14:58,884 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-27T00:00:00+00:00, run_after=2024-05-28T00:00:00+00:00
2025-02-22 11:14:58,947 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-22 00:00:00+00:00: scheduled__2024-05-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:14:58,947 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-22 00:00:00+00:00, run_id=scheduled__2024-05-22T00:00:00+00:00, run_start_date=2025-02-22 11:14:38.639603+00:00, run_end_date=2025-02-22 11:14:58.947482+00:00, run_duration=20.307879, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-22 00:00:00+00:00, data_interval_end=2024-05-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:14:58,949 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-23T00:00:00+00:00, run_after=2024-05-24T00:00:00+00:00
2025-02-22 11:14:58,969 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:58,969 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:14:58,969 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:14:58,969 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:14:58,969 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:14:58,970 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:14:58,971 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:14:58,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:58,971 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:14:58,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:58,971 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:14:58,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:58,971 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:14:58,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:14:58,986 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:00,800 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:02,625 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:04,393 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:06,222 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:06,223 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:06,223 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:06,224 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:06,240 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:05.723614+00:00, run_end_date=2025-02-22 11:15:05.914820+00:00, run_duration=0.191206, state=success, executor_state=success, try_number=1, max_tries=1, job_id=401, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:14:58.970310+00:00, queued_by_job_id=7, pid=57402
2025-02-22 11:15:06,241 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:03.926466+00:00, run_end_date=2025-02-22 11:15:04.077534+00:00, run_duration=0.151068, state=success, executor_state=success, try_number=1, max_tries=1, job_id=400, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:14:58.970310+00:00, queued_by_job_id=7, pid=57383
2025-02-22 11:15:06,242 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:02.143655+00:00, run_end_date=2025-02-22 11:15:02.308744+00:00, run_duration=0.165089, state=success, executor_state=success, try_number=1, max_tries=1, job_id=399, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:14:58.970310+00:00, queued_by_job_id=7, pid=57365
2025-02-22 11:15:06,242 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:00.334014+00:00, run_end_date=2025-02-22 11:15:00.485511+00:00, run_duration=0.151497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=398, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:14:58.970310+00:00, queued_by_job_id=7, pid=57345
2025-02-22 11:15:06,433 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-24T00:00:00+00:00, run_after=2024-05-25T00:00:00+00:00
2025-02-22 11:15:06,479 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-23 00:00:00+00:00: scheduled__2024-05-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:06,479 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-23 00:00:00+00:00, run_id=scheduled__2024-05-23T00:00:00+00:00, run_start_date=2025-02-22 11:14:40.723149+00:00, run_end_date=2025-02-22 11:15:06.479482+00:00, run_duration=25.756333, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-23 00:00:00+00:00, data_interval_end=2024-05-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:06,483 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-24T00:00:00+00:00, run_after=2024-05-25T00:00:00+00:00
2025-02-22 11:15:06,506 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:06,506 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:06,506 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:06,507 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:15:06,507 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:06,509 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:06,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:06,509 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:06,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:06,509 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:06,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:06,523 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:08,351 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:10,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:12,065 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:12,066 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:12,066 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:12,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:11.576903+00:00, run_end_date=2025-02-22 11:15:11.743860+00:00, run_duration=0.166957, state=success, executor_state=success, try_number=1, max_tries=1, job_id=404, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:06.507555+00:00, queued_by_job_id=7, pid=57460
2025-02-22 11:15:12,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:09.666224+00:00, run_end_date=2025-02-22 11:15:09.816214+00:00, run_duration=0.14999, state=success, executor_state=success, try_number=1, max_tries=1, job_id=403, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:06.507555+00:00, queued_by_job_id=7, pid=57442
2025-02-22 11:15:12,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:07.860225+00:00, run_end_date=2025-02-22 11:15:08.009240+00:00, run_duration=0.149015, state=success, executor_state=success, try_number=1, max_tries=1, job_id=402, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:06.507555+00:00, queued_by_job_id=7, pid=57423
2025-02-22 11:15:12,251 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-25T00:00:00+00:00, run_after=2024-05-26T00:00:00+00:00
2025-02-22 11:15:12,315 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-24 00:00:00+00:00: scheduled__2024-05-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:12,315 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-24 00:00:00+00:00, run_id=scheduled__2024-05-24T00:00:00+00:00, run_start_date=2025-02-22 11:14:44.786013+00:00, run_end_date=2025-02-22 11:15:12.315498+00:00, run_duration=27.529485, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-24 00:00:00+00:00, data_interval_end=2024-05-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:12,320 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-25T00:00:00+00:00, run_after=2024-05-26T00:00:00+00:00
2025-02-22 11:15:12,346 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:12,346 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:12,347 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:12,347 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:12,349 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:12,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:12,350 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:12,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:12,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:14,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:16,240 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:16,241 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:16,257 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:15.724931+00:00, run_end_date=2025-02-22 11:15:15.879182+00:00, run_duration=0.154251, state=success, executor_state=success, try_number=1, max_tries=1, job_id=406, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:12.347752+00:00, queued_by_job_id=7, pid=57499
2025-02-22 11:15:16,258 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:13.674875+00:00, run_end_date=2025-02-22 11:15:13.819074+00:00, run_duration=0.144199, state=success, executor_state=success, try_number=1, max_tries=1, job_id=405, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:12.347752+00:00, queued_by_job_id=7, pid=57480
2025-02-22 11:15:16,399 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-26T00:00:00+00:00, run_after=2024-05-27T00:00:00+00:00
2025-02-22 11:15:16,453 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-25 00:00:00+00:00: scheduled__2024-05-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:16,454 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-25 00:00:00+00:00, run_id=scheduled__2024-05-25T00:00:00+00:00, run_start_date=2025-02-22 11:14:51.097812+00:00, run_end_date=2025-02-22 11:15:16.454339+00:00, run_duration=25.356527, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-25 00:00:00+00:00, data_interval_end=2024-05-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:16,460 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-26T00:00:00+00:00, run_after=2024-05-27T00:00:00+00:00
2025-02-22 11:15:16,487 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:16,487 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:16,488 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:16,490 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:16,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:16,505 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:18,669 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:18,685 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:17.844649+00:00, run_end_date=2025-02-22 11:15:18.316757+00:00, run_duration=0.472108, state=success, executor_state=success, try_number=1, max_tries=1, job_id=407, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:16.488884+00:00, queued_by_job_id=7, pid=57519
2025-02-22 11:15:18,866 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-27T00:00:00+00:00, run_after=2024-05-28T00:00:00+00:00
2025-02-22 11:15:18,912 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-26 00:00:00+00:00: scheduled__2024-05-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:18,912 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-26 00:00:00+00:00, run_id=scheduled__2024-05-26T00:00:00+00:00, run_start_date=2025-02-22 11:14:58.911478+00:00, run_end_date=2025-02-22 11:15:18.912642+00:00, run_duration=20.001164, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-26 00:00:00+00:00, data_interval_end=2024-05-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:18,918 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-27T00:00:00+00:00, run_after=2024-05-28T00:00:00+00:00
2025-02-22 11:15:20,190 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-28T00:00:00+00:00, run_after=2024-05-29T00:00:00+00:00
2025-02-22 11:15:20,266 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:20,266 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:20,266 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:20,268 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:15:20,268 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:20,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:22,081 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:22,093 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:21.597002+00:00, run_end_date=2025-02-22 11:15:21.756737+00:00, run_duration=0.159735, state=success, executor_state=success, try_number=1, max_tries=1, job_id=408, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:15:20.267114+00:00, queued_by_job_id=7, pid=57549
2025-02-22 11:15:22,248 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-29T00:00:00+00:00, run_after=2024-05-30T00:00:00+00:00
2025-02-22 11:15:22,330 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:22,330 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:22,330 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:22,330 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:22,332 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:15:22,333 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:22,333 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:22,333 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:22,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:24,182 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:25,979 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:25,980 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:25,988 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:25.492105+00:00, run_end_date=2025-02-22 11:15:25.643069+00:00, run_duration=0.150964, state=success, executor_state=success, try_number=1, max_tries=1, job_id=410, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:22.331307+00:00, queued_by_job_id=7, pid=57589
2025-02-22 11:15:25,988 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:23.681223+00:00, run_end_date=2025-02-22 11:15:23.832699+00:00, run_duration=0.151476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=409, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:15:22.331307+00:00, queued_by_job_id=7, pid=57570
2025-02-22 11:15:26,163 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-30T00:00:00+00:00, run_after=2024-05-31T00:00:00+00:00
2025-02-22 11:15:26,248 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:26,249 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:26,249 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:26,249 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:15:26,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:26,251 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:15:26,251 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:26,251 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:26,251 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:26,251 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:26,251 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:26,266 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:28,084 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:29,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:31,993 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:31,995 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:31,996 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:32,012 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:31.318269+00:00, run_end_date=2025-02-22 11:15:31.579221+00:00, run_duration=0.260952, state=success, executor_state=success, try_number=1, max_tries=1, job_id=413, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:26.249719+00:00, queued_by_job_id=7, pid=57646
2025-02-22 11:15:32,013 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:29.458103+00:00, run_end_date=2025-02-22 11:15:29.608436+00:00, run_duration=0.150333, state=success, executor_state=success, try_number=1, max_tries=1, job_id=412, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:26.249719+00:00, queued_by_job_id=7, pid=57627
2025-02-22 11:15:32,013 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:27.585172+00:00, run_end_date=2025-02-22 11:15:27.734690+00:00, run_duration=0.149518, state=success, executor_state=success, try_number=1, max_tries=1, job_id=411, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:15:26.249719+00:00, queued_by_job_id=7, pid=57608
2025-02-22 11:15:32,317 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-31T00:00:00+00:00, run_after=2024-06-01T00:00:00+00:00
2025-02-22 11:15:32,406 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:32,407 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:32,407 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:32,407 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:15:32,407 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:15:32,407 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:32,409 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:15:32,409 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:32,409 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:32,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:32,410 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:32,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:32,410 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:32,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:32,424 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:34,271 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:36,172 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:38,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:39,923 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:39,923 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:39,923 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:39,923 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:39,931 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:39.444018+00:00, run_end_date=2025-02-22 11:15:39.605472+00:00, run_duration=0.161454, state=success, executor_state=success, try_number=1, max_tries=1, job_id=417, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:32.408000+00:00, queued_by_job_id=7, pid=57738
2025-02-22 11:15:39,931 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:37.515317+00:00, run_end_date=2025-02-22 11:15:37.695464+00:00, run_duration=0.180147, state=success, executor_state=success, try_number=1, max_tries=1, job_id=416, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:32.408000+00:00, queued_by_job_id=7, pid=57718
2025-02-22 11:15:39,931 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:35.603718+00:00, run_end_date=2025-02-22 11:15:35.825347+00:00, run_duration=0.221629, state=success, executor_state=success, try_number=1, max_tries=1, job_id=415, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:32.408000+00:00, queued_by_job_id=7, pid=57700
2025-02-22 11:15:39,931 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:33.757963+00:00, run_end_date=2025-02-22 11:15:33.914027+00:00, run_duration=0.156064, state=success, executor_state=success, try_number=1, max_tries=1, job_id=414, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:15:32.408000+00:00, queued_by_job_id=7, pid=57673
2025-02-22 11:15:40,103 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-01T00:00:00+00:00, run_after=2024-06-02T00:00:00+00:00
2025-02-22 11:15:40,197 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-27 00:00:00+00:00: scheduled__2024-05-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:40,198 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-27 00:00:00+00:00, run_id=scheduled__2024-05-27T00:00:00+00:00, run_start_date=2025-02-22 11:15:20.217570+00:00, run_end_date=2025-02-22 11:15:40.198174+00:00, run_duration=19.980604, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-27 00:00:00+00:00, data_interval_end=2024-05-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:40,201 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-28T00:00:00+00:00, run_after=2024-05-29T00:00:00+00:00
2025-02-22 11:15:40,224 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:40,224 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:40,224 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:40,224 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:15:40,224 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:15:40,224 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:40,226 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:15:40,226 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:40,226 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:40,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:40,227 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:40,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:40,227 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:40,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:40,285 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:42,100 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:43,912 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:45,809 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:47,558 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-05-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:47,558 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:47,558 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:47,558 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:47,567 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:47.098497+00:00, run_end_date=2025-02-22 11:15:47.245856+00:00, run_duration=0.147359, state=success, executor_state=success, try_number=1, max_tries=1, job_id=421, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:40.225056+00:00, queued_by_job_id=7, pid=57814
2025-02-22 11:15:47,567 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:45.221946+00:00, run_end_date=2025-02-22 11:15:45.457510+00:00, run_duration=0.235564, state=success, executor_state=success, try_number=1, max_tries=1, job_id=420, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:40.225056+00:00, queued_by_job_id=7, pid=57795
2025-02-22 11:15:47,567 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:43.407184+00:00, run_end_date=2025-02-22 11:15:43.558003+00:00, run_duration=0.150819, state=success, executor_state=success, try_number=1, max_tries=1, job_id=419, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:40.225056+00:00, queued_by_job_id=7, pid=57777
2025-02-22 11:15:47,567 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-05-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:41.612912+00:00, run_end_date=2025-02-22 11:15:41.772528+00:00, run_duration=0.159616, state=success, executor_state=success, try_number=1, max_tries=1, job_id=418, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:15:40.225056+00:00, queued_by_job_id=7, pid=57758
2025-02-22 11:15:47,749 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-29T00:00:00+00:00, run_after=2024-05-30T00:00:00+00:00
2025-02-22 11:15:47,794 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-28 00:00:00+00:00: scheduled__2024-05-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:47,795 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-28 00:00:00+00:00, run_id=scheduled__2024-05-28T00:00:00+00:00, run_start_date=2025-02-22 11:15:22.274766+00:00, run_end_date=2025-02-22 11:15:47.795080+00:00, run_duration=25.520314, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-28 00:00:00+00:00, data_interval_end=2024-05-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:47,798 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-29T00:00:00+00:00, run_after=2024-05-30T00:00:00+00:00
2025-02-22 11:15:47,821 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:47,822 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:47,822 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:47,822 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:15:47,822 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:47,824 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:15:47,824 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:47,824 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:47,824 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:47,825 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:47,825 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:47,838 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:49,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:51,674 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:53,461 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-05-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:53,462 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:53,462 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:53,470 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:52.988376+00:00, run_end_date=2025-02-22 11:15:53.148254+00:00, run_duration=0.159878, state=success, executor_state=success, try_number=1, max_tries=1, job_id=424, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:47.822810+00:00, queued_by_job_id=7, pid=57872
2025-02-22 11:15:53,470 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:51.029007+00:00, run_end_date=2025-02-22 11:15:51.288148+00:00, run_duration=0.259141, state=success, executor_state=success, try_number=1, max_tries=1, job_id=423, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:47.822810+00:00, queued_by_job_id=7, pid=57853
2025-02-22 11:15:53,470 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-05-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:49.137179+00:00, run_end_date=2025-02-22 11:15:49.318833+00:00, run_duration=0.181654, state=success, executor_state=success, try_number=1, max_tries=1, job_id=422, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:15:47.822810+00:00, queued_by_job_id=7, pid=57834
2025-02-22 11:15:53,632 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-30T00:00:00+00:00, run_after=2024-05-31T00:00:00+00:00
2025-02-22 11:15:53,695 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-29 00:00:00+00:00: scheduled__2024-05-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:53,695 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-29 00:00:00+00:00, run_id=scheduled__2024-05-29T00:00:00+00:00, run_start_date=2025-02-22 11:15:26.187997+00:00, run_end_date=2025-02-22 11:15:53.695596+00:00, run_duration=27.507599, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-29 00:00:00+00:00, data_interval_end=2024-05-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:53,700 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-30T00:00:00+00:00, run_after=2024-05-31T00:00:00+00:00
2025-02-22 11:15:53,731 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:53,731 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:53,732 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:15:53,732 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:53,735 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:15:53,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:53,735 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:53,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:53,750 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:55,551 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:57,327 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-05-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:57,328 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:57,335 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:56.856431+00:00, run_end_date=2025-02-22 11:15:57.011234+00:00, run_duration=0.154803, state=success, executor_state=success, try_number=1, max_tries=1, job_id=426, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:53.732838+00:00, queued_by_job_id=7, pid=57918
2025-02-22 11:15:57,335 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-05-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:55.069553+00:00, run_end_date=2025-02-22 11:15:55.217745+00:00, run_duration=0.148192, state=success, executor_state=success, try_number=1, max_tries=1, job_id=425, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:15:53.732838+00:00, queued_by_job_id=7, pid=57892
2025-02-22 11:15:57,573 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-31T00:00:00+00:00, run_after=2024-06-01T00:00:00+00:00
2025-02-22 11:15:57,630 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-30 00:00:00+00:00: scheduled__2024-05-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:57,631 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-30 00:00:00+00:00, run_id=scheduled__2024-05-30T00:00:00+00:00, run_start_date=2025-02-22 11:15:32.342525+00:00, run_end_date=2025-02-22 11:15:57.631169+00:00, run_duration=25.288644, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-30 00:00:00+00:00, data_interval_end=2024-05-31 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:57,637 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-05-31T00:00:00+00:00, run_after=2024-06-01T00:00:00+00:00
2025-02-22 11:15:57,665 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:57,665 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:15:57,665 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-05-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:15:57,668 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:15:57,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:57,682 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:15:59,650 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-05-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:15:59,663 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-05-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:15:59.039160+00:00, run_end_date=2025-02-22 11:15:59.320641+00:00, run_duration=0.281481, state=success, executor_state=success, try_number=1, max_tries=1, job_id=427, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:15:57.666423+00:00, queued_by_job_id=7, pid=57940
2025-02-22 11:15:59,838 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-01T00:00:00+00:00, run_after=2024-06-02T00:00:00+00:00
2025-02-22 11:15:59,882 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-05-31 00:00:00+00:00: scheduled__2024-05-31T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:15:59,883 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-05-31 00:00:00+00:00, run_id=scheduled__2024-05-31T00:00:00+00:00, run_start_date=2025-02-22 11:15:40.131972+00:00, run_end_date=2025-02-22 11:15:59.883385+00:00, run_duration=19.751413, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-05-31 00:00:00+00:00, data_interval_end=2024-06-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:15:59,889 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-01T00:00:00+00:00, run_after=2024-06-02T00:00:00+00:00
2025-02-22 11:16:01,064 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-02T00:00:00+00:00, run_after=2024-06-03T00:00:00+00:00
2025-02-22 11:16:01,199 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:01,200 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:01,200 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:01,201 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:01,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:01,217 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:03,040 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:03,048 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:02.556014+00:00, run_end_date=2025-02-22 11:16:02.714987+00:00, run_duration=0.158973, state=success, executor_state=success, try_number=1, max_tries=1, job_id=428, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:01.200644+00:00, queued_by_job_id=7, pid=57962
2025-02-22 11:16:03,197 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-03T00:00:00+00:00, run_after=2024-06-04T00:00:00+00:00
2025-02-22 11:16:03,270 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:03,271 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:03,271 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:03,271 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:03,273 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:03,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:03,273 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:03,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:03,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:05,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:06,903 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:06,904 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:06,911 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:06.407121+00:00, run_end_date=2025-02-22 11:16:06.584042+00:00, run_duration=0.176921, state=success, executor_state=success, try_number=1, max_tries=1, job_id=430, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:03.271760+00:00, queued_by_job_id=7, pid=58001
2025-02-22 11:16:06,912 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:04.612761+00:00, run_end_date=2025-02-22 11:16:04.776373+00:00, run_duration=0.163612, state=success, executor_state=success, try_number=1, max_tries=1, job_id=429, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:03.271760+00:00, queued_by_job_id=7, pid=57982
2025-02-22 11:16:07,091 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-04T00:00:00+00:00, run_after=2024-06-05T00:00:00+00:00
2025-02-22 11:16:07,178 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:07,178 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:07,178 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:07,178 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:07,179 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:07,181 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:07,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:07,182 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:07,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:07,182 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:07,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:07,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:09,017 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:10,838 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:12,646 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:12,647 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:12,647 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:12,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:12.166309+00:00, run_end_date=2025-02-22 11:16:12.314424+00:00, run_duration=0.148115, state=success, executor_state=success, try_number=1, max_tries=1, job_id=433, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:07.179575+00:00, queued_by_job_id=7, pid=58074
2025-02-22 11:16:12,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:10.326092+00:00, run_end_date=2025-02-22 11:16:10.495756+00:00, run_duration=0.169664, state=success, executor_state=success, try_number=1, max_tries=1, job_id=432, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:07.179575+00:00, queued_by_job_id=7, pid=58055
2025-02-22 11:16:12,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:08.530455+00:00, run_end_date=2025-02-22 11:16:08.680574+00:00, run_duration=0.150119, state=success, executor_state=success, try_number=1, max_tries=1, job_id=431, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:07.179575+00:00, queued_by_job_id=7, pid=58029
2025-02-22 11:16:12,828 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-05T00:00:00+00:00, run_after=2024-06-06T00:00:00+00:00
2025-02-22 11:16:12,923 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:12,923 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:12,923 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:12,923 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:12,923 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:16:12,923 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:12,926 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:12,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:12,926 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:12,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:12,927 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:12,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:12,927 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:12,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:12,941 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:14,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:16,681 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:18,767 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:20,673 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:20,674 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:20,674 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:20,674 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:20,682 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:20.104251+00:00, run_end_date=2025-02-22 11:16:20.333492+00:00, run_duration=0.229241, state=success, executor_state=success, try_number=1, max_tries=1, job_id=437, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:12.924365+00:00, queued_by_job_id=7, pid=58151
2025-02-22 11:16:20,682 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:18.070095+00:00, run_end_date=2025-02-22 11:16:18.281155+00:00, run_duration=0.21106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=436, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:12.924365+00:00, queued_by_job_id=7, pid=58132
2025-02-22 11:16:20,682 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:16.193633+00:00, run_end_date=2025-02-22 11:16:16.348065+00:00, run_duration=0.154432, state=success, executor_state=success, try_number=1, max_tries=1, job_id=435, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:12.924365+00:00, queued_by_job_id=7, pid=58113
2025-02-22 11:16:20,683 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:14.271693+00:00, run_end_date=2025-02-22 11:16:14.432019+00:00, run_duration=0.160326, state=success, executor_state=success, try_number=1, max_tries=1, job_id=434, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:12.924365+00:00, queued_by_job_id=7, pid=58094
2025-02-22 11:16:20,868 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-06T00:00:00+00:00, run_after=2024-06-07T00:00:00+00:00
2025-02-22 11:16:20,959 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-01 00:00:00+00:00: scheduled__2024-06-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:20,959 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-01 00:00:00+00:00, run_id=scheduled__2024-06-01T00:00:00+00:00, run_start_date=2025-02-22 11:16:01.132141+00:00, run_end_date=2025-02-22 11:16:20.959609+00:00, run_duration=19.827468, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-01 00:00:00+00:00, data_interval_end=2024-06-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:20,963 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-02T00:00:00+00:00, run_after=2024-06-03T00:00:00+00:00
2025-02-22 11:16:20,987 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:20,987 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:20,987 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:20,987 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:20,987 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:16:20,987 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:20,990 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:20,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:20,990 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:20,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:20,990 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:20,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:20,991 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:20,991 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:21,005 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:22,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:24,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:27,034 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:28,940 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:28,941 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:28,941 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:28,941 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:28,946 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:28.360632+00:00, run_end_date=2025-02-22 11:16:28.505953+00:00, run_duration=0.145321, state=success, executor_state=success, try_number=1, max_tries=1, job_id=441, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:20.988166+00:00, queued_by_job_id=7, pid=58230
2025-02-22 11:16:28,946 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:26.281685+00:00, run_end_date=2025-02-22 11:16:26.646220+00:00, run_duration=0.364535, state=success, executor_state=success, try_number=1, max_tries=1, job_id=440, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:20.988166+00:00, queued_by_job_id=7, pid=58210
2025-02-22 11:16:28,946 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:24.260964+00:00, run_end_date=2025-02-22 11:16:24.428686+00:00, run_duration=0.167722, state=success, executor_state=success, try_number=1, max_tries=1, job_id=439, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:20.988166+00:00, queued_by_job_id=7, pid=58190
2025-02-22 11:16:28,947 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:22.317897+00:00, run_end_date=2025-02-22 11:16:22.463971+00:00, run_duration=0.146074, state=success, executor_state=success, try_number=1, max_tries=1, job_id=438, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:20.988166+00:00, queued_by_job_id=7, pid=58171
2025-02-22 11:16:29,102 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-03T00:00:00+00:00, run_after=2024-06-04T00:00:00+00:00
2025-02-22 11:16:29,166 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-02 00:00:00+00:00: scheduled__2024-06-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:29,167 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-02 00:00:00+00:00, run_id=scheduled__2024-06-02T00:00:00+00:00, run_start_date=2025-02-22 11:16:03.220179+00:00, run_end_date=2025-02-22 11:16:29.167185+00:00, run_duration=25.947006, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-02 00:00:00+00:00, data_interval_end=2024-06-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:29,171 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-03T00:00:00+00:00, run_after=2024-06-04T00:00:00+00:00
2025-02-22 11:16:29,198 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:29,198 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:29,198 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:29,198 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:29,198 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:29,201 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:29,201 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:29,201 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:29,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:29,202 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:29,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:29,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:31,208 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:33,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:35,096 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:35,096 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:35,096 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:35,104 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:34.565977+00:00, run_end_date=2025-02-22 11:16:34.746054+00:00, run_duration=0.180077, state=success, executor_state=success, try_number=1, max_tries=1, job_id=444, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:29.199307+00:00, queued_by_job_id=7, pid=58295
2025-02-22 11:16:35,104 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:32.571390+00:00, run_end_date=2025-02-22 11:16:32.728031+00:00, run_duration=0.156641, state=success, executor_state=success, try_number=1, max_tries=1, job_id=443, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:29.199307+00:00, queued_by_job_id=7, pid=58276
2025-02-22 11:16:35,104 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:30.530198+00:00, run_end_date=2025-02-22 11:16:30.798270+00:00, run_duration=0.268072, state=success, executor_state=success, try_number=1, max_tries=1, job_id=442, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:29.199307+00:00, queued_by_job_id=7, pid=58258
2025-02-22 11:16:35,564 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-04T00:00:00+00:00, run_after=2024-06-05T00:00:00+00:00
2025-02-22 11:16:35,621 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-03 00:00:00+00:00: scheduled__2024-06-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:35,621 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-03 00:00:00+00:00, run_id=scheduled__2024-06-03T00:00:00+00:00, run_start_date=2025-02-22 11:16:07.115130+00:00, run_end_date=2025-02-22 11:16:35.621832+00:00, run_duration=28.506702, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-03 00:00:00+00:00, data_interval_end=2024-06-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:35,627 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-04T00:00:00+00:00, run_after=2024-06-05T00:00:00+00:00
2025-02-22 11:16:35,727 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:35,728 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:35,728 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:35,728 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:35,731 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:35,732 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:35,732 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:35,732 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:35,748 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:37,680 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:40,129 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:40,129 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:40,137 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:39.325476+00:00, run_end_date=2025-02-22 11:16:39.724112+00:00, run_duration=0.398636, state=success, executor_state=success, try_number=1, max_tries=1, job_id=446, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:35.729199+00:00, queued_by_job_id=7, pid=58349
2025-02-22 11:16:40,137 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:37.084133+00:00, run_end_date=2025-02-22 11:16:37.279487+00:00, run_duration=0.195354, state=success, executor_state=success, try_number=1, max_tries=1, job_id=445, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:35.729199+00:00, queued_by_job_id=7, pid=58327
2025-02-22 11:16:40,759 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-05T00:00:00+00:00, run_after=2024-06-06T00:00:00+00:00
2025-02-22 11:16:40,805 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-04 00:00:00+00:00: scheduled__2024-06-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:40,805 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-04 00:00:00+00:00, run_id=scheduled__2024-06-04T00:00:00+00:00, run_start_date=2025-02-22 11:16:12.855452+00:00, run_end_date=2025-02-22 11:16:40.805851+00:00, run_duration=27.950399, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-04 00:00:00+00:00, data_interval_end=2024-06-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:40,811 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-05T00:00:00+00:00, run_after=2024-06-06T00:00:00+00:00
2025-02-22 11:16:40,839 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:40,839 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:40,839 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:40,842 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:40,842 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:40,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:43,105 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:43,113 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:42.269579+00:00, run_end_date=2025-02-22 11:16:42.755193+00:00, run_duration=0.485614, state=success, executor_state=success, try_number=1, max_tries=1, job_id=447, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:40.840418+00:00, queued_by_job_id=7, pid=58394
2025-02-22 11:16:43,558 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-07T00:00:00+00:00, run_after=2024-06-08T00:00:00+00:00
2025-02-22 11:16:43,610 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-05 00:00:00+00:00: scheduled__2024-06-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:43,610 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-05 00:00:00+00:00, run_id=scheduled__2024-06-05T00:00:00+00:00, run_start_date=2025-02-22 11:16:20.913893+00:00, run_end_date=2025-02-22 11:16:43.610625+00:00, run_duration=22.696732, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-05 00:00:00+00:00, data_interval_end=2024-06-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:43,613 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-06T00:00:00+00:00, run_after=2024-06-07T00:00:00+00:00
2025-02-22 11:16:43,633 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:43,633 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:43,633 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:43,635 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:43,635 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:43,652 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:45,530 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:45,538 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:45.024017+00:00, run_end_date=2025-02-22 11:16:45.197765+00:00, run_duration=0.173748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=448, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:43.634072+00:00, queued_by_job_id=7, pid=58422
2025-02-22 11:16:45,702 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-07T00:00:00+00:00, run_after=2024-06-08T00:00:00+00:00
2025-02-22 11:16:45,834 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:45,835 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:45,835 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:45,838 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:45,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:45,853 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:47,711 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:47,719 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:47.214984+00:00, run_end_date=2025-02-22 11:16:47.361982+00:00, run_duration=0.146998, state=success, executor_state=success, try_number=1, max_tries=1, job_id=449, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:45.836266+00:00, queued_by_job_id=7, pid=58443
2025-02-22 11:16:47,868 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-08T00:00:00+00:00, run_after=2024-06-09T00:00:00+00:00
2025-02-22 11:16:47,945 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:47,945 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:47,945 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:47,945 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:47,947 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:47,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:47,947 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:47,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:47,960 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:49,992 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:51,888 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:51,889 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:51,894 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:51.406451+00:00, run_end_date=2025-02-22 11:16:51.555671+00:00, run_duration=0.14922, state=success, executor_state=success, try_number=1, max_tries=1, job_id=451, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:47.946068+00:00, queued_by_job_id=7, pid=58482
2025-02-22 11:16:51,894 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:49.340549+00:00, run_end_date=2025-02-22 11:16:49.565688+00:00, run_duration=0.225139, state=success, executor_state=success, try_number=1, max_tries=1, job_id=450, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:47.946068+00:00, queued_by_job_id=7, pid=58463
2025-02-22 11:16:52,078 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-09T00:00:00+00:00, run_after=2024-06-10T00:00:00+00:00
2025-02-22 11:16:52,153 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:52,153 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:52,153 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:52,153 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:52,153 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:52,155 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:52,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:52,155 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:52,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:52,155 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:16:52,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:52,168 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:54,064 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:55,932 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:57,858 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:57,859 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:57,859 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:16:57,867 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:57.398195+00:00, run_end_date=2025-02-22 11:16:57.550692+00:00, run_duration=0.152497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=454, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:16:52.154074+00:00, queued_by_job_id=7, pid=58539
2025-02-22 11:16:57,867 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:55.428193+00:00, run_end_date=2025-02-22 11:16:55.579566+00:00, run_duration=0.151373, state=success, executor_state=success, try_number=1, max_tries=1, job_id=453, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:52.154074+00:00, queued_by_job_id=7, pid=58520
2025-02-22 11:16:57,867 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:53.476929+00:00, run_end_date=2025-02-22 11:16:53.720527+00:00, run_duration=0.243598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=452, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:52.154074+00:00, queued_by_job_id=7, pid=58501
2025-02-22 11:16:57,902 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:16:58,104 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-10T00:00:00+00:00, run_after=2024-06-11T00:00:00+00:00
2025-02-22 11:16:58,243 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-06 00:00:00+00:00: scheduled__2024-06-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:16:58,244 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-06 00:00:00+00:00, run_id=scheduled__2024-06-06T00:00:00+00:00, run_start_date=2025-02-22 11:16:43.584700+00:00, run_end_date=2025-02-22 11:16:58.244261+00:00, run_duration=14.659561, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-06 00:00:00+00:00, data_interval_end=2024-06-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:16:58,247 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-07T00:00:00+00:00, run_after=2024-06-08T00:00:00+00:00
2025-02-22 11:16:58,281 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:58,281 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:16:58,281 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:16:58,281 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:16:58,281 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:16:58,283 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:16:58,283 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:58,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:16:58,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:58,284 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:16:58,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:16:58,311 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:00,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:02,243 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:04,031 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:04,031 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:04,032 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:04,037 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:03.541635+00:00, run_end_date=2025-02-22 11:17:03.695275+00:00, run_duration=0.15364, state=success, executor_state=success, try_number=1, max_tries=1, job_id=457, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:16:58.282214+00:00, queued_by_job_id=7, pid=58605
2025-02-22 11:17:04,037 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:01.699243+00:00, run_end_date=2025-02-22 11:17:01.893935+00:00, run_duration=0.194692, state=success, executor_state=success, try_number=1, max_tries=1, job_id=456, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:16:58.282214+00:00, queued_by_job_id=7, pid=58586
2025-02-22 11:17:04,037 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:16:59.697620+00:00, run_end_date=2025-02-22 11:16:59.963213+00:00, run_duration=0.265593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=455, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:16:58.282214+00:00, queued_by_job_id=7, pid=58559
2025-02-22 11:17:04,447 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-08T00:00:00+00:00, run_after=2024-06-09T00:00:00+00:00
2025-02-22 11:17:04,535 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:04,535 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:04,535 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:04,535 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:17:04,535 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:04,538 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:04,539 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:04,539 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:04,539 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:04,540 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:04,540 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:04,556 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:06,563 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:08,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:10,321 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:10,321 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:10,321 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:10,329 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:09.852017+00:00, run_end_date=2025-02-22 11:17:10.020484+00:00, run_duration=0.168467, state=success, executor_state=success, try_number=1, max_tries=1, job_id=460, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:04.536537+00:00, queued_by_job_id=7, pid=58663
2025-02-22 11:17:10,329 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:07.921746+00:00, run_end_date=2025-02-22 11:17:08.070570+00:00, run_duration=0.148824, state=success, executor_state=success, try_number=1, max_tries=1, job_id=459, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:04.536537+00:00, queued_by_job_id=7, pid=58644
2025-02-22 11:17:10,329 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:05.887927+00:00, run_end_date=2025-02-22 11:17:06.046033+00:00, run_duration=0.158106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=458, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:04.536537+00:00, queued_by_job_id=7, pid=58625
2025-02-22 11:17:10,487 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-09T00:00:00+00:00, run_after=2024-06-10T00:00:00+00:00
2025-02-22 11:17:10,550 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-07 00:00:00+00:00: scheduled__2024-06-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:10,550 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-07 00:00:00+00:00, run_id=scheduled__2024-06-07T00:00:00+00:00, run_start_date=2025-02-22 11:16:47.894756+00:00, run_end_date=2025-02-22 11:17:10.550842+00:00, run_duration=22.656086, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-07 00:00:00+00:00, data_interval_end=2024-06-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:10,555 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-08T00:00:00+00:00, run_after=2024-06-09T00:00:00+00:00
2025-02-22 11:17:10,583 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:10,583 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:10,583 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:10,583 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:10,586 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:10,586 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:10,586 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:10,587 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:10,601 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:12,433 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:14,205 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:14,205 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:14,213 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:13.742514+00:00, run_end_date=2025-02-22 11:17:13.897457+00:00, run_duration=0.154943, state=success, executor_state=success, try_number=1, max_tries=1, job_id=462, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:10.584272+00:00, queued_by_job_id=7, pid=58709
2025-02-22 11:17:14,213 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:11.950980+00:00, run_end_date=2025-02-22 11:17:12.104610+00:00, run_duration=0.15363, state=success, executor_state=success, try_number=1, max_tries=1, job_id=461, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:10.584272+00:00, queued_by_job_id=7, pid=58683
2025-02-22 11:17:14,343 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-09T00:00:00+00:00, run_after=2024-06-10T00:00:00+00:00
2025-02-22 11:17:14,375 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-08 00:00:00+00:00: scheduled__2024-06-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:14,376 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-08 00:00:00+00:00, run_id=scheduled__2024-06-08T00:00:00+00:00, run_start_date=2025-02-22 11:16:52.105194+00:00, run_end_date=2025-02-22 11:17:14.375978+00:00, run_duration=22.270784, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-08 00:00:00+00:00, data_interval_end=2024-06-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:14,379 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-09T00:00:00+00:00, run_after=2024-06-10T00:00:00+00:00
2025-02-22 11:17:14,400 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:14,400 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:14,400 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:14,402 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:14,402 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:14,415 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:16,197 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:16,205 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:15.722259+00:00, run_end_date=2025-02-22 11:17:15.880437+00:00, run_duration=0.158178, state=success, executor_state=success, try_number=1, max_tries=1, job_id=463, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:14.400797+00:00, queued_by_job_id=7, pid=58737
2025-02-22 11:17:16,469 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-10T00:00:00+00:00, run_after=2024-06-11T00:00:00+00:00
2025-02-22 11:17:16,516 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-09 00:00:00+00:00: scheduled__2024-06-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:16,517 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-09 00:00:00+00:00, run_id=scheduled__2024-06-09T00:00:00+00:00, run_start_date=2025-02-22 11:16:58.144630+00:00, run_end_date=2025-02-22 11:17:16.517552+00:00, run_duration=18.372922, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-09 00:00:00+00:00, data_interval_end=2024-06-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:16,524 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-10T00:00:00+00:00, run_after=2024-06-11T00:00:00+00:00
2025-02-22 11:17:17,702 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-11T00:00:00+00:00, run_after=2024-06-12T00:00:00+00:00
2025-02-22 11:17:17,778 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:17,779 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:17,779 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:17,780 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:17,781 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:17,807 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:19,726 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:19,733 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:19.108620+00:00, run_end_date=2025-02-22 11:17:19.340280+00:00, run_duration=0.23166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=464, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:17.779604+00:00, queued_by_job_id=7, pid=58765
2025-02-22 11:17:19,879 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-12T00:00:00+00:00, run_after=2024-06-13T00:00:00+00:00
2025-02-22 11:17:19,964 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:19,964 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:19,964 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:19,964 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:19,966 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:19,966 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:19,966 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:19,967 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:19,980 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:21,792 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:23,591 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:23,592 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:23,597 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:23.095309+00:00, run_end_date=2025-02-22 11:17:23.258716+00:00, run_duration=0.163407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=466, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:19.965089+00:00, queued_by_job_id=7, pid=58810
2025-02-22 11:17:23,597 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:21.298268+00:00, run_end_date=2025-02-22 11:17:21.449304+00:00, run_duration=0.151036, state=success, executor_state=success, try_number=1, max_tries=1, job_id=465, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:19.965089+00:00, queued_by_job_id=7, pid=58791
2025-02-22 11:17:23,881 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-13T00:00:00+00:00, run_after=2024-06-14T00:00:00+00:00
2025-02-22 11:17:23,954 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:23,954 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:23,954 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:23,954 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:17:23,954 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:23,956 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:23,956 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:23,956 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:23,956 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:23,956 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:23,956 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:23,969 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:25,754 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:27,528 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:29,620 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:29,620 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:29,620 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:29,628 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:29.078727+00:00, run_end_date=2025-02-22 11:17:29.255091+00:00, run_duration=0.176364, state=success, executor_state=success, try_number=1, max_tries=1, job_id=469, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:23.955203+00:00, queued_by_job_id=7, pid=58868
2025-02-22 11:17:29,628 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:27.042688+00:00, run_end_date=2025-02-22 11:17:27.205549+00:00, run_duration=0.162861, state=success, executor_state=success, try_number=1, max_tries=1, job_id=468, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:23.955203+00:00, queued_by_job_id=7, pid=58849
2025-02-22 11:17:29,629 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:25.269677+00:00, run_end_date=2025-02-22 11:17:25.428220+00:00, run_duration=0.158543, state=success, executor_state=success, try_number=1, max_tries=1, job_id=467, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:23.955203+00:00, queued_by_job_id=7, pid=58830
2025-02-22 11:17:29,808 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-14T00:00:00+00:00, run_after=2024-06-15T00:00:00+00:00
2025-02-22 11:17:29,896 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:29,897 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:29,897 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:29,897 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:17:29,897 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:17:29,897 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:29,899 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:29,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:29,899 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:29,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:29,899 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:29,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:29,900 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:29,900 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:29,912 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:31,739 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:33,649 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:35,468 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:37,263 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:37,263 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:37,263 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:37,263 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:37,271 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:36.801971+00:00, run_end_date=2025-02-22 11:17:36.946249+00:00, run_duration=0.144278, state=success, executor_state=success, try_number=1, max_tries=1, job_id=473, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:29.897841+00:00, queued_by_job_id=7, pid=58961
2025-02-22 11:17:37,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:34.972690+00:00, run_end_date=2025-02-22 11:17:35.120811+00:00, run_duration=0.148121, state=success, executor_state=success, try_number=1, max_tries=1, job_id=472, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:29.897841+00:00, queued_by_job_id=7, pid=58935
2025-02-22 11:17:37,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:33.138254+00:00, run_end_date=2025-02-22 11:17:33.286045+00:00, run_duration=0.147791, state=success, executor_state=success, try_number=1, max_tries=1, job_id=471, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:29.897841+00:00, queued_by_job_id=7, pid=58910
2025-02-22 11:17:37,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:31.213009+00:00, run_end_date=2025-02-22 11:17:31.385872+00:00, run_duration=0.172863, state=success, executor_state=success, try_number=1, max_tries=1, job_id=470, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:29.897841+00:00, queued_by_job_id=7, pid=58888
2025-02-22 11:17:37,446 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-15T00:00:00+00:00, run_after=2024-06-16T00:00:00+00:00
2025-02-22 11:17:37,516 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-10 00:00:00+00:00: scheduled__2024-06-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:37,516 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-10 00:00:00+00:00, run_id=scheduled__2024-06-10T00:00:00+00:00, run_start_date=2025-02-22 11:17:17.729435+00:00, run_end_date=2025-02-22 11:17:37.516731+00:00, run_duration=19.787296, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-10 00:00:00+00:00, data_interval_end=2024-06-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:37,519 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-11T00:00:00+00:00, run_after=2024-06-12T00:00:00+00:00
2025-02-22 11:17:37,542 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:37,542 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:37,542 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:37,542 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:17:37,542 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:17:37,543 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:37,544 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:37,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:37,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:37,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:37,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:37,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:37,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:37,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:37,559 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:39,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:41,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:43,284 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:45,192 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:45,192 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:45,193 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:45,193 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:45,200 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:44.593848+00:00, run_end_date=2025-02-22 11:17:44.866004+00:00, run_duration=0.272156, state=success, executor_state=success, try_number=1, max_tries=1, job_id=477, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:37.543369+00:00, queued_by_job_id=7, pid=59037
2025-02-22 11:17:45,201 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:42.688507+00:00, run_end_date=2025-02-22 11:17:42.942328+00:00, run_duration=0.253821, state=success, executor_state=success, try_number=1, max_tries=1, job_id=476, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:37.543369+00:00, queued_by_job_id=7, pid=59018
2025-02-22 11:17:45,201 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:40.745284+00:00, run_end_date=2025-02-22 11:17:40.985674+00:00, run_duration=0.24039, state=success, executor_state=success, try_number=1, max_tries=1, job_id=475, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:37.543369+00:00, queued_by_job_id=7, pid=59000
2025-02-22 11:17:45,201 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:38.913414+00:00, run_end_date=2025-02-22 11:17:39.062946+00:00, run_duration=0.149532, state=success, executor_state=success, try_number=1, max_tries=1, job_id=474, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:37.543369+00:00, queued_by_job_id=7, pid=58981
2025-02-22 11:17:45,365 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-12T00:00:00+00:00, run_after=2024-06-13T00:00:00+00:00
2025-02-22 11:17:45,489 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-11 00:00:00+00:00: scheduled__2024-06-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:45,489 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-11 00:00:00+00:00, run_id=scheduled__2024-06-11T00:00:00+00:00, run_start_date=2025-02-22 11:17:19.909425+00:00, run_end_date=2025-02-22 11:17:45.489388+00:00, run_duration=25.579963, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-11 00:00:00+00:00, data_interval_end=2024-06-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:45,494 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-12T00:00:00+00:00, run_after=2024-06-13T00:00:00+00:00
2025-02-22 11:17:45,523 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:45,523 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:45,523 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:45,524 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:17:45,524 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:45,527 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:17:45,527 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:45,528 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:45,528 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:45,528 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:45,529 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:45,542 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:47,349 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:49,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:51,122 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:51,123 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:51,123 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:51,130 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:50.634376+00:00, run_end_date=2025-02-22 11:17:50.777812+00:00, run_duration=0.143436, state=success, executor_state=success, try_number=1, max_tries=1, job_id=480, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:45.524895+00:00, queued_by_job_id=7, pid=59117
2025-02-22 11:17:51,130 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:48.653645+00:00, run_end_date=2025-02-22 11:17:48.807767+00:00, run_duration=0.154122, state=success, executor_state=success, try_number=1, max_tries=1, job_id=479, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:45.524895+00:00, queued_by_job_id=7, pid=59087
2025-02-22 11:17:51,130 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:46.889267+00:00, run_end_date=2025-02-22 11:17:47.044938+00:00, run_duration=0.155671, state=success, executor_state=success, try_number=1, max_tries=1, job_id=478, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:17:45.524895+00:00, queued_by_job_id=7, pid=59057
2025-02-22 11:17:51,290 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-13T00:00:00+00:00, run_after=2024-06-14T00:00:00+00:00
2025-02-22 11:17:51,354 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-12 00:00:00+00:00: scheduled__2024-06-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:51,354 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-12 00:00:00+00:00, run_id=scheduled__2024-06-12T00:00:00+00:00, run_start_date=2025-02-22 11:17:23.905257+00:00, run_end_date=2025-02-22 11:17:51.354435+00:00, run_duration=27.449178, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-12 00:00:00+00:00, data_interval_end=2024-06-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:51,359 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-13T00:00:00+00:00, run_after=2024-06-14T00:00:00+00:00
2025-02-22 11:17:51,385 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:51,385 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:51,385 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:17:51,385 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:51,388 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:17:51,389 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:51,389 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:51,389 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:51,402 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:53,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:55,148 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:55,149 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:55,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:54.677739+00:00, run_end_date=2025-02-22 11:17:54.835136+00:00, run_duration=0.157397, state=success, executor_state=success, try_number=1, max_tries=1, job_id=482, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:51.386349+00:00, queued_by_job_id=7, pid=59156
2025-02-22 11:17:55,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:52.742940+00:00, run_end_date=2025-02-22 11:17:52.944681+00:00, run_duration=0.201741, state=success, executor_state=success, try_number=1, max_tries=1, job_id=481, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:17:51.386349+00:00, queued_by_job_id=7, pid=59136
2025-02-22 11:17:55,317 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-14T00:00:00+00:00, run_after=2024-06-15T00:00:00+00:00
2025-02-22 11:17:55,364 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-13 00:00:00+00:00: scheduled__2024-06-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:55,365 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-13 00:00:00+00:00, run_id=scheduled__2024-06-13T00:00:00+00:00, run_start_date=2025-02-22 11:17:29.835046+00:00, run_end_date=2025-02-22 11:17:55.365211+00:00, run_duration=25.530165, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-13 00:00:00+00:00, data_interval_end=2024-06-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:55,371 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-14T00:00:00+00:00, run_after=2024-06-15T00:00:00+00:00
2025-02-22 11:17:55,398 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:55,398 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:55,398 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:55,401 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:17:55,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:55,416 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:57,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:17:57,194 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:17:56.720075+00:00, run_end_date=2025-02-22 11:17:56.864238+00:00, run_duration=0.144163, state=success, executor_state=success, try_number=1, max_tries=1, job_id=483, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:17:55.399585+00:00, queued_by_job_id=7, pid=59175
2025-02-22 11:17:57,540 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-15T00:00:00+00:00, run_after=2024-06-16T00:00:00+00:00
2025-02-22 11:17:57,568 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-14 00:00:00+00:00: scheduled__2024-06-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:17:57,569 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-14 00:00:00+00:00, run_id=scheduled__2024-06-14T00:00:00+00:00, run_start_date=2025-02-22 11:17:37.473788+00:00, run_end_date=2025-02-22 11:17:57.569246+00:00, run_duration=20.095458, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-14 00:00:00+00:00, data_interval_end=2024-06-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:17:57,572 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-15T00:00:00+00:00, run_after=2024-06-16T00:00:00+00:00
2025-02-22 11:17:58,743 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-16T00:00:00+00:00, run_after=2024-06-17T00:00:00+00:00
2025-02-22 11:17:58,812 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:58,813 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:17:58,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:17:58,814 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:17:58,815 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:17:58,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:00,645 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:00,653 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:00.152451+00:00, run_end_date=2025-02-22 11:18:00.302053+00:00, run_duration=0.149602, state=success, executor_state=success, try_number=1, max_tries=1, job_id=484, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:17:58.813741+00:00, queued_by_job_id=7, pid=59198
2025-02-22 11:18:00,797 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
2025-02-22 11:18:00,872 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:00,872 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:00,872 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:00,872 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:00,874 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:00,874 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:00,874 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:00,874 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:00,998 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:02,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:04,665 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:04,666 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:04,673 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:04.159962+00:00, run_end_date=2025-02-22 11:18:04.321021+00:00, run_duration=0.161059, state=success, executor_state=success, try_number=1, max_tries=1, job_id=486, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:00.873021+00:00, queued_by_job_id=7, pid=59236
2025-02-22 11:18:04,673 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:02.318389+00:00, run_end_date=2025-02-22 11:18:02.464983+00:00, run_duration=0.146594, state=success, executor_state=success, try_number=1, max_tries=1, job_id=485, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:00.873021+00:00, queued_by_job_id=7, pid=59218
2025-02-22 11:18:04,956 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-18T00:00:00+00:00, run_after=2024-06-19T00:00:00+00:00
2025-02-22 11:18:05,040 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:05,040 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:05,040 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:05,040 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:05,040 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:05,042 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:05,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:05,043 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:05,043 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:05,043 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:05,043 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:05,057 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:06,913 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:08,714 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:10,562 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:10,563 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:10,563 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:10,571 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:10.024266+00:00, run_end_date=2025-02-22 11:18:10.193644+00:00, run_duration=0.169378, state=success, executor_state=success, try_number=1, max_tries=1, job_id=489, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:05.041224+00:00, queued_by_job_id=7, pid=59295
2025-02-22 11:18:10,572 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:08.220087+00:00, run_end_date=2025-02-22 11:18:08.378401+00:00, run_duration=0.158314, state=success, executor_state=success, try_number=1, max_tries=1, job_id=488, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:05.041224+00:00, queued_by_job_id=7, pid=59276
2025-02-22 11:18:10,572 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:06.360694+00:00, run_end_date=2025-02-22 11:18:06.513923+00:00, run_duration=0.153229, state=success, executor_state=success, try_number=1, max_tries=1, job_id=487, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:05.041224+00:00, queued_by_job_id=7, pid=59257
2025-02-22 11:18:10,845 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-19T00:00:00+00:00, run_after=2024-06-20T00:00:00+00:00
2025-02-22 11:18:10,933 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:10,933 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:10,933 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:10,933 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:10,933 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:18:10,934 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:10,935 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:10,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:10,936 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:10,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:10,936 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:10,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:10,936 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:10,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:10,949 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:12,912 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:14,674 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:16,495 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:18,394 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:18,395 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:18,395 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:18,395 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:18,412 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:17.813144+00:00, run_end_date=2025-02-22 11:18:17.968048+00:00, run_duration=0.154904, state=success, executor_state=success, try_number=1, max_tries=1, job_id=493, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:10.934368+00:00, queued_by_job_id=7, pid=59380
2025-02-22 11:18:18,413 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:16.005873+00:00, run_end_date=2025-02-22 11:18:16.182001+00:00, run_duration=0.176128, state=success, executor_state=success, try_number=1, max_tries=1, job_id=492, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:10.934368+00:00, queued_by_job_id=7, pid=59361
2025-02-22 11:18:18,413 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:14.236900+00:00, run_end_date=2025-02-22 11:18:14.408838+00:00, run_duration=0.171938, state=success, executor_state=success, try_number=1, max_tries=1, job_id=491, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:10.934368+00:00, queued_by_job_id=7, pid=59342
2025-02-22 11:18:18,413 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:12.298083+00:00, run_end_date=2025-02-22 11:18:12.568214+00:00, run_duration=0.270131, state=success, executor_state=success, try_number=1, max_tries=1, job_id=490, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:10.934368+00:00, queued_by_job_id=7, pid=59323
2025-02-22 11:18:18,587 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-20T00:00:00+00:00, run_after=2024-06-21T00:00:00+00:00
2025-02-22 11:18:18,646 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-15 00:00:00+00:00: scheduled__2024-06-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:18:18,646 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-15 00:00:00+00:00, run_id=scheduled__2024-06-15T00:00:00+00:00, run_start_date=2025-02-22 11:17:58.766271+00:00, run_end_date=2025-02-22 11:18:18.646399+00:00, run_duration=19.880128, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-15 00:00:00+00:00, data_interval_end=2024-06-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:18:18,648 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-16T00:00:00+00:00, run_after=2024-06-17T00:00:00+00:00
2025-02-22 11:18:18,670 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:18,671 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:18,671 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:18,671 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:18,671 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:18:18,671 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:18,672 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:18,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:18,672 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:18,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:18,672 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:18,673 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:18,673 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:18,673 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:18,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:20,505 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:22,426 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:24,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:26,349 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:26,350 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:26,350 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:26,350 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:26,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:25.749490+00:00, run_end_date=2025-02-22 11:18:25.898976+00:00, run_duration=0.149486, state=success, executor_state=success, try_number=1, max_tries=1, job_id=497, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:18.671513+00:00, queued_by_job_id=7, pid=59477
2025-02-22 11:18:26,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:23.742194+00:00, run_end_date=2025-02-22 11:18:23.901360+00:00, run_duration=0.159166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=496, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:18.671513+00:00, queued_by_job_id=7, pid=59453
2025-02-22 11:18:26,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:21.834687+00:00, run_end_date=2025-02-22 11:18:22.066570+00:00, run_duration=0.231883, state=success, executor_state=success, try_number=1, max_tries=1, job_id=495, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:18.671513+00:00, queued_by_job_id=7, pid=59419
2025-02-22 11:18:26,358 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:20.010169+00:00, run_end_date=2025-02-22 11:18:20.176780+00:00, run_duration=0.166611, state=success, executor_state=success, try_number=1, max_tries=1, job_id=494, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:18.671513+00:00, queued_by_job_id=7, pid=59400
2025-02-22 11:18:26,544 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
2025-02-22 11:18:26,589 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-16 00:00:00+00:00: scheduled__2024-06-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:18:26,589 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-16 00:00:00+00:00, run_id=scheduled__2024-06-16T00:00:00+00:00, run_start_date=2025-02-22 11:18:00.821950+00:00, run_end_date=2025-02-22 11:18:26.589806+00:00, run_duration=25.767856, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-16 00:00:00+00:00, data_interval_end=2024-06-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:18:26,593 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-17T00:00:00+00:00, run_after=2024-06-18T00:00:00+00:00
2025-02-22 11:18:26,619 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:26,620 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:26,620 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:26,620 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:26,620 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:26,623 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:26,623 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:26,623 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:26,623 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:26,624 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:26,624 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:26,638 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:28,442 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:30,220 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:31,995 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:31,996 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:31,996 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:32,005 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:31.528130+00:00, run_end_date=2025-02-22 11:18:31.677813+00:00, run_duration=0.149683, state=success, executor_state=success, try_number=1, max_tries=1, job_id=500, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:26.621052+00:00, queued_by_job_id=7, pid=59536
2025-02-22 11:18:32,005 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:29.734726+00:00, run_end_date=2025-02-22 11:18:29.882968+00:00, run_duration=0.148242, state=success, executor_state=success, try_number=1, max_tries=1, job_id=499, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:26.621052+00:00, queued_by_job_id=7, pid=59518
2025-02-22 11:18:32,005 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:27.962124+00:00, run_end_date=2025-02-22 11:18:28.123806+00:00, run_duration=0.161682, state=success, executor_state=success, try_number=1, max_tries=1, job_id=498, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:26.621052+00:00, queued_by_job_id=7, pid=59498
2025-02-22 11:18:32,167 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-18T00:00:00+00:00, run_after=2024-06-19T00:00:00+00:00
2025-02-22 11:18:32,229 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-17 00:00:00+00:00: scheduled__2024-06-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:18:32,229 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-17 00:00:00+00:00, run_id=scheduled__2024-06-17T00:00:00+00:00, run_start_date=2025-02-22 11:18:04.983797+00:00, run_end_date=2025-02-22 11:18:32.229927+00:00, run_duration=27.24613, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-17 00:00:00+00:00, data_interval_end=2024-06-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:18:32,235 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-18T00:00:00+00:00, run_after=2024-06-19T00:00:00+00:00
2025-02-22 11:18:32,262 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:32,263 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:32,263 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:32,263 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:32,266 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:32,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:32,267 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:32,267 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:32,280 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:34,268 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:36,044 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:36,044 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:36,052 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:35.580145+00:00, run_end_date=2025-02-22 11:18:35.727019+00:00, run_duration=0.146874, state=success, executor_state=success, try_number=1, max_tries=1, job_id=502, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:32.264229+00:00, queued_by_job_id=7, pid=59574
2025-02-22 11:18:36,052 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:33.789405+00:00, run_end_date=2025-02-22 11:18:33.948161+00:00, run_duration=0.158756, state=success, executor_state=success, try_number=1, max_tries=1, job_id=501, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:32.264229+00:00, queued_by_job_id=7, pid=59556
2025-02-22 11:18:36,188 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-19T00:00:00+00:00, run_after=2024-06-20T00:00:00+00:00
2025-02-22 11:18:36,245 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-18 00:00:00+00:00: scheduled__2024-06-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:18:36,245 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-18 00:00:00+00:00, run_id=scheduled__2024-06-18T00:00:00+00:00, run_start_date=2025-02-22 11:18:10.870789+00:00, run_end_date=2025-02-22 11:18:36.245730+00:00, run_duration=25.374941, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-18 00:00:00+00:00, data_interval_end=2024-06-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:18:36,251 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-19T00:00:00+00:00, run_after=2024-06-20T00:00:00+00:00
2025-02-22 11:18:36,281 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:36,281 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:36,281 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:36,285 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:36,285 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:36,299 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:38,092 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:38,100 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:37.613286+00:00, run_end_date=2025-02-22 11:18:37.764042+00:00, run_duration=0.150756, state=success, executor_state=success, try_number=1, max_tries=1, job_id=503, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:36.282777+00:00, queued_by_job_id=7, pid=59595
2025-02-22 11:18:38,266 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-20T00:00:00+00:00, run_after=2024-06-21T00:00:00+00:00
2025-02-22 11:18:38,305 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-19 00:00:00+00:00: scheduled__2024-06-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:18:38,305 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-19 00:00:00+00:00, run_id=scheduled__2024-06-19T00:00:00+00:00, run_start_date=2025-02-22 11:18:18.612287+00:00, run_end_date=2025-02-22 11:18:38.305596+00:00, run_duration=19.693309, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-19 00:00:00+00:00, data_interval_end=2024-06-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:18:38,311 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-20T00:00:00+00:00, run_after=2024-06-21T00:00:00+00:00
2025-02-22 11:18:39,487 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-21T00:00:00+00:00, run_after=2024-06-22T00:00:00+00:00
2025-02-22 11:18:39,564 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:39,564 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:39,564 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:39,566 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:39,566 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:39,578 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:41,408 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:41,416 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:40.928058+00:00, run_end_date=2025-02-22 11:18:41.083152+00:00, run_duration=0.155094, state=success, executor_state=success, try_number=1, max_tries=1, job_id=504, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:39.564899+00:00, queued_by_job_id=7, pid=59617
2025-02-22 11:18:41,565 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-22T00:00:00+00:00, run_after=2024-06-23T00:00:00+00:00
2025-02-22 11:18:41,723 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:41,723 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:41,724 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:41,724 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:41,728 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:41,728 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:41,728 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:41,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:41,744 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:43,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:46,032 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:46,033 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:46,041 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:45.306510+00:00, run_end_date=2025-02-22 11:18:45.542332+00:00, run_duration=0.235822, state=success, executor_state=success, try_number=1, max_tries=1, job_id=506, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:41.725114+00:00, queued_by_job_id=7, pid=59657
2025-02-22 11:18:46,041 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:43.119641+00:00, run_end_date=2025-02-22 11:18:43.528319+00:00, run_duration=0.408678, state=success, executor_state=success, try_number=1, max_tries=1, job_id=505, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:41.725114+00:00, queued_by_job_id=7, pid=59638
2025-02-22 11:18:46,212 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-23T00:00:00+00:00, run_after=2024-06-24T00:00:00+00:00
2025-02-22 11:18:46,315 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:46,316 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:46,316 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:46,316 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:46,316 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:46,318 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:46,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:46,318 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:46,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:46,318 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:46,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:46,339 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:48,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:50,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:52,133 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:52,133 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:52,133 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:52,141 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:51.411537+00:00, run_end_date=2025-02-22 11:18:51.600001+00:00, run_duration=0.188464, state=success, executor_state=success, try_number=1, max_tries=1, job_id=509, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:46.316694+00:00, queued_by_job_id=7, pid=59723
2025-02-22 11:18:52,142 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:49.507822+00:00, run_end_date=2025-02-22 11:18:49.658689+00:00, run_duration=0.150867, state=success, executor_state=success, try_number=1, max_tries=1, job_id=508, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:46.316694+00:00, queued_by_job_id=7, pid=59696
2025-02-22 11:18:52,142 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:47.701867+00:00, run_end_date=2025-02-22 11:18:47.851247+00:00, run_duration=0.14938, state=success, executor_state=success, try_number=1, max_tries=1, job_id=507, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:46.316694+00:00, queued_by_job_id=7, pid=59677
2025-02-22 11:18:52,314 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-24T00:00:00+00:00, run_after=2024-06-25T00:00:00+00:00
2025-02-22 11:18:52,401 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:52,402 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:18:52,402 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:18:52,402 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:18:52,402 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:18:52,402 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:18:52,404 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:18:52,404 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:52,404 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:18:52,404 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:52,405 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:18:52,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:52,405 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:18:52,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:52,421 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:54,362 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:56,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:58,063 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:18:59,873 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:59,873 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:59,874 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:59,874 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:18:59,881 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:59.386322+00:00, run_end_date=2025-02-22 11:18:59.529602+00:00, run_duration=0.14328, state=success, executor_state=success, try_number=1, max_tries=1, job_id=513, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:18:52.402797+00:00, queued_by_job_id=7, pid=59800
2025-02-22 11:18:59,882 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:57.573094+00:00, run_end_date=2025-02-22 11:18:57.735240+00:00, run_duration=0.162146, state=success, executor_state=success, try_number=1, max_tries=1, job_id=512, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:18:52.402797+00:00, queued_by_job_id=7, pid=59781
2025-02-22 11:18:59,882 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:55.767791+00:00, run_end_date=2025-02-22 11:18:55.946090+00:00, run_duration=0.178299, state=success, executor_state=success, try_number=1, max_tries=1, job_id=511, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:18:52.402797+00:00, queued_by_job_id=7, pid=59762
2025-02-22 11:18:59,882 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:18:53.734177+00:00, run_end_date=2025-02-22 11:18:53.999232+00:00, run_duration=0.265055, state=success, executor_state=success, try_number=1, max_tries=1, job_id=510, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:18:52.402797+00:00, queued_by_job_id=7, pid=59743
2025-02-22 11:19:00,070 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-25T00:00:00+00:00, run_after=2024-06-26T00:00:00+00:00
2025-02-22 11:19:00,146 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-20 00:00:00+00:00: scheduled__2024-06-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:00,146 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-20 00:00:00+00:00, run_id=scheduled__2024-06-20T00:00:00+00:00, run_start_date=2025-02-22 11:18:39.513902+00:00, run_end_date=2025-02-22 11:19:00.146871+00:00, run_duration=20.632969, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-20 00:00:00+00:00, data_interval_end=2024-06-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:00,150 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-21T00:00:00+00:00, run_after=2024-06-22T00:00:00+00:00
2025-02-22 11:19:00,170 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:00,170 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:00,170 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:00,170 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:19:00,170 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:19:00,171 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:00,172 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:00,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:00,173 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:00,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:00,173 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:00,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:00,173 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:00,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:00,190 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:01,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:03,897 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:05,685 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:07,490 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:07,490 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:07,491 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:07,491 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:07,499 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:07.006103+00:00, run_end_date=2025-02-22 11:19:07.153010+00:00, run_duration=0.146907, state=success, executor_state=success, try_number=1, max_tries=1, job_id=517, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:00.171435+00:00, queued_by_job_id=7, pid=59891
2025-02-22 11:19:07,499 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:05.211729+00:00, run_end_date=2025-02-22 11:19:05.363476+00:00, run_duration=0.151747, state=success, executor_state=success, try_number=1, max_tries=1, job_id=516, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:00.171435+00:00, queued_by_job_id=7, pid=59873
2025-02-22 11:19:07,499 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:03.348248+00:00, run_end_date=2025-02-22 11:19:03.497995+00:00, run_duration=0.149747, state=success, executor_state=success, try_number=1, max_tries=1, job_id=515, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:00.171435+00:00, queued_by_job_id=7, pid=59854
2025-02-22 11:19:07,499 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:01.511633+00:00, run_end_date=2025-02-22 11:19:01.662231+00:00, run_duration=0.150598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=514, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:00.171435+00:00, queued_by_job_id=7, pid=59827
2025-02-22 11:19:07,663 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-22T00:00:00+00:00, run_after=2024-06-23T00:00:00+00:00
2025-02-22 11:19:07,734 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-21 00:00:00+00:00: scheduled__2024-06-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:07,734 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-21 00:00:00+00:00, run_id=scheduled__2024-06-21T00:00:00+00:00, run_start_date=2025-02-22 11:18:41.611586+00:00, run_end_date=2025-02-22 11:19:07.734768+00:00, run_duration=26.123182, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-21 00:00:00+00:00, data_interval_end=2024-06-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:07,739 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-22T00:00:00+00:00, run_after=2024-06-23T00:00:00+00:00
2025-02-22 11:19:07,766 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:07,766 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:07,767 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:07,767 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:19:07,767 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:07,770 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:07,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:07,770 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:07,771 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:07,771 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:07,771 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:07,785 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:09,584 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:11,714 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:13,582 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:13,582 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:13,582 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:13,592 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:13.118416+00:00, run_end_date=2025-02-22 11:19:13.271346+00:00, run_duration=0.15293, state=success, executor_state=success, try_number=1, max_tries=1, job_id=520, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:07.767993+00:00, queued_by_job_id=7, pid=59951
2025-02-22 11:19:13,593 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:11.034411+00:00, run_end_date=2025-02-22 11:19:11.315961+00:00, run_duration=0.28155, state=success, executor_state=success, try_number=1, max_tries=1, job_id=519, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:07.767993+00:00, queued_by_job_id=7, pid=59931
2025-02-22 11:19:13,593 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:09.093137+00:00, run_end_date=2025-02-22 11:19:09.252457+00:00, run_duration=0.15932, state=success, executor_state=success, try_number=1, max_tries=1, job_id=518, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:07.767993+00:00, queued_by_job_id=7, pid=59913
2025-02-22 11:19:14,121 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-23T00:00:00+00:00, run_after=2024-06-24T00:00:00+00:00
2025-02-22 11:19:14,181 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-22 00:00:00+00:00: scheduled__2024-06-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:14,181 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-22 00:00:00+00:00, run_id=scheduled__2024-06-22T00:00:00+00:00, run_start_date=2025-02-22 11:18:46.234651+00:00, run_end_date=2025-02-22 11:19:14.181514+00:00, run_duration=27.946863, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-22 00:00:00+00:00, data_interval_end=2024-06-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:14,186 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-23T00:00:00+00:00, run_after=2024-06-24T00:00:00+00:00
2025-02-22 11:19:14,208 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:14,208 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:14,208 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:14,208 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:14,210 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:14,210 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:14,210 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:14,211 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:14,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:15,988 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:17,794 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:17,795 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:17,802 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:17.321093+00:00, run_end_date=2025-02-22 11:19:17.474871+00:00, run_duration=0.153778, state=success, executor_state=success, try_number=1, max_tries=1, job_id=522, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:14.209027+00:00, queued_by_job_id=7, pid=59997
2025-02-22 11:19:17,803 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:15.536695+00:00, run_end_date=2025-02-22 11:19:15.688709+00:00, run_duration=0.152014, state=success, executor_state=success, try_number=1, max_tries=1, job_id=521, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:14.209027+00:00, queued_by_job_id=7, pid=59979
2025-02-22 11:19:18,244 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-24T00:00:00+00:00, run_after=2024-06-25T00:00:00+00:00
2025-02-22 11:19:18,279 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-23 00:00:00+00:00: scheduled__2024-06-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:18,280 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-23 00:00:00+00:00, run_id=scheduled__2024-06-23T00:00:00+00:00, run_start_date=2025-02-22 11:18:52.339401+00:00, run_end_date=2025-02-22 11:19:18.279982+00:00, run_duration=25.940581, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-23 00:00:00+00:00, data_interval_end=2024-06-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:18,283 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-24T00:00:00+00:00, run_after=2024-06-25T00:00:00+00:00
2025-02-22 11:19:18,303 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:18,303 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:18,303 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:18,305 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:18,305 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:18,317 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:20,075 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:20,083 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:19.613316+00:00, run_end_date=2025-02-22 11:19:19.773997+00:00, run_duration=0.160681, state=success, executor_state=success, try_number=1, max_tries=1, job_id=523, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:18.304162+00:00, queued_by_job_id=7, pid=60026
2025-02-22 11:19:20,555 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-26T00:00:00+00:00, run_after=2024-06-27T00:00:00+00:00
2025-02-22 11:19:20,616 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-24 00:00:00+00:00: scheduled__2024-06-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:20,616 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-24 00:00:00+00:00, run_id=scheduled__2024-06-24T00:00:00+00:00, run_start_date=2025-02-22 11:19:00.103551+00:00, run_end_date=2025-02-22 11:19:20.616522+00:00, run_duration=20.512971, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-24 00:00:00+00:00, data_interval_end=2024-06-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:20,619 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-25T00:00:00+00:00, run_after=2024-06-26T00:00:00+00:00
2025-02-22 11:19:20,638 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:20,638 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:20,639 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:20,640 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:20,640 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:20,654 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:22,480 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:22,488 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:22.033885+00:00, run_end_date=2025-02-22 11:19:22.181826+00:00, run_duration=0.147941, state=success, executor_state=success, try_number=1, max_tries=1, job_id=524, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:20.639492+00:00, queued_by_job_id=7, pid=60062
2025-02-22 11:19:22,621 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-26T00:00:00+00:00, run_after=2024-06-27T00:00:00+00:00
2025-02-22 11:19:22,674 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:22,674 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:22,674 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:22,676 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:22,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:22,689 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:24,536 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:24,548 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:24.039655+00:00, run_end_date=2025-02-22 11:19:24.191249+00:00, run_duration=0.151594, state=success, executor_state=success, try_number=1, max_tries=1, job_id=525, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:22.675318+00:00, queued_by_job_id=7, pid=60082
2025-02-22 11:19:24,693 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-27T00:00:00+00:00, run_after=2024-06-28T00:00:00+00:00
2025-02-22 11:19:24,771 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:24,771 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:24,771 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:24,771 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:24,773 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:24,773 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:24,774 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:24,774 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:24,786 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:26,571 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:28,383 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:28,383 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:28,391 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:27.898503+00:00, run_end_date=2025-02-22 11:19:28.053822+00:00, run_duration=0.155319, state=success, executor_state=success, try_number=1, max_tries=1, job_id=527, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:24.772303+00:00, queued_by_job_id=7, pid=60121
2025-02-22 11:19:28,391 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:26.089360+00:00, run_end_date=2025-02-22 11:19:26.237692+00:00, run_duration=0.148332, state=success, executor_state=success, try_number=1, max_tries=1, job_id=526, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:24.772303+00:00, queued_by_job_id=7, pid=60102
2025-02-22 11:19:28,840 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-28T00:00:00+00:00, run_after=2024-06-29T00:00:00+00:00
2025-02-22 11:19:29,024 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:29,024 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:29,024 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:29,024 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:19:29,024 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:29,026 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:29,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:29,027 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:29,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:29,027 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:29,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:29,042 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:30,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:32,701 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:34,600 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:34,601 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:34,601 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:34,609 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:34.140425+00:00, run_end_date=2025-02-22 11:19:34.307401+00:00, run_duration=0.166976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=530, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:29.025208+00:00, queued_by_job_id=7, pid=60187
2025-02-22 11:19:34,609 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:32.194023+00:00, run_end_date=2025-02-22 11:19:32.355663+00:00, run_duration=0.16164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=529, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:29.025208+00:00, queued_by_job_id=7, pid=60168
2025-02-22 11:19:34,609 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:30.362478+00:00, run_end_date=2025-02-22 11:19:30.520737+00:00, run_duration=0.158259, state=success, executor_state=success, try_number=1, max_tries=1, job_id=528, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:29.025208+00:00, queued_by_job_id=7, pid=60141
2025-02-22 11:19:34,791 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-29T00:00:00+00:00, run_after=2024-06-30T00:00:00+00:00
2025-02-22 11:19:34,850 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-25 00:00:00+00:00: scheduled__2024-06-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:34,850 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-25 00:00:00+00:00, run_id=scheduled__2024-06-25T00:00:00+00:00, run_start_date=2025-02-22 11:19:20.583592+00:00, run_end_date=2025-02-22 11:19:34.850342+00:00, run_duration=14.26675, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-25 00:00:00+00:00, data_interval_end=2024-06-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:34,853 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-26T00:00:00+00:00, run_after=2024-06-27T00:00:00+00:00
2025-02-22 11:19:34,873 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:34,873 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:34,873 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:34,873 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:19:34,874 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:34,876 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:34,876 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:34,876 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:34,876 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:34,876 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:34,876 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:34,892 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:36,697 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:38,487 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:40,401 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:40,401 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:40,401 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:40,409 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:39.810497+00:00, run_end_date=2025-02-22 11:19:39.962757+00:00, run_duration=0.15226, state=success, executor_state=success, try_number=1, max_tries=1, job_id=533, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:34.874450+00:00, queued_by_job_id=7, pid=60248
2025-02-22 11:19:40,410 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:38.029342+00:00, run_end_date=2025-02-22 11:19:38.180978+00:00, run_duration=0.151636, state=success, executor_state=success, try_number=1, max_tries=1, job_id=532, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:34.874450+00:00, queued_by_job_id=7, pid=60225
2025-02-22 11:19:40,410 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:36.211722+00:00, run_end_date=2025-02-22 11:19:36.355780+00:00, run_duration=0.144058, state=success, executor_state=success, try_number=1, max_tries=1, job_id=531, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:34.874450+00:00, queued_by_job_id=7, pid=60207
2025-02-22 11:19:40,599 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-27T00:00:00+00:00, run_after=2024-06-28T00:00:00+00:00
2025-02-22 11:19:40,690 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:40,690 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:40,690 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:40,690 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:19:40,691 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:40,694 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:40,694 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:40,694 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:40,694 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:40,695 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:40,695 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:40,708 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:42,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:44,353 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:46,154 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:46,155 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:46,155 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:46,163 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:45.685758+00:00, run_end_date=2025-02-22 11:19:45.837054+00:00, run_duration=0.151296, state=success, executor_state=success, try_number=1, max_tries=1, job_id=536, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:40.691668+00:00, queued_by_job_id=7, pid=60326
2025-02-22 11:19:46,163 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:43.830124+00:00, run_end_date=2025-02-22 11:19:44.044050+00:00, run_duration=0.213926, state=success, executor_state=success, try_number=1, max_tries=1, job_id=535, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:40.691668+00:00, queued_by_job_id=7, pid=60300
2025-02-22 11:19:46,163 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:42.057581+00:00, run_end_date=2025-02-22 11:19:42.206922+00:00, run_duration=0.149341, state=success, executor_state=success, try_number=1, max_tries=1, job_id=534, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:40.691668+00:00, queued_by_job_id=7, pid=60281
2025-02-22 11:19:46,445 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-28T00:00:00+00:00, run_after=2024-06-29T00:00:00+00:00
2025-02-22 11:19:46,479 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-26 00:00:00+00:00: scheduled__2024-06-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:46,480 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-26 00:00:00+00:00, run_id=scheduled__2024-06-26T00:00:00+00:00, run_start_date=2025-02-22 11:19:24.720297+00:00, run_end_date=2025-02-22 11:19:46.479998+00:00, run_duration=21.759701, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-26 00:00:00+00:00, data_interval_end=2024-06-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:46,482 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-27T00:00:00+00:00, run_after=2024-06-28T00:00:00+00:00
2025-02-22 11:19:46,501 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:46,501 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:46,501 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:46,501 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:46,503 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:19:46,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:46,503 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:46,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:46,517 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:48,297 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:50,098 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:50,098 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:50,106 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:49.596176+00:00, run_end_date=2025-02-22 11:19:49.758397+00:00, run_duration=0.162221, state=success, executor_state=success, try_number=1, max_tries=1, job_id=538, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:46.502110+00:00, queued_by_job_id=7, pid=60379
2025-02-22 11:19:50,106 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:47.828203+00:00, run_end_date=2025-02-22 11:19:47.987613+00:00, run_duration=0.15941, state=success, executor_state=success, try_number=1, max_tries=1, job_id=537, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:19:46.502110+00:00, queued_by_job_id=7, pid=60360
2025-02-22 11:19:50,244 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-28T00:00:00+00:00, run_after=2024-06-29T00:00:00+00:00
2025-02-22 11:19:50,298 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-27 00:00:00+00:00: scheduled__2024-06-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:50,299 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-27 00:00:00+00:00, run_id=scheduled__2024-06-27T00:00:00+00:00, run_start_date=2025-02-22 11:19:28.892882+00:00, run_end_date=2025-02-22 11:19:50.299370+00:00, run_duration=21.406488, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-27 00:00:00+00:00, data_interval_end=2024-06-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:50,305 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-28T00:00:00+00:00, run_after=2024-06-29T00:00:00+00:00
2025-02-22 11:19:50,328 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:50,328 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:50,328 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:50,330 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:19:50,330 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:50,343 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:52,339 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:52,347 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:51.738639+00:00, run_end_date=2025-02-22 11:19:51.993002+00:00, run_duration=0.254363, state=success, executor_state=success, try_number=1, max_tries=1, job_id=539, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:19:50.328993+00:00, queued_by_job_id=7, pid=60407
2025-02-22 11:19:52,506 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-29T00:00:00+00:00, run_after=2024-06-30T00:00:00+00:00
2025-02-22 11:19:52,551 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-28 00:00:00+00:00: scheduled__2024-06-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:19:52,551 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-28 00:00:00+00:00, run_id=scheduled__2024-06-28T00:00:00+00:00, run_start_date=2025-02-22 11:19:34.813028+00:00, run_end_date=2025-02-22 11:19:52.551544+00:00, run_duration=17.738516, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-28 00:00:00+00:00, data_interval_end=2024-06-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:19:52,557 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-29T00:00:00+00:00, run_after=2024-06-30T00:00:00+00:00
2025-02-22 11:19:53,737 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-30T00:00:00+00:00, run_after=2024-07-01T00:00:00+00:00
2025-02-22 11:19:53,832 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:53,832 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:53,833 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:53,836 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:53,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:53,852 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:55,770 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:55,778 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:55.180933+00:00, run_end_date=2025-02-22 11:19:55.331609+00:00, run_duration=0.150676, state=success, executor_state=success, try_number=1, max_tries=1, job_id=540, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:53.833977+00:00, queued_by_job_id=7, pid=60429
2025-02-22 11:19:55,928 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-01T00:00:00+00:00, run_after=2024-07-02T00:00:00+00:00
2025-02-22 11:19:56,004 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:56,005 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:19:56,005 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:19:56,005 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:19:56,007 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:19:56,007 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:56,007 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:19:56,007 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:56,018 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:57,830 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:19:59,646 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-06-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:59,647 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:19:59,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:59.152498+00:00, run_end_date=2025-02-22 11:19:59.324599+00:00, run_duration=0.172101, state=success, executor_state=success, try_number=1, max_tries=1, job_id=542, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:19:56.005620+00:00, queued_by_job_id=7, pid=60468
2025-02-22 11:19:59,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-06-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:19:57.357019+00:00, run_end_date=2025-02-22 11:19:57.509636+00:00, run_duration=0.152617, state=success, executor_state=success, try_number=1, max_tries=1, job_id=541, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:19:56.005620+00:00, queued_by_job_id=7, pid=60450
2025-02-22 11:19:59,826 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-02T00:00:00+00:00, run_after=2024-07-03T00:00:00+00:00
2025-02-22 11:20:00,020 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:00,020 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:00,020 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:00,021 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:00,021 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:00,024 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:00,025 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:00,025 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:00,025 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:00,026 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:00,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:00,039 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:01,904 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:03,733 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:05,499 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:05,500 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-06-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:05,500 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:05,508 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:05.044477+00:00, run_end_date=2025-02-22 11:20:05.199386+00:00, run_duration=0.154909, state=success, executor_state=success, try_number=1, max_tries=1, job_id=545, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:00.022023+00:00, queued_by_job_id=7, pid=60538
2025-02-22 11:20:05,508 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-06-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:03.243583+00:00, run_end_date=2025-02-22 11:20:03.412734+00:00, run_duration=0.169151, state=success, executor_state=success, try_number=1, max_tries=1, job_id=544, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:00.022023+00:00, queued_by_job_id=7, pid=60518
2025-02-22 11:20:05,508 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:01.444636+00:00, run_end_date=2025-02-22 11:20:01.614690+00:00, run_duration=0.170054, state=success, executor_state=success, try_number=1, max_tries=1, job_id=543, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:00.022023+00:00, queued_by_job_id=7, pid=60492
2025-02-22 11:20:05,691 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-03T00:00:00+00:00, run_after=2024-07-04T00:00:00+00:00
2025-02-22 11:20:05,784 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:05,784 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:05,784 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:05,784 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:05,784 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:20:05,784 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:05,786 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:05,786 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:05,786 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:05,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:05,787 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:05,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:05,787 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:05,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:05,801 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:07,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:09,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:11,370 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:13,282 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:13,283 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:13,283 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-06-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:13,283 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:13,291 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:12.725750+00:00, run_end_date=2025-02-22 11:20:12.936706+00:00, run_duration=0.210956, state=success, executor_state=success, try_number=1, max_tries=1, job_id=549, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:05.784995+00:00, queued_by_job_id=7, pid=60625
2025-02-22 11:20:13,291 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-06-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:10.846782+00:00, run_end_date=2025-02-22 11:20:11.029434+00:00, run_duration=0.182652, state=success, executor_state=success, try_number=1, max_tries=1, job_id=548, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:05.784995+00:00, queued_by_job_id=7, pid=60596
2025-02-22 11:20:13,292 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:09.033316+00:00, run_end_date=2025-02-22 11:20:09.185449+00:00, run_duration=0.152133, state=success, executor_state=success, try_number=1, max_tries=1, job_id=547, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:05.784995+00:00, queued_by_job_id=7, pid=60576
2025-02-22 11:20:13,292 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:07.235923+00:00, run_end_date=2025-02-22 11:20:07.409156+00:00, run_duration=0.173233, state=success, executor_state=success, try_number=1, max_tries=1, job_id=546, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:05.784995+00:00, queued_by_job_id=7, pid=60557
2025-02-22 11:20:13,462 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-04T00:00:00+00:00, run_after=2024-07-05T00:00:00+00:00
2025-02-22 11:20:13,532 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-29 00:00:00+00:00: scheduled__2024-06-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:13,532 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-29 00:00:00+00:00, run_id=scheduled__2024-06-29T00:00:00+00:00, run_start_date=2025-02-22 11:19:53.768247+00:00, run_end_date=2025-02-22 11:20:13.532808+00:00, run_duration=19.764561, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-29 00:00:00+00:00, data_interval_end=2024-06-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:13,536 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-06-30T00:00:00+00:00, run_after=2024-07-01T00:00:00+00:00
2025-02-22 11:20:13,559 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:13,560 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:13,560 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:13,560 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:13,560 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:20:13,560 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-06-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:13,562 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:13,562 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:13,562 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:13,562 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:13,563 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:13,563 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:13,563 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:13,563 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:13,577 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:15,415 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:17,408 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:19,183 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:20,961 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:20,961 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:20,961 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:20,961 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-06-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:20,969 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-06-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:20.501217+00:00, run_end_date=2025-02-22 11:20:20.652478+00:00, run_duration=0.151261, state=success, executor_state=success, try_number=1, max_tries=1, job_id=553, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:13.560868+00:00, queued_by_job_id=7, pid=60706
2025-02-22 11:20:20,970 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:18.702111+00:00, run_end_date=2025-02-22 11:20:18.847136+00:00, run_duration=0.145025, state=success, executor_state=success, try_number=1, max_tries=1, job_id=552, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:13.560868+00:00, queued_by_job_id=7, pid=60687
2025-02-22 11:20:20,970 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:16.760003+00:00, run_end_date=2025-02-22 11:20:16.974695+00:00, run_duration=0.214692, state=success, executor_state=success, try_number=1, max_tries=1, job_id=551, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:13.560868+00:00, queued_by_job_id=7, pid=60668
2025-02-22 11:20:20,970 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:14.925885+00:00, run_end_date=2025-02-22 11:20:15.077529+00:00, run_duration=0.151644, state=success, executor_state=success, try_number=1, max_tries=1, job_id=550, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:13.560868+00:00, queued_by_job_id=7, pid=60645
2025-02-22 11:20:21,132 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-01T00:00:00+00:00, run_after=2024-07-02T00:00:00+00:00
2025-02-22 11:20:21,222 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-06-30 00:00:00+00:00: scheduled__2024-06-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:21,222 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-06-30 00:00:00+00:00, run_id=scheduled__2024-06-30T00:00:00+00:00, run_start_date=2025-02-22 11:19:55.954538+00:00, run_end_date=2025-02-22 11:20:21.222783+00:00, run_duration=25.268245, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-06-30 00:00:00+00:00, data_interval_end=2024-07-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:21,227 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-01T00:00:00+00:00, run_after=2024-07-02T00:00:00+00:00
2025-02-22 11:20:21,288 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:21,288 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:21,288 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:21,289 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:21,289 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:21,293 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:21,293 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:21,294 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:21,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:21,294 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:21,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:21,309 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:23,123 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:25,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:26,958 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:26,959 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:26,959 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:26,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:26.476573+00:00, run_end_date=2025-02-22 11:20:26.635920+00:00, run_duration=0.159347, state=success, executor_state=success, try_number=1, max_tries=1, job_id=556, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:21.290054+00:00, queued_by_job_id=7, pid=60771
2025-02-22 11:20:26,967 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:24.448273+00:00, run_end_date=2025-02-22 11:20:24.793556+00:00, run_duration=0.345283, state=success, executor_state=success, try_number=1, max_tries=1, job_id=555, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:21.290054+00:00, queued_by_job_id=7, pid=60752
2025-02-22 11:20:26,967 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:22.640805+00:00, run_end_date=2025-02-22 11:20:22.799895+00:00, run_duration=0.15909, state=success, executor_state=success, try_number=1, max_tries=1, job_id=554, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:21.290054+00:00, queued_by_job_id=7, pid=60734
2025-02-22 11:20:27,132 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-02T00:00:00+00:00, run_after=2024-07-03T00:00:00+00:00
2025-02-22 11:20:27,194 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-01 00:00:00+00:00: scheduled__2024-07-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:27,195 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-01 00:00:00+00:00, run_id=scheduled__2024-07-01T00:00:00+00:00, run_start_date=2025-02-22 11:19:59.902419+00:00, run_end_date=2025-02-22 11:20:27.195126+00:00, run_duration=27.292707, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-01 00:00:00+00:00, data_interval_end=2024-07-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:27,200 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-02T00:00:00+00:00, run_after=2024-07-03T00:00:00+00:00
2025-02-22 11:20:27,227 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:27,227 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:27,227 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:27,227 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:27,230 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:27,230 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:27,230 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:27,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:27,244 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:29,046 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:30,974 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:30,975 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:30,983 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:30.357741+00:00, run_end_date=2025-02-22 11:20:30.628924+00:00, run_duration=0.271183, state=success, executor_state=success, try_number=1, max_tries=1, job_id=558, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:27.228108+00:00, queued_by_job_id=7, pid=60810
2025-02-22 11:20:30,983 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:28.574814+00:00, run_end_date=2025-02-22 11:20:28.722645+00:00, run_duration=0.147831, state=success, executor_state=success, try_number=1, max_tries=1, job_id=557, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:27.228108+00:00, queued_by_job_id=7, pid=60791
2025-02-22 11:20:31,124 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-03T00:00:00+00:00, run_after=2024-07-04T00:00:00+00:00
2025-02-22 11:20:31,179 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-02 00:00:00+00:00: scheduled__2024-07-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:31,179 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-02 00:00:00+00:00, run_id=scheduled__2024-07-02T00:00:00+00:00, run_start_date=2025-02-22 11:20:05.718486+00:00, run_end_date=2025-02-22 11:20:31.179674+00:00, run_duration=25.461188, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-02 00:00:00+00:00, data_interval_end=2024-07-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:31,185 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-03T00:00:00+00:00, run_after=2024-07-04T00:00:00+00:00
2025-02-22 11:20:31,218 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:31,218 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:31,218 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:31,221 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:31,222 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:31,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:33,024 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:33,030 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:32.557424+00:00, run_end_date=2025-02-22 11:20:32.714929+00:00, run_duration=0.157505, state=success, executor_state=success, try_number=1, max_tries=1, job_id=559, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:31.219523+00:00, queued_by_job_id=7, pid=60830
2025-02-22 11:20:33,186 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-04T00:00:00+00:00, run_after=2024-07-05T00:00:00+00:00
2025-02-22 11:20:33,214 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-03 00:00:00+00:00: scheduled__2024-07-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:33,214 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-03 00:00:00+00:00, run_id=scheduled__2024-07-03T00:00:00+00:00, run_start_date=2025-02-22 11:20:13.487195+00:00, run_end_date=2025-02-22 11:20:33.214905+00:00, run_duration=19.72771, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-03 00:00:00+00:00, data_interval_end=2024-07-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:33,217 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-04T00:00:00+00:00, run_after=2024-07-05T00:00:00+00:00
2025-02-22 11:20:34,386 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-05T00:00:00+00:00, run_after=2024-07-06T00:00:00+00:00
2025-02-22 11:20:34,462 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:34,462 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:34,462 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:34,463 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:34,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:34,476 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:36,445 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:36,453 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:35.908473+00:00, run_end_date=2025-02-22 11:20:36.093622+00:00, run_duration=0.185149, state=success, executor_state=success, try_number=1, max_tries=1, job_id=560, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:34.462763+00:00, queued_by_job_id=7, pid=60859
2025-02-22 11:20:36,614 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-06T00:00:00+00:00, run_after=2024-07-07T00:00:00+00:00
2025-02-22 11:20:36,696 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:36,697 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:36,697 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:36,697 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:36,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:36,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:36,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:36,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:36,712 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:38,483 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:40,247 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:40,248 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:40,256 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:39.794338+00:00, run_end_date=2025-02-22 11:20:39.962388+00:00, run_duration=0.16805, state=success, executor_state=success, try_number=1, max_tries=1, job_id=562, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:36.697661+00:00, queued_by_job_id=7, pid=60898
2025-02-22 11:20:40,256 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:38.021462+00:00, run_end_date=2025-02-22 11:20:38.164948+00:00, run_duration=0.143486, state=success, executor_state=success, try_number=1, max_tries=1, job_id=561, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:36.697661+00:00, queued_by_job_id=7, pid=60880
2025-02-22 11:20:40,435 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-07T00:00:00+00:00, run_after=2024-07-08T00:00:00+00:00
2025-02-22 11:20:40,517 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:40,518 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:40,518 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:40,518 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:40,518 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:40,520 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:40,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:40,520 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:40,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:40,520 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:40,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:40,531 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:42,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:44,175 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:45,984 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:45,984 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:45,984 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:45,992 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:45.486777+00:00, run_end_date=2025-02-22 11:20:45.639138+00:00, run_duration=0.152361, state=success, executor_state=success, try_number=1, max_tries=1, job_id=565, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:40.518699+00:00, queued_by_job_id=7, pid=60964
2025-02-22 11:20:45,993 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:43.710119+00:00, run_end_date=2025-02-22 11:20:43.856138+00:00, run_duration=0.146019, state=success, executor_state=success, try_number=1, max_tries=1, job_id=564, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:40.518699+00:00, queued_by_job_id=7, pid=60946
2025-02-22 11:20:45,993 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:41.868760+00:00, run_end_date=2025-02-22 11:20:42.033784+00:00, run_duration=0.165024, state=success, executor_state=success, try_number=1, max_tries=1, job_id=563, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:40.518699+00:00, queued_by_job_id=7, pid=60919
2025-02-22 11:20:46,165 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-08T00:00:00+00:00, run_after=2024-07-09T00:00:00+00:00
2025-02-22 11:20:46,454 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:46,455 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:46,455 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:46,455 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:46,455 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:20:46,455 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:46,457 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:46,457 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:46,457 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:46,457 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:46,458 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:46,458 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:46,458 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:46,458 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:46,469 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:48,272 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:50,104 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:51,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:53,846 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:53,846 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:53,846 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:53,846 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:20:53,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:53.199378+00:00, run_end_date=2025-02-22 11:20:53.516309+00:00, run_duration=0.316931, state=success, executor_state=success, try_number=1, max_tries=1, job_id=569, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:46.455795+00:00, queued_by_job_id=7, pid=61041
2025-02-22 11:20:53,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:51.426359+00:00, run_end_date=2025-02-22 11:20:51.580087+00:00, run_duration=0.153728, state=success, executor_state=success, try_number=1, max_tries=1, job_id=568, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:46.455795+00:00, queued_by_job_id=7, pid=61022
2025-02-22 11:20:53,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:49.595507+00:00, run_end_date=2025-02-22 11:20:49.746217+00:00, run_duration=0.15071, state=success, executor_state=success, try_number=1, max_tries=1, job_id=567, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:46.455795+00:00, queued_by_job_id=7, pid=61003
2025-02-22 11:20:53,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:47.789031+00:00, run_end_date=2025-02-22 11:20:47.948639+00:00, run_duration=0.159608, state=success, executor_state=success, try_number=1, max_tries=1, job_id=566, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:46.455795+00:00, queued_by_job_id=7, pid=60984
2025-02-22 11:20:54,029 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-09T00:00:00+00:00, run_after=2024-07-10T00:00:00+00:00
2025-02-22 11:20:54,095 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-04 00:00:00+00:00: scheduled__2024-07-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:20:54,095 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-04 00:00:00+00:00, run_id=scheduled__2024-07-04T00:00:00+00:00, run_start_date=2025-02-22 11:20:34.413643+00:00, run_end_date=2025-02-22 11:20:54.095566+00:00, run_duration=19.681923, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-04 00:00:00+00:00, data_interval_end=2024-07-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:20:54,098 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-05T00:00:00+00:00, run_after=2024-07-06T00:00:00+00:00
2025-02-22 11:20:54,121 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:54,121 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:20:54,121 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:20:54,121 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:20:54,122 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:20:54,122 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:20:54,124 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:20:54,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:54,124 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:20:54,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:54,124 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:20:54,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:54,125 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:20:54,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:54,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:56,008 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:57,926 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:20:59,803 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:01,652 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:01,652 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:01,652 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:01,652 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:01,660 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:01.121630+00:00, run_end_date=2025-02-22 11:21:01.277922+00:00, run_duration=0.156292, state=success, executor_state=success, try_number=1, max_tries=1, job_id=573, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:20:54.122536+00:00, queued_by_job_id=7, pid=61125
2025-02-22 11:21:01,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:59.323286+00:00, run_end_date=2025-02-22 11:20:59.475657+00:00, run_duration=0.152371, state=success, executor_state=success, try_number=1, max_tries=1, job_id=572, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:20:54.122536+00:00, queued_by_job_id=7, pid=61106
2025-02-22 11:21:01,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:57.320449+00:00, run_end_date=2025-02-22 11:20:57.474699+00:00, run_duration=0.15425, state=success, executor_state=success, try_number=1, max_tries=1, job_id=571, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:20:54.122536+00:00, queued_by_job_id=7, pid=61088
2025-02-22 11:21:01,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:20:55.533031+00:00, run_end_date=2025-02-22 11:20:55.708688+00:00, run_duration=0.175657, state=success, executor_state=success, try_number=1, max_tries=1, job_id=570, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:20:54.122536+00:00, queued_by_job_id=7, pid=61069
2025-02-22 11:21:01,825 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-06T00:00:00+00:00, run_after=2024-07-07T00:00:00+00:00
2025-02-22 11:21:01,889 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-05 00:00:00+00:00: scheduled__2024-07-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:01,889 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-05 00:00:00+00:00, run_id=scheduled__2024-07-05T00:00:00+00:00, run_start_date=2025-02-22 11:20:36.640713+00:00, run_end_date=2025-02-22 11:21:01.889446+00:00, run_duration=25.248733, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-05 00:00:00+00:00, data_interval_end=2024-07-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:01,894 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-06T00:00:00+00:00, run_after=2024-07-07T00:00:00+00:00
2025-02-22 11:21:01,919 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:01,920 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:01,920 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:01,920 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:21:01,920 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:01,923 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:01,923 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:01,923 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:01,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:01,924 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:01,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:01,938 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:03,764 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:05,547 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:07,329 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:07,330 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:07,330 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:07,338 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:06.865666+00:00, run_end_date=2025-02-22 11:21:07.008581+00:00, run_duration=0.142915, state=success, executor_state=success, try_number=1, max_tries=1, job_id=576, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:01.921172+00:00, queued_by_job_id=7, pid=61190
2025-02-22 11:21:07,338 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:05.073152+00:00, run_end_date=2025-02-22 11:21:05.230337+00:00, run_duration=0.157185, state=success, executor_state=success, try_number=1, max_tries=1, job_id=575, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:01.921172+00:00, queued_by_job_id=7, pid=61164
2025-02-22 11:21:07,339 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:03.251146+00:00, run_end_date=2025-02-22 11:21:03.405485+00:00, run_duration=0.154339, state=success, executor_state=success, try_number=1, max_tries=1, job_id=574, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:01.921172+00:00, queued_by_job_id=7, pid=61145
2025-02-22 11:21:07,517 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-07T00:00:00+00:00, run_after=2024-07-08T00:00:00+00:00
2025-02-22 11:21:07,572 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-06 00:00:00+00:00: scheduled__2024-07-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:07,573 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-06 00:00:00+00:00, run_id=scheduled__2024-07-06T00:00:00+00:00, run_start_date=2025-02-22 11:20:40.460960+00:00, run_end_date=2025-02-22 11:21:07.573289+00:00, run_duration=27.112329, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-06 00:00:00+00:00, data_interval_end=2024-07-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:07,578 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-07T00:00:00+00:00, run_after=2024-07-08T00:00:00+00:00
2025-02-22 11:21:07,605 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:07,606 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:07,606 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:07,606 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:07,609 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:07,610 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:07,610 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:07,610 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:07,624 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:09,437 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:11,227 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:11,228 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:11,235 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:10.742775+00:00, run_end_date=2025-02-22 11:21:10.918328+00:00, run_duration=0.175553, state=success, executor_state=success, try_number=1, max_tries=1, job_id=578, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:07.607197+00:00, queued_by_job_id=7, pid=61229
2025-02-22 11:21:11,235 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:08.940964+00:00, run_end_date=2025-02-22 11:21:09.093759+00:00, run_duration=0.152795, state=success, executor_state=success, try_number=1, max_tries=1, job_id=577, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:07.607197+00:00, queued_by_job_id=7, pid=61211
2025-02-22 11:21:11,378 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-08T00:00:00+00:00, run_after=2024-07-09T00:00:00+00:00
2025-02-22 11:21:11,433 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-07 00:00:00+00:00: scheduled__2024-07-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:11,434 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-07 00:00:00+00:00, run_id=scheduled__2024-07-07T00:00:00+00:00, run_start_date=2025-02-22 11:20:46.305796+00:00, run_end_date=2025-02-22 11:21:11.434148+00:00, run_duration=25.128352, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-07 00:00:00+00:00, data_interval_end=2024-07-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:11,439 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-08T00:00:00+00:00, run_after=2024-07-09T00:00:00+00:00
2025-02-22 11:21:11,467 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:11,467 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:11,467 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:11,470 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:11,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:11,484 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:13,479 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:13,484 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:13.017985+00:00, run_end_date=2025-02-22 11:21:13.171952+00:00, run_duration=0.153967, state=success, executor_state=success, try_number=1, max_tries=1, job_id=579, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:11.468682+00:00, queued_by_job_id=7, pid=61251
2025-02-22 11:21:13,733 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-09T00:00:00+00:00, run_after=2024-07-10T00:00:00+00:00
2025-02-22 11:21:13,773 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-08 00:00:00+00:00: scheduled__2024-07-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:13,773 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-08 00:00:00+00:00, run_id=scheduled__2024-07-08T00:00:00+00:00, run_start_date=2025-02-22 11:20:54.053256+00:00, run_end_date=2025-02-22 11:21:13.773892+00:00, run_duration=19.720636, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-08 00:00:00+00:00, data_interval_end=2024-07-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:13,779 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-09T00:00:00+00:00, run_after=2024-07-10T00:00:00+00:00
2025-02-22 11:21:14,956 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-10T00:00:00+00:00, run_after=2024-07-11T00:00:00+00:00
2025-02-22 11:21:15,035 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:15,035 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:15,035 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:15,037 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:15,037 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:15,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:16,953 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:16,960 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:16.393035+00:00, run_end_date=2025-02-22 11:21:16.554445+00:00, run_duration=0.16141, state=success, executor_state=success, try_number=1, max_tries=1, job_id=580, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:15.035823+00:00, queued_by_job_id=7, pid=61280
2025-02-22 11:21:17,208 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-11T00:00:00+00:00, run_after=2024-07-12T00:00:00+00:00
2025-02-22 11:21:17,352 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:17,352 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:17,352 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:17,352 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:17,354 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:17,354 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:17,354 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:17,355 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:17,368 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:19,282 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:21,099 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:21,099 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:21,104 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:20.614579+00:00, run_end_date=2025-02-22 11:21:20.770857+00:00, run_duration=0.156278, state=success, executor_state=success, try_number=1, max_tries=1, job_id=582, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:17.352941+00:00, queued_by_job_id=7, pid=61320
2025-02-22 11:21:21,105 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:18.792864+00:00, run_end_date=2025-02-22 11:21:18.957108+00:00, run_duration=0.164244, state=success, executor_state=success, try_number=1, max_tries=1, job_id=581, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:17.352941+00:00, queued_by_job_id=7, pid=61301
2025-02-22 11:21:21,270 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-12T00:00:00+00:00, run_after=2024-07-13T00:00:00+00:00
2025-02-22 11:21:21,346 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:21,346 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:21,346 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:21,346 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:21:21,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:21,348 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:21,348 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:21,349 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:21,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:21,349 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:21,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:21,361 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:23,226 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:25,203 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:27,050 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:27,050 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:27,050 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:27,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:26.577708+00:00, run_end_date=2025-02-22 11:21:26.723130+00:00, run_duration=0.145422, state=success, executor_state=success, try_number=1, max_tries=1, job_id=585, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:21.347202+00:00, queued_by_job_id=7, pid=61385
2025-02-22 11:21:27,059 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:24.577985+00:00, run_end_date=2025-02-22 11:21:24.845467+00:00, run_duration=0.267482, state=success, executor_state=success, try_number=1, max_tries=1, job_id=584, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:21.347202+00:00, queued_by_job_id=7, pid=61359
2025-02-22 11:21:27,059 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:22.744476+00:00, run_end_date=2025-02-22 11:21:22.902656+00:00, run_duration=0.15818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=583, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:21.347202+00:00, queued_by_job_id=7, pid=61340
2025-02-22 11:21:27,229 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-13T00:00:00+00:00, run_after=2024-07-14T00:00:00+00:00
2025-02-22 11:21:27,310 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:27,310 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:27,310 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:27,310 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:21:27,310 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:21:27,310 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:27,312 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:27,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:27,313 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:27,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:27,313 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:27,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:27,313 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:27,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:27,324 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:29,169 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:31,078 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:32,909 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:34,895 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:34,896 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:34,896 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:34,896 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:34,904 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:34.216827+00:00, run_end_date=2025-02-22 11:21:34.424489+00:00, run_duration=0.207662, state=success, executor_state=success, try_number=1, max_tries=1, job_id=589, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:27.311068+00:00, queued_by_job_id=7, pid=61463
2025-02-22 11:21:34,904 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:32.398765+00:00, run_end_date=2025-02-22 11:21:32.557975+00:00, run_duration=0.15921, state=success, executor_state=success, try_number=1, max_tries=1, job_id=588, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:27.311068+00:00, queued_by_job_id=7, pid=61444
2025-02-22 11:21:34,904 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:30.550014+00:00, run_end_date=2025-02-22 11:21:30.808476+00:00, run_duration=0.258462, state=success, executor_state=success, try_number=1, max_tries=1, job_id=587, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:27.311068+00:00, queued_by_job_id=7, pid=61424
2025-02-22 11:21:34,905 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:28.643052+00:00, run_end_date=2025-02-22 11:21:28.791883+00:00, run_duration=0.148831, state=success, executor_state=success, try_number=1, max_tries=1, job_id=586, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:27.311068+00:00, queued_by_job_id=7, pid=61406
2025-02-22 11:21:35,075 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-14T00:00:00+00:00, run_after=2024-07-15T00:00:00+00:00
2025-02-22 11:21:35,148 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-09 00:00:00+00:00: scheduled__2024-07-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:35,149 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-09 00:00:00+00:00, run_id=scheduled__2024-07-09T00:00:00+00:00, run_start_date=2025-02-22 11:21:14.983335+00:00, run_end_date=2025-02-22 11:21:35.148978+00:00, run_duration=20.165643, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-09 00:00:00+00:00, data_interval_end=2024-07-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:35,152 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-10T00:00:00+00:00, run_after=2024-07-11T00:00:00+00:00
2025-02-22 11:21:35,178 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:35,179 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:35,179 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:35,179 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:21:35,179 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:21:35,179 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:35,181 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:35,181 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:35,181 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:35,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:35,182 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:35,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:35,182 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:35,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:35,197 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:37,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:38,890 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:40,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:42,563 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:42,563 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:42,563 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:42,563 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:42,571 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:42.093670+00:00, run_end_date=2025-02-22 11:21:42.241114+00:00, run_duration=0.147444, state=success, executor_state=success, try_number=1, max_tries=1, job_id=593, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:35.179825+00:00, queued_by_job_id=7, pid=61539
2025-02-22 11:21:42,571 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:40.213977+00:00, run_end_date=2025-02-22 11:21:40.451573+00:00, run_duration=0.237596, state=success, executor_state=success, try_number=1, max_tries=1, job_id=592, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:35.179825+00:00, queued_by_job_id=7, pid=61521
2025-02-22 11:21:42,572 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:38.375419+00:00, run_end_date=2025-02-22 11:21:38.525850+00:00, run_duration=0.150431, state=success, executor_state=success, try_number=1, max_tries=1, job_id=591, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:35.179825+00:00, queued_by_job_id=7, pid=61502
2025-02-22 11:21:42,572 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:36.549350+00:00, run_end_date=2025-02-22 11:21:36.702147+00:00, run_duration=0.152797, state=success, executor_state=success, try_number=1, max_tries=1, job_id=590, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:35.179825+00:00, queued_by_job_id=7, pid=61483
2025-02-22 11:21:42,768 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-11T00:00:00+00:00, run_after=2024-07-12T00:00:00+00:00
2025-02-22 11:21:42,842 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-10 00:00:00+00:00: scheduled__2024-07-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:42,843 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-10 00:00:00+00:00, run_id=scheduled__2024-07-10T00:00:00+00:00, run_start_date=2025-02-22 11:21:17.280410+00:00, run_end_date=2025-02-22 11:21:42.843036+00:00, run_duration=25.562626, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-10 00:00:00+00:00, data_interval_end=2024-07-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:42,847 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-11T00:00:00+00:00, run_after=2024-07-12T00:00:00+00:00
2025-02-22 11:21:42,875 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:42,875 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:42,875 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:42,876 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:21:42,876 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:42,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:42,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:42,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:42,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:42,880 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:42,880 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:42,893 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:44,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:47,092 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:48,888 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:48,889 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:48,889 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:48,906 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:48.427445+00:00, run_end_date=2025-02-22 11:21:48.576022+00:00, run_duration=0.148577, state=success, executor_state=success, try_number=1, max_tries=1, job_id=596, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:42.876711+00:00, queued_by_job_id=7, pid=61607
2025-02-22 11:21:48,907 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:46.251922+00:00, run_end_date=2025-02-22 11:21:46.406045+00:00, run_duration=0.154123, state=success, executor_state=success, try_number=1, max_tries=1, job_id=595, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:42.876711+00:00, queued_by_job_id=7, pid=61588
2025-02-22 11:21:48,907 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:44.236910+00:00, run_end_date=2025-02-22 11:21:44.400814+00:00, run_duration=0.163904, state=success, executor_state=success, try_number=1, max_tries=1, job_id=594, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:42.876711+00:00, queued_by_job_id=7, pid=61568
2025-02-22 11:21:49,282 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-12T00:00:00+00:00, run_after=2024-07-13T00:00:00+00:00
2025-02-22 11:21:49,336 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-11 00:00:00+00:00: scheduled__2024-07-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:49,337 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-11 00:00:00+00:00, run_id=scheduled__2024-07-11T00:00:00+00:00, run_start_date=2025-02-22 11:21:21.292179+00:00, run_end_date=2025-02-22 11:21:49.337051+00:00, run_duration=28.044872, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-11 00:00:00+00:00, data_interval_end=2024-07-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:49,342 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-12T00:00:00+00:00, run_after=2024-07-13T00:00:00+00:00
2025-02-22 11:21:49,364 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:49,364 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:49,364 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:21:49,364 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:49,366 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:21:49,366 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:49,366 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:49,366 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:49,379 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:51,359 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:53,216 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:53,216 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:53,224 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:52.698486+00:00, run_end_date=2025-02-22 11:21:52.883881+00:00, run_duration=0.185395, state=success, executor_state=success, try_number=1, max_tries=1, job_id=598, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:49.364975+00:00, queued_by_job_id=7, pid=61658
2025-02-22 11:21:53,224 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:50.766602+00:00, run_end_date=2025-02-22 11:21:51.007788+00:00, run_duration=0.241186, state=success, executor_state=success, try_number=1, max_tries=1, job_id=597, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:21:49.364975+00:00, queued_by_job_id=7, pid=61639
2025-02-22 11:21:53,668 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-13T00:00:00+00:00, run_after=2024-07-14T00:00:00+00:00
2025-02-22 11:21:53,704 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-12 00:00:00+00:00: scheduled__2024-07-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:53,704 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-12 00:00:00+00:00, run_id=scheduled__2024-07-12T00:00:00+00:00, run_start_date=2025-02-22 11:21:27.250007+00:00, run_end_date=2025-02-22 11:21:53.704744+00:00, run_duration=26.454737, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-12 00:00:00+00:00, data_interval_end=2024-07-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:53,708 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-13T00:00:00+00:00, run_after=2024-07-14T00:00:00+00:00
2025-02-22 11:21:53,730 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:53,730 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:53,730 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:53,732 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:21:53,732 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:53,746 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:55,519 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:55,527 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:55.066379+00:00, run_end_date=2025-02-22 11:21:55.236091+00:00, run_duration=0.169712, state=success, executor_state=success, try_number=1, max_tries=1, job_id=599, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:21:53.731242+00:00, queued_by_job_id=7, pid=61694
2025-02-22 11:21:55,995 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-15T00:00:00+00:00, run_after=2024-07-16T00:00:00+00:00
2025-02-22 11:21:56,055 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-13 00:00:00+00:00: scheduled__2024-07-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:21:56,055 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-13 00:00:00+00:00, run_id=scheduled__2024-07-13T00:00:00+00:00, run_start_date=2025-02-22 11:21:35.103088+00:00, run_end_date=2025-02-22 11:21:56.055911+00:00, run_duration=20.952823, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-13 00:00:00+00:00, data_interval_end=2024-07-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:21:56,059 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-14T00:00:00+00:00, run_after=2024-07-15T00:00:00+00:00
2025-02-22 11:21:56,079 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:56,079 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:56,079 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:56,081 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:21:56,081 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:56,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:58,087 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:21:58,095 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:57.435760+00:00, run_end_date=2025-02-22 11:21:57.699111+00:00, run_duration=0.263351, state=success, executor_state=success, try_number=1, max_tries=1, job_id=600, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:21:56.080151+00:00, queued_by_job_id=7, pid=61722
2025-02-22 11:21:58,109 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:21:58,261 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-15T00:00:00+00:00, run_after=2024-07-16T00:00:00+00:00
2025-02-22 11:21:58,313 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:58,313 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:21:58,313 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:21:58,315 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:21:58,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:21:58,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:00,133 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:00,141 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:21:59.656423+00:00, run_end_date=2025-02-22 11:21:59.810500+00:00, run_duration=0.154077, state=success, executor_state=success, try_number=1, max_tries=1, job_id=601, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:21:58.313873+00:00, queued_by_job_id=7, pid=61742
2025-02-22 11:22:00,287 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-16T00:00:00+00:00, run_after=2024-07-17T00:00:00+00:00
2025-02-22 11:22:00,368 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:00,368 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:00,368 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:00,368 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:00,370 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:00,370 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:00,370 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:00,370 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:00,383 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:02,288 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:04,139 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:04,140 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:04,145 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:03.666515+00:00, run_end_date=2025-02-22 11:22:03.822370+00:00, run_duration=0.155855, state=success, executor_state=success, try_number=1, max_tries=1, job_id=603, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:00.369005+00:00, queued_by_job_id=7, pid=61789
2025-02-22 11:22:04,146 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:01.702834+00:00, run_end_date=2025-02-22 11:22:01.849002+00:00, run_duration=0.146168, state=success, executor_state=success, try_number=1, max_tries=1, job_id=602, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:00.369005+00:00, queued_by_job_id=7, pid=61763
2025-02-22 11:22:04,313 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-17T00:00:00+00:00, run_after=2024-07-18T00:00:00+00:00
2025-02-22 11:22:04,385 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:04,385 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:04,385 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:04,385 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:04,385 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:04,386 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:04,386 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:04,386 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:04,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:04,387 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:04,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:04,399 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:06,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:08,190 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:10,053 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:10,054 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:10,054 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:10,062 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:09.532152+00:00, run_end_date=2025-02-22 11:22:09.703475+00:00, run_duration=0.171323, state=success, executor_state=success, try_number=1, max_tries=1, job_id=606, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:04.385622+00:00, queued_by_job_id=7, pid=61849
2025-02-22 11:22:10,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:07.466368+00:00, run_end_date=2025-02-22 11:22:07.663296+00:00, run_duration=0.196928, state=success, executor_state=success, try_number=1, max_tries=1, job_id=605, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:04.385622+00:00, queued_by_job_id=7, pid=61830
2025-02-22 11:22:10,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:05.700098+00:00, run_end_date=2025-02-22 11:22:05.872338+00:00, run_duration=0.17224, state=success, executor_state=success, try_number=1, max_tries=1, job_id=604, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:04.385622+00:00, queued_by_job_id=7, pid=61809
2025-02-22 11:22:10,232 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-18T00:00:00+00:00, run_after=2024-07-19T00:00:00+00:00
2025-02-22 11:22:10,295 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-14 00:00:00+00:00: scheduled__2024-07-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:10,296 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-14 00:00:00+00:00, run_id=scheduled__2024-07-14T00:00:00+00:00, run_start_date=2025-02-22 11:21:56.022273+00:00, run_end_date=2025-02-22 11:22:10.296046+00:00, run_duration=14.273773, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-14 00:00:00+00:00, data_interval_end=2024-07-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:10,299 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-15T00:00:00+00:00, run_after=2024-07-16T00:00:00+00:00
2025-02-22 11:22:10,322 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:10,322 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:10,322 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:10,322 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:10,322 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:10,324 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:10,324 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:10,324 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:10,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:10,325 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:10,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:10,338 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:12,146 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:14,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:15,951 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:15,952 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:15,953 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:15,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:15.466393+00:00, run_end_date=2025-02-22 11:22:15.613030+00:00, run_duration=0.146637, state=success, executor_state=success, try_number=1, max_tries=1, job_id=609, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:10.323029+00:00, queued_by_job_id=7, pid=61915
2025-02-22 11:22:15,967 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:13.474458+00:00, run_end_date=2025-02-22 11:22:13.620586+00:00, run_duration=0.146128, state=success, executor_state=success, try_number=1, max_tries=1, job_id=608, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:10.323029+00:00, queued_by_job_id=7, pid=61889
2025-02-22 11:22:15,967 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:11.651922+00:00, run_end_date=2025-02-22 11:22:11.817182+00:00, run_duration=0.16526, state=success, executor_state=success, try_number=1, max_tries=1, job_id=607, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:10.323029+00:00, queued_by_job_id=7, pid=61870
2025-02-22 11:22:16,264 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-16T00:00:00+00:00, run_after=2024-07-17T00:00:00+00:00
2025-02-22 11:22:16,331 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:16,331 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:16,331 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:16,331 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:16,331 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:16,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:16,334 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:16,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:16,334 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:16,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:16,334 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:16,348 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:18,506 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:20,640 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:22,509 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:22,509 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:22,510 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:22,518 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:22.058057+00:00, run_end_date=2025-02-22 11:22:22.205650+00:00, run_duration=0.147593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:16.332330+00:00, queued_by_job_id=7, pid=61974
2025-02-22 11:22:22,518 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:19.989940+00:00, run_end_date=2025-02-22 11:22:20.277568+00:00, run_duration=0.287628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=611, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:16.332330+00:00, queued_by_job_id=7, pid=61954
2025-02-22 11:22:22,518 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:17.657673+00:00, run_end_date=2025-02-22 11:22:17.804794+00:00, run_duration=0.147121, state=success, executor_state=success, try_number=1, max_tries=1, job_id=610, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:16.332330+00:00, queued_by_job_id=7, pid=61935
2025-02-22 11:22:22,679 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-17T00:00:00+00:00, run_after=2024-07-18T00:00:00+00:00
2025-02-22 11:22:22,741 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-15 00:00:00+00:00: scheduled__2024-07-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:22,742 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-15 00:00:00+00:00, run_id=scheduled__2024-07-15T00:00:00+00:00, run_start_date=2025-02-22 11:22:00.314424+00:00, run_end_date=2025-02-22 11:22:22.742090+00:00, run_duration=22.427666, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-15 00:00:00+00:00, data_interval_end=2024-07-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:22,747 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-16T00:00:00+00:00, run_after=2024-07-17T00:00:00+00:00
2025-02-22 11:22:22,783 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:22,783 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:22,783 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:22,783 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:22,787 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:22,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:22,788 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:22,788 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:22,803 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:24,683 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:26,566 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:26,566 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:26,574 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:26.000230+00:00, run_end_date=2025-02-22 11:22:26.149437+00:00, run_duration=0.149207, state=success, executor_state=success, try_number=1, max_tries=1, job_id=614, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:22.784595+00:00, queued_by_job_id=7, pid=62020
2025-02-22 11:22:26,574 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:24.187650+00:00, run_end_date=2025-02-22 11:22:24.339975+00:00, run_duration=0.152325, state=success, executor_state=success, try_number=1, max_tries=1, job_id=613, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:22.784595+00:00, queued_by_job_id=7, pid=61993
2025-02-22 11:22:26,715 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-17T00:00:00+00:00, run_after=2024-07-18T00:00:00+00:00
2025-02-22 11:22:26,767 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-16 00:00:00+00:00: scheduled__2024-07-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:26,767 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-16 00:00:00+00:00, run_id=scheduled__2024-07-16T00:00:00+00:00, run_start_date=2025-02-22 11:22:04.337035+00:00, run_end_date=2025-02-22 11:22:26.767578+00:00, run_duration=22.430543, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-16 00:00:00+00:00, data_interval_end=2024-07-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:26,770 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-17T00:00:00+00:00, run_after=2024-07-18T00:00:00+00:00
2025-02-22 11:22:26,793 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:26,793 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:26,793 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:26,795 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:26,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:26,812 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:28,753 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:28,760 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:28.186469+00:00, run_end_date=2025-02-22 11:22:28.421373+00:00, run_duration=0.234904, state=success, executor_state=success, try_number=1, max_tries=1, job_id=615, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:26.793778+00:00, queued_by_job_id=7, pid=62040
2025-02-22 11:22:28,916 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-18T00:00:00+00:00, run_after=2024-07-19T00:00:00+00:00
2025-02-22 11:22:28,955 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-17 00:00:00+00:00: scheduled__2024-07-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:28,956 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-17 00:00:00+00:00, run_id=scheduled__2024-07-17T00:00:00+00:00, run_start_date=2025-02-22 11:22:10.257321+00:00, run_end_date=2025-02-22 11:22:28.956392+00:00, run_duration=18.699071, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:28,962 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-18T00:00:00+00:00, run_after=2024-07-19T00:00:00+00:00
2025-02-22 11:22:30,138 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-19T00:00:00+00:00, run_after=2024-07-20T00:00:00+00:00
2025-02-22 11:22:30,216 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:30,217 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:30,217 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:30,218 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:30,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:30,232 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:32,133 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:32,139 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:31.643502+00:00, run_end_date=2025-02-22 11:22:31.794240+00:00, run_duration=0.150738, state=success, executor_state=success, try_number=1, max_tries=1, job_id=616, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:30.217763+00:00, queued_by_job_id=7, pid=62063
2025-02-22 11:22:32,287 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-20T00:00:00+00:00, run_after=2024-07-21T00:00:00+00:00
2025-02-22 11:22:32,348 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:32,348 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:32,348 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:32,348 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:32,350 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:32,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:32,350 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:32,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:32,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:34,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:36,157 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:36,157 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:36,165 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:35.663950+00:00, run_end_date=2025-02-22 11:22:35.825357+00:00, run_duration=0.161407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=618, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:32.349197+00:00, queued_by_job_id=7, pid=62102
2025-02-22 11:22:36,165 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:33.698381+00:00, run_end_date=2025-02-22 11:22:34.010771+00:00, run_duration=0.31239, state=success, executor_state=success, try_number=1, max_tries=1, job_id=617, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:32.349197+00:00, queued_by_job_id=7, pid=62083
2025-02-22 11:22:36,334 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-21T00:00:00+00:00, run_after=2024-07-22T00:00:00+00:00
2025-02-22 11:22:36,410 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:36,410 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:36,410 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:36,410 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:36,410 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:36,412 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:36,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:36,412 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:36,413 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:36,413 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:36,413 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:36,426 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:38,208 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:39,983 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:42,000 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:42,001 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:42,001 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:42,009 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:41.283371+00:00, run_end_date=2025-02-22 11:22:41.505477+00:00, run_duration=0.222106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=621, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:36.411153+00:00, queued_by_job_id=7, pid=62172
2025-02-22 11:22:42,009 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:39.511341+00:00, run_end_date=2025-02-22 11:22:39.660062+00:00, run_duration=0.148721, state=success, executor_state=success, try_number=1, max_tries=1, job_id=620, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:36.411153+00:00, queued_by_job_id=7, pid=62151
2025-02-22 11:22:42,009 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:37.766593+00:00, run_end_date=2025-02-22 11:22:37.917005+00:00, run_duration=0.150412, state=success, executor_state=success, try_number=1, max_tries=1, job_id=619, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:36.411153+00:00, queued_by_job_id=7, pid=62129
2025-02-22 11:22:42,326 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-22T00:00:00+00:00, run_after=2024-07-23T00:00:00+00:00
2025-02-22 11:22:42,478 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:42,479 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:42,479 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:42,479 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:42,479 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:22:42,479 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:42,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:42,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:42,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:42,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:42,482 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:42,482 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:42,482 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:42,482 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:42,493 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:44,306 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:46,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:47,975 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:49,821 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:49,821 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:49,821 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:49,822 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:49,830 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:49.278403+00:00, run_end_date=2025-02-22 11:22:49.425769+00:00, run_duration=0.147366, state=success, executor_state=success, try_number=1, max_tries=1, job_id=625, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:42.479775+00:00, queued_by_job_id=7, pid=62257
2025-02-22 11:22:49,830 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:47.420773+00:00, run_end_date=2025-02-22 11:22:47.579341+00:00, run_duration=0.158568, state=success, executor_state=success, try_number=1, max_tries=1, job_id=624, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:42.479775+00:00, queued_by_job_id=7, pid=62239
2025-02-22 11:22:49,830 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:45.598594+00:00, run_end_date=2025-02-22 11:22:45.749186+00:00, run_duration=0.150592, state=success, executor_state=success, try_number=1, max_tries=1, job_id=623, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:42.479775+00:00, queued_by_job_id=7, pid=62212
2025-02-22 11:22:49,831 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:43.821544+00:00, run_end_date=2025-02-22 11:22:43.972695+00:00, run_duration=0.151151, state=success, executor_state=success, try_number=1, max_tries=1, job_id=622, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:42.479775+00:00, queued_by_job_id=7, pid=62193
2025-02-22 11:22:50,018 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-23T00:00:00+00:00, run_after=2024-07-24T00:00:00+00:00
2025-02-22 11:22:50,086 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-18 00:00:00+00:00: scheduled__2024-07-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:50,087 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-18 00:00:00+00:00, run_id=scheduled__2024-07-18T00:00:00+00:00, run_start_date=2025-02-22 11:22:30.163462+00:00, run_end_date=2025-02-22 11:22:50.087087+00:00, run_duration=19.923625, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-18 00:00:00+00:00, data_interval_end=2024-07-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:50,090 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-19T00:00:00+00:00, run_after=2024-07-20T00:00:00+00:00
2025-02-22 11:22:50,112 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:50,112 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:50,112 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:50,112 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:50,112 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:22:50,112 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:50,114 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:22:50,114 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:50,115 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:50,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:50,115 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:50,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:50,115 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:50,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:50,281 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:52,540 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:54,368 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:56,184 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:58,030 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:58,031 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:58,031 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:58,031 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:22:58,039 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:57.489693+00:00, run_end_date=2025-02-22 11:22:57.647026+00:00, run_duration=0.157333, state=success, executor_state=success, try_number=1, max_tries=1, job_id=629, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:50.113016+00:00, queued_by_job_id=7, pid=62333
2025-02-22 11:22:58,039 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:55.716282+00:00, run_end_date=2025-02-22 11:22:55.862518+00:00, run_duration=0.146236, state=success, executor_state=success, try_number=1, max_tries=1, job_id=628, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:50.113016+00:00, queued_by_job_id=7, pid=62315
2025-02-22 11:22:58,039 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:53.902949+00:00, run_end_date=2025-02-22 11:22:54.054542+00:00, run_duration=0.151593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=627, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:50.113016+00:00, queued_by_job_id=7, pid=62296
2025-02-22 11:22:58,039 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:51.880859+00:00, run_end_date=2025-02-22 11:22:52.270609+00:00, run_duration=0.38975, state=success, executor_state=success, try_number=1, max_tries=1, job_id=626, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:22:50.113016+00:00, queued_by_job_id=7, pid=62277
2025-02-22 11:22:58,203 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-20T00:00:00+00:00, run_after=2024-07-21T00:00:00+00:00
2025-02-22 11:22:58,273 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-19 00:00:00+00:00: scheduled__2024-07-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:22:58,274 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-19 00:00:00+00:00, run_id=scheduled__2024-07-19T00:00:00+00:00, run_start_date=2025-02-22 11:22:32.306585+00:00, run_end_date=2025-02-22 11:22:58.274047+00:00, run_duration=25.967462, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-19 00:00:00+00:00, data_interval_end=2024-07-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:22:58,278 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-20T00:00:00+00:00, run_after=2024-07-21T00:00:00+00:00
2025-02-22 11:22:58,306 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:58,307 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:22:58,307 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:22:58,307 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:22:58,307 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:22:58,311 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:22:58,311 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:58,311 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:22:58,311 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:58,312 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:22:58,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:22:58,326 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:00,456 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:02,221 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:04,012 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:04,013 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:04,013 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:04,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:03.558194+00:00, run_end_date=2025-02-22 11:23:03.706523+00:00, run_duration=0.148329, state=success, executor_state=success, try_number=1, max_tries=1, job_id=632, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:22:58.308153+00:00, queued_by_job_id=7, pid=62400
2025-02-22 11:23:04,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:01.744484+00:00, run_end_date=2025-02-22 11:23:01.890202+00:00, run_duration=0.145718, state=success, executor_state=success, try_number=1, max_tries=1, job_id=631, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:22:58.308153+00:00, queued_by_job_id=7, pid=62380
2025-02-22 11:23:04,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:22:59.672891+00:00, run_end_date=2025-02-22 11:23:00.099846+00:00, run_duration=0.426955, state=success, executor_state=success, try_number=1, max_tries=1, job_id=630, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:22:58.308153+00:00, queued_by_job_id=7, pid=62362
2025-02-22 11:23:04,183 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-21T00:00:00+00:00, run_after=2024-07-22T00:00:00+00:00
2025-02-22 11:23:04,240 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-20 00:00:00+00:00: scheduled__2024-07-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:04,241 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-20 00:00:00+00:00, run_id=scheduled__2024-07-20T00:00:00+00:00, run_start_date=2025-02-22 11:22:36.357484+00:00, run_end_date=2025-02-22 11:23:04.241201+00:00, run_duration=27.883717, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-20 00:00:00+00:00, data_interval_end=2024-07-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:04,246 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-21T00:00:00+00:00, run_after=2024-07-22T00:00:00+00:00
2025-02-22 11:23:04,274 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:04,274 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:04,275 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:04,275 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:04,278 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:04,278 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:04,279 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:04,279 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:04,292 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:06,097 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:07,842 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:07,842 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:07,850 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:07.393209+00:00, run_end_date=2025-02-22 11:23:07.541414+00:00, run_duration=0.148205, state=success, executor_state=success, try_number=1, max_tries=1, job_id=634, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:04.275845+00:00, queued_by_job_id=7, pid=62438
2025-02-22 11:23:07,851 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:05.624166+00:00, run_end_date=2025-02-22 11:23:05.778752+00:00, run_duration=0.154586, state=success, executor_state=success, try_number=1, max_tries=1, job_id=633, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:04.275845+00:00, queued_by_job_id=7, pid=62419
2025-02-22 11:23:07,987 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-22T00:00:00+00:00, run_after=2024-07-23T00:00:00+00:00
2025-02-22 11:23:08,071 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-21 00:00:00+00:00: scheduled__2024-07-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:08,071 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-21 00:00:00+00:00, run_id=scheduled__2024-07-21T00:00:00+00:00, run_start_date=2025-02-22 11:22:42.390285+00:00, run_end_date=2025-02-22 11:23:08.071932+00:00, run_duration=25.681647, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-21 00:00:00+00:00, data_interval_end=2024-07-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:08,075 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-22T00:00:00+00:00, run_after=2024-07-23T00:00:00+00:00
2025-02-22 11:23:08,095 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:08,096 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:08,096 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:08,098 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:08,098 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:08,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:09,941 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:09,949 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:09.461093+00:00, run_end_date=2025-02-22 11:23:09.617030+00:00, run_duration=0.155937, state=success, executor_state=success, try_number=1, max_tries=1, job_id=635, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:08.096730+00:00, queued_by_job_id=7, pid=62458
2025-02-22 11:23:10,113 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-23T00:00:00+00:00, run_after=2024-07-24T00:00:00+00:00
2025-02-22 11:23:10,152 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-22 00:00:00+00:00: scheduled__2024-07-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:10,152 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-22 00:00:00+00:00, run_id=scheduled__2024-07-22T00:00:00+00:00, run_start_date=2025-02-22 11:22:50.044205+00:00, run_end_date=2025-02-22 11:23:10.152446+00:00, run_duration=20.108241, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-22 00:00:00+00:00, data_interval_end=2024-07-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:10,158 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-23T00:00:00+00:00, run_after=2024-07-24T00:00:00+00:00
2025-02-22 11:23:11,332 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-24T00:00:00+00:00, run_after=2024-07-25T00:00:00+00:00
2025-02-22 11:23:11,398 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:11,398 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:11,398 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:11,400 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:11,400 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:11,412 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:13,371 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:13,383 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:12.796719+00:00, run_end_date=2025-02-22 11:23:12.955589+00:00, run_duration=0.15887, state=success, executor_state=success, try_number=1, max_tries=1, job_id=636, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:11.398989+00:00, queued_by_job_id=7, pid=62489
2025-02-22 11:23:13,534 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-25T00:00:00+00:00, run_after=2024-07-26T00:00:00+00:00
2025-02-22 11:23:13,606 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:13,606 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:13,606 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:13,606 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:13,607 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:13,608 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:13,608 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:13,608 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:13,620 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:15,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:17,295 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:17,296 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:17,304 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:16.795416+00:00, run_end_date=2025-02-22 11:23:16.963776+00:00, run_duration=0.16836, state=success, executor_state=success, try_number=1, max_tries=1, job_id=638, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:13.606878+00:00, queued_by_job_id=7, pid=62527
2025-02-22 11:23:17,305 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:14.933029+00:00, run_end_date=2025-02-22 11:23:15.079678+00:00, run_duration=0.146649, state=success, executor_state=success, try_number=1, max_tries=1, job_id=637, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:13.606878+00:00, queued_by_job_id=7, pid=62509
2025-02-22 11:23:17,592 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-26T00:00:00+00:00, run_after=2024-07-27T00:00:00+00:00
2025-02-22 11:23:17,670 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:17,670 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:17,670 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:17,670 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:23:17,670 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:17,672 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:17,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:17,672 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:17,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:17,673 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:17,673 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:17,683 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:19,523 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:21,358 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:23,125 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:23,126 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:23,126 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:23,134 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:22.648057+00:00, run_end_date=2025-02-22 11:23:22.800452+00:00, run_duration=0.152395, state=success, executor_state=success, try_number=1, max_tries=1, job_id=641, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:17.670830+00:00, queued_by_job_id=7, pid=62585
2025-02-22 11:23:23,135 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:20.837944+00:00, run_end_date=2025-02-22 11:23:21.006506+00:00, run_duration=0.168562, state=success, executor_state=success, try_number=1, max_tries=1, job_id=640, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:17.670830+00:00, queued_by_job_id=7, pid=62566
2025-02-22 11:23:23,135 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:19.013750+00:00, run_end_date=2025-02-22 11:23:19.200518+00:00, run_duration=0.186768, state=success, executor_state=success, try_number=1, max_tries=1, job_id=639, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:17.670830+00:00, queued_by_job_id=7, pid=62548
2025-02-22 11:23:23,336 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-27T00:00:00+00:00, run_after=2024-07-28T00:00:00+00:00
2025-02-22 11:23:23,431 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:23,432 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:23,432 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:23,432 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:23:23,432 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:23:23,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:23,434 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:23,434 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:23,434 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:23,434 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:23,435 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:23,435 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:23,435 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:23,435 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:23,453 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:25,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:27,067 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:29,117 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:30,966 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:30,967 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:30,967 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:30,967 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:30,977 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:30.464546+00:00, run_end_date=2025-02-22 11:23:30.646598+00:00, run_duration=0.182052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=645, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:23.432905+00:00, queued_by_job_id=7, pid=62670
2025-02-22 11:23:30,977 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:28.465797+00:00, run_end_date=2025-02-22 11:23:28.765070+00:00, run_duration=0.299273, state=success, executor_state=success, try_number=1, max_tries=1, job_id=644, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:23.432905+00:00, queued_by_job_id=7, pid=62650
2025-02-22 11:23:30,978 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:26.582437+00:00, run_end_date=2025-02-22 11:23:26.727387+00:00, run_duration=0.14495, state=success, executor_state=success, try_number=1, max_tries=1, job_id=643, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:23.432905+00:00, queued_by_job_id=7, pid=62632
2025-02-22 11:23:30,978 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:24.786805+00:00, run_end_date=2025-02-22 11:23:24.933451+00:00, run_duration=0.146646, state=success, executor_state=success, try_number=1, max_tries=1, job_id=642, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:23.432905+00:00, queued_by_job_id=7, pid=62613
2025-02-22 11:23:31,144 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-28T00:00:00+00:00, run_after=2024-07-29T00:00:00+00:00
2025-02-22 11:23:31,205 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-23 00:00:00+00:00: scheduled__2024-07-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:31,205 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-23 00:00:00+00:00, run_id=scheduled__2024-07-23T00:00:00+00:00, run_start_date=2025-02-22 11:23:11.355626+00:00, run_end_date=2025-02-22 11:23:31.205394+00:00, run_duration=19.849768, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-23 00:00:00+00:00, data_interval_end=2024-07-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:31,208 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-24T00:00:00+00:00, run_after=2024-07-25T00:00:00+00:00
2025-02-22 11:23:31,228 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:31,228 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:31,228 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:31,229 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:23:31,229 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:23:31,229 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:31,231 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:31,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:31,231 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:31,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:31,231 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:31,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:31,231 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:31,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:31,247 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:33,227 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:35,250 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:37,084 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:38,850 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:38,851 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:38,851 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:38,851 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:38,860 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:38.383862+00:00, run_end_date=2025-02-22 11:23:38.528394+00:00, run_duration=0.144532, state=success, executor_state=success, try_number=1, max_tries=1, job_id=649, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:31.229535+00:00, queued_by_job_id=7, pid=62754
2025-02-22 11:23:38,860 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:36.556903+00:00, run_end_date=2025-02-22 11:23:36.738268+00:00, run_duration=0.181365, state=success, executor_state=success, try_number=1, max_tries=1, job_id=648, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:31.229535+00:00, queued_by_job_id=7, pid=62735
2025-02-22 11:23:38,860 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:34.709800+00:00, run_end_date=2025-02-22 11:23:34.902583+00:00, run_duration=0.192783, state=success, executor_state=success, try_number=1, max_tries=1, job_id=647, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:31.229535+00:00, queued_by_job_id=7, pid=62717
2025-02-22 11:23:38,861 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:32.554434+00:00, run_end_date=2025-02-22 11:23:32.731377+00:00, run_duration=0.176943, state=success, executor_state=success, try_number=1, max_tries=1, job_id=646, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:31.229535+00:00, queued_by_job_id=7, pid=62690
2025-02-22 11:23:39,025 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-25T00:00:00+00:00, run_after=2024-07-26T00:00:00+00:00
2025-02-22 11:23:39,090 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-24 00:00:00+00:00: scheduled__2024-07-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:39,091 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-24 00:00:00+00:00, run_id=scheduled__2024-07-24T00:00:00+00:00, run_start_date=2025-02-22 11:23:13.558410+00:00, run_end_date=2025-02-22 11:23:39.091135+00:00, run_duration=25.532725, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-24 00:00:00+00:00, data_interval_end=2024-07-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:39,095 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-25T00:00:00+00:00, run_after=2024-07-26T00:00:00+00:00
2025-02-22 11:23:39,122 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:39,122 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:39,123 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:39,123 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:23:39,123 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:39,126 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:39,126 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:39,126 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:39,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:39,127 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:39,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:39,143 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:40,953 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:42,832 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:44,773 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:44,774 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:44,774 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:44,788 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:44.245257+00:00, run_end_date=2025-02-22 11:23:44.418833+00:00, run_duration=0.173576, state=success, executor_state=success, try_number=1, max_tries=1, job_id=652, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:39.123813+00:00, queued_by_job_id=7, pid=62820
2025-02-22 11:23:44,788 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:42.334829+00:00, run_end_date=2025-02-22 11:23:42.477335+00:00, run_duration=0.142506, state=success, executor_state=success, try_number=1, max_tries=1, job_id=651, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:39.123813+00:00, queued_by_job_id=7, pid=62793
2025-02-22 11:23:44,789 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:40.484432+00:00, run_end_date=2025-02-22 11:23:40.664276+00:00, run_duration=0.179844, state=success, executor_state=success, try_number=1, max_tries=1, job_id=650, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:39.123813+00:00, queued_by_job_id=7, pid=62774
2025-02-22 11:23:45,168 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-26T00:00:00+00:00, run_after=2024-07-27T00:00:00+00:00
2025-02-22 11:23:45,279 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-25 00:00:00+00:00: scheduled__2024-07-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:45,280 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-25 00:00:00+00:00, run_id=scheduled__2024-07-25T00:00:00+00:00, run_start_date=2025-02-22 11:23:17.614778+00:00, run_end_date=2025-02-22 11:23:45.280019+00:00, run_duration=27.665241, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-25 00:00:00+00:00, data_interval_end=2024-07-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:45,285 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-26T00:00:00+00:00, run_after=2024-07-27T00:00:00+00:00
2025-02-22 11:23:45,309 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:45,309 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:45,309 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:45,309 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:45,311 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:45,311 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:45,311 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:45,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:45,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:47,104 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:48,863 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:48,864 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:48,872 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:48.405845+00:00, run_end_date=2025-02-22 11:23:48.551699+00:00, run_duration=0.145854, state=success, executor_state=success, try_number=1, max_tries=1, job_id=654, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:45.309880+00:00, queued_by_job_id=7, pid=62861
2025-02-22 11:23:48,872 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:46.625485+00:00, run_end_date=2025-02-22 11:23:46.780468+00:00, run_duration=0.154983, state=success, executor_state=success, try_number=1, max_tries=1, job_id=653, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:45.309880+00:00, queued_by_job_id=7, pid=62840
2025-02-22 11:23:49,012 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-27T00:00:00+00:00, run_after=2024-07-28T00:00:00+00:00
2025-02-22 11:23:49,066 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-26 00:00:00+00:00: scheduled__2024-07-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:49,066 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-26 00:00:00+00:00, run_id=scheduled__2024-07-26T00:00:00+00:00, run_start_date=2025-02-22 11:23:23.361924+00:00, run_end_date=2025-02-22 11:23:49.066609+00:00, run_duration=25.704685, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-26 00:00:00+00:00, data_interval_end=2024-07-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:49,072 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-27T00:00:00+00:00, run_after=2024-07-28T00:00:00+00:00
2025-02-22 11:23:49,102 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:49,102 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:49,103 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:49,106 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:23:49,106 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:49,121 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:50,910 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:50,919 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:50.458945+00:00, run_end_date=2025-02-22 11:23:50.621706+00:00, run_duration=0.162761, state=success, executor_state=success, try_number=1, max_tries=1, job_id=655, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:23:49.103941+00:00, queued_by_job_id=7, pid=62885
2025-02-22 11:23:51,084 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-28T00:00:00+00:00, run_after=2024-07-29T00:00:00+00:00
2025-02-22 11:23:51,126 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-27 00:00:00+00:00: scheduled__2024-07-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:23:51,126 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-27 00:00:00+00:00, run_id=scheduled__2024-07-27T00:00:00+00:00, run_start_date=2025-02-22 11:23:31.166573+00:00, run_end_date=2025-02-22 11:23:51.126468+00:00, run_duration=19.959895, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-27 00:00:00+00:00, data_interval_end=2024-07-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:23:51,132 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-28T00:00:00+00:00, run_after=2024-07-29T00:00:00+00:00
2025-02-22 11:23:52,607 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-29T00:00:00+00:00, run_after=2024-07-30T00:00:00+00:00
2025-02-22 11:23:52,683 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:52,683 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:52,683 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:52,685 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:52,685 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:52,697 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:54,509 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:54,517 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:54.039644+00:00, run_end_date=2025-02-22 11:23:54.189440+00:00, run_duration=0.149796, state=success, executor_state=success, try_number=1, max_tries=1, job_id=656, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:52.683843+00:00, queued_by_job_id=7, pid=62907
2025-02-22 11:23:54,683 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-30T00:00:00+00:00, run_after=2024-07-31T00:00:00+00:00
2025-02-22 11:23:54,756 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:54,756 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:54,756 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:54,756 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:54,758 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:54,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:54,758 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:54,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:54,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:57,242 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:59,131 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:59,132 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:23:59,140 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:58.594143+00:00, run_end_date=2025-02-22 11:23:58.746796+00:00, run_duration=0.152653, state=success, executor_state=success, try_number=1, max_tries=1, job_id=658, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:54.757031+00:00, queued_by_job_id=7, pid=62958
2025-02-22 11:23:59,140 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:23:56.424087+00:00, run_end_date=2025-02-22 11:23:56.874814+00:00, run_duration=0.450727, state=success, executor_state=success, try_number=1, max_tries=1, job_id=657, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:54.757031+00:00, queued_by_job_id=7, pid=62940
2025-02-22 11:23:59,311 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-31T00:00:00+00:00, run_after=2024-08-01T00:00:00+00:00
2025-02-22 11:23:59,473 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:59,473 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:23:59,473 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:23:59,473 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:23:59,474 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:23:59,477 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:23:59,478 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:59,478 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:23:59,478 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:59,479 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:23:59,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:23:59,513 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:01,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:03,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:05,199 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:05,199 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:05,199 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:05,207 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:04.710573+00:00, run_end_date=2025-02-22 11:24:04.857263+00:00, run_duration=0.14669, state=success, executor_state=success, try_number=1, max_tries=1, job_id=661, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:23:59.474847+00:00, queued_by_job_id=7, pid=63017
2025-02-22 11:24:05,207 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:02.664127+00:00, run_end_date=2025-02-22 11:24:02.829751+00:00, run_duration=0.165624, state=success, executor_state=success, try_number=1, max_tries=1, job_id=660, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:23:59.474847+00:00, queued_by_job_id=7, pid=62997
2025-02-22 11:24:05,208 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:00.876718+00:00, run_end_date=2025-02-22 11:24:01.025374+00:00, run_duration=0.148656, state=success, executor_state=success, try_number=1, max_tries=1, job_id=659, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:23:59.474847+00:00, queued_by_job_id=7, pid=62979
2025-02-22 11:24:05,428 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-01T00:00:00+00:00, run_after=2024-08-02T00:00:00+00:00
2025-02-22 11:24:05,521 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:05,521 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:05,522 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:05,522 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:05,522 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:24:05,522 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:05,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:05,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:05,524 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:05,524 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:05,525 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:05,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:05,525 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:05,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:05,537 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:07,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:09,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:10,996 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:12,749 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-07-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:12,750 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:12,751 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:12,751 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:12,768 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:12.307765+00:00, run_end_date=2025-02-22 11:24:12.455669+00:00, run_duration=0.147904, state=success, executor_state=success, try_number=1, max_tries=1, job_id=665, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:05.522708+00:00, queued_by_job_id=7, pid=63101
2025-02-22 11:24:12,769 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:10.528784+00:00, run_end_date=2025-02-22 11:24:10.682373+00:00, run_duration=0.153589, state=success, executor_state=success, try_number=1, max_tries=1, job_id=664, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:05.522708+00:00, queued_by_job_id=7, pid=63081
2025-02-22 11:24:12,769 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:08.634676+00:00, run_end_date=2025-02-22 11:24:08.785652+00:00, run_duration=0.150976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=663, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:05.522708+00:00, queued_by_job_id=7, pid=63063
2025-02-22 11:24:12,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-07-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:06.855557+00:00, run_end_date=2025-02-22 11:24:07.006037+00:00, run_duration=0.15048, state=success, executor_state=success, try_number=1, max_tries=1, job_id=662, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:05.522708+00:00, queued_by_job_id=7, pid=63044
2025-02-22 11:24:13,127 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-02T00:00:00+00:00, run_after=2024-08-03T00:00:00+00:00
2025-02-22 11:24:13,198 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-28 00:00:00+00:00: scheduled__2024-07-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:13,199 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-28 00:00:00+00:00, run_id=scheduled__2024-07-28T00:00:00+00:00, run_start_date=2025-02-22 11:23:52.634431+00:00, run_end_date=2025-02-22 11:24:13.199175+00:00, run_duration=20.564744, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-28 00:00:00+00:00, data_interval_end=2024-07-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:13,202 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-29T00:00:00+00:00, run_after=2024-07-30T00:00:00+00:00
2025-02-22 11:24:13,241 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:13,241 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:13,242 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:13,242 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:13,242 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:24:13,242 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:13,244 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:13,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:13,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:13,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:13,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:13,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:13,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:13,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:13,287 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:15,231 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:17,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:19,168 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:21,149 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:21,149 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-07-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:21,149 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:21,149 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:21,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:20.632208+00:00, run_end_date=2025-02-22 11:24:20.811732+00:00, run_duration=0.179524, state=success, executor_state=success, try_number=1, max_tries=1, job_id=669, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:13.242863+00:00, queued_by_job_id=7, pid=63185
2025-02-22 11:24:21,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:18.694015+00:00, run_end_date=2025-02-22 11:24:18.849050+00:00, run_duration=0.155035, state=success, executor_state=success, try_number=1, max_tries=1, job_id=668, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:13.242863+00:00, queued_by_job_id=7, pid=63166
2025-02-22 11:24:21,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-07-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:16.599291+00:00, run_end_date=2025-02-22 11:24:16.743296+00:00, run_duration=0.144005, state=success, executor_state=success, try_number=1, max_tries=1, job_id=667, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:13.242863+00:00, queued_by_job_id=7, pid=63148
2025-02-22 11:24:21,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:14.638254+00:00, run_end_date=2025-02-22 11:24:14.864372+00:00, run_duration=0.226118, state=success, executor_state=success, try_number=1, max_tries=1, job_id=666, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:13.242863+00:00, queued_by_job_id=7, pid=63121
2025-02-22 11:24:21,320 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-30T00:00:00+00:00, run_after=2024-07-31T00:00:00+00:00
2025-02-22 11:24:21,385 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-29 00:00:00+00:00: scheduled__2024-07-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:21,386 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-29 00:00:00+00:00, run_id=scheduled__2024-07-29T00:00:00+00:00, run_start_date=2025-02-22 11:23:54.705928+00:00, run_end_date=2025-02-22 11:24:21.386060+00:00, run_duration=26.680132, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-29 00:00:00+00:00, data_interval_end=2024-07-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:21,390 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-30T00:00:00+00:00, run_after=2024-07-31T00:00:00+00:00
2025-02-22 11:24:21,418 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:21,418 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:21,418 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:21,418 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:21,419 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:21,421 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:21,422 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:21,422 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:21,422 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:21,422 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:21,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:21,437 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:23,246 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:25,026 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:26,870 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:26,871 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-07-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:26,871 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:26,879 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:26.410968+00:00, run_end_date=2025-02-22 11:24:26.580651+00:00, run_duration=0.169683, state=success, executor_state=success, try_number=1, max_tries=1, job_id=672, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:21.419544+00:00, queued_by_job_id=7, pid=63251
2025-02-22 11:24:26,879 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-07-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:24.558842+00:00, run_end_date=2025-02-22 11:24:24.705087+00:00, run_duration=0.146245, state=success, executor_state=success, try_number=1, max_tries=1, job_id=671, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:21.419544+00:00, queued_by_job_id=7, pid=63224
2025-02-22 11:24:26,879 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:22.755718+00:00, run_end_date=2025-02-22 11:24:22.906843+00:00, run_duration=0.151125, state=success, executor_state=success, try_number=1, max_tries=1, job_id=670, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:21.419544+00:00, queued_by_job_id=7, pid=63206
2025-02-22 11:24:27,400 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-31T00:00:00+00:00, run_after=2024-08-01T00:00:00+00:00
2025-02-22 11:24:27,464 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-30 00:00:00+00:00: scheduled__2024-07-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:27,465 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-30 00:00:00+00:00, run_id=scheduled__2024-07-30T00:00:00+00:00, run_start_date=2025-02-22 11:23:59.333922+00:00, run_end_date=2025-02-22 11:24:27.465111+00:00, run_duration=28.131189, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-30 00:00:00+00:00, data_interval_end=2024-07-31 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:27,470 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-07-31T00:00:00+00:00, run_after=2024-08-01T00:00:00+00:00
2025-02-22 11:24:27,497 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:27,498 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:27,498 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:27,498 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-07-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:27,501 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:27,502 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:27,502 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:27,502 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:27,516 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:29,359 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:31,153 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:31,153 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-07-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:31,161 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-07-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:30.690497+00:00, run_end_date=2025-02-22 11:24:30.841088+00:00, run_duration=0.150591, state=success, executor_state=success, try_number=1, max_tries=1, job_id=674, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:27.499086+00:00, queued_by_job_id=7, pid=63299
2025-02-22 11:24:31,162 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:28.848092+00:00, run_end_date=2025-02-22 11:24:29.011814+00:00, run_duration=0.163722, state=success, executor_state=success, try_number=1, max_tries=1, job_id=673, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:27.499086+00:00, queued_by_job_id=7, pid=63279
2025-02-22 11:24:31,601 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-01T00:00:00+00:00, run_after=2024-08-02T00:00:00+00:00
2025-02-22 11:24:31,636 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-07-31 00:00:00+00:00: scheduled__2024-07-31T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:31,636 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-07-31 00:00:00+00:00, run_id=scheduled__2024-07-31T00:00:00+00:00, run_start_date=2025-02-22 11:24:05.455013+00:00, run_end_date=2025-02-22 11:24:31.636537+00:00, run_duration=26.181524, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-07-31 00:00:00+00:00, data_interval_end=2024-08-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:31,639 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-01T00:00:00+00:00, run_after=2024-08-02T00:00:00+00:00
2025-02-22 11:24:31,663 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:31,663 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:31,663 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:31,665 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:31,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:31,679 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:33,463 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:33,471 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:33.001575+00:00, run_end_date=2025-02-22 11:24:33.148203+00:00, run_duration=0.146628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=675, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:31.663987+00:00, queued_by_job_id=7, pid=63327
2025-02-22 11:24:33,939 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-03T00:00:00+00:00, run_after=2024-08-04T00:00:00+00:00
2025-02-22 11:24:33,990 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-01 00:00:00+00:00: scheduled__2024-08-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:33,990 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-01 00:00:00+00:00, run_id=scheduled__2024-08-01T00:00:00+00:00, run_start_date=2025-02-22 11:24:13.153117+00:00, run_end_date=2025-02-22 11:24:33.990677+00:00, run_duration=20.83756, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-01 00:00:00+00:00, data_interval_end=2024-08-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:33,993 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-02T00:00:00+00:00, run_after=2024-08-03T00:00:00+00:00
2025-02-22 11:24:34,013 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:34,013 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:34,013 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:34,014 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:34,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:34,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:35,847 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:35,855 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:35.368349+00:00, run_end_date=2025-02-22 11:24:35.519178+00:00, run_duration=0.150829, state=success, executor_state=success, try_number=1, max_tries=1, job_id=676, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:34.013778+00:00, queued_by_job_id=7, pid=63355
2025-02-22 11:24:35,994 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-03T00:00:00+00:00, run_after=2024-08-04T00:00:00+00:00
2025-02-22 11:24:36,081 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:36,082 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:36,082 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:36,085 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:36,085 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:36,145 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:38,014 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:38,022 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:37.491815+00:00, run_end_date=2025-02-22 11:24:37.700059+00:00, run_duration=0.208244, state=success, executor_state=success, try_number=1, max_tries=1, job_id=677, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:36.083063+00:00, queued_by_job_id=7, pid=63384
2025-02-22 11:24:38,269 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-04T00:00:00+00:00, run_after=2024-08-05T00:00:00+00:00
2025-02-22 11:24:38,376 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:38,376 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:38,376 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:38,376 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:38,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:38,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:38,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:38,379 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:38,392 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:40,309 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:42,097 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:42,098 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:42,112 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:41.622137+00:00, run_end_date=2025-02-22 11:24:41.775019+00:00, run_duration=0.152882, state=success, executor_state=success, try_number=1, max_tries=1, job_id=679, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:38.377023+00:00, queued_by_job_id=7, pid=63422
2025-02-22 11:24:42,112 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:39.830012+00:00, run_end_date=2025-02-22 11:24:40.003219+00:00, run_duration=0.173207, state=success, executor_state=success, try_number=1, max_tries=1, job_id=678, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:38.377023+00:00, queued_by_job_id=7, pid=63404
2025-02-22 11:24:42,286 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-05T00:00:00+00:00, run_after=2024-08-06T00:00:00+00:00
2025-02-22 11:24:42,370 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:42,370 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:42,370 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:42,371 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:42,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:42,372 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:42,373 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:42,373 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:42,373 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:42,373 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:42,373 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:42,386 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:44,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:46,054 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:47,889 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:47,890 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:47,890 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:47,897 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:47.404562+00:00, run_end_date=2025-02-22 11:24:47.559385+00:00, run_duration=0.154823, state=success, executor_state=success, try_number=1, max_tries=1, job_id=682, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:42.371431+00:00, queued_by_job_id=7, pid=63488
2025-02-22 11:24:47,898 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:45.568314+00:00, run_end_date=2025-02-22 11:24:45.723762+00:00, run_duration=0.155448, state=success, executor_state=success, try_number=1, max_tries=1, job_id=681, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:42.371431+00:00, queued_by_job_id=7, pid=63461
2025-02-22 11:24:47,898 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:43.747951+00:00, run_end_date=2025-02-22 11:24:43.905317+00:00, run_duration=0.157366, state=success, executor_state=success, try_number=1, max_tries=1, job_id=680, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:42.371431+00:00, queued_by_job_id=7, pid=63443
2025-02-22 11:24:48,070 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-06T00:00:00+00:00, run_after=2024-08-07T00:00:00+00:00
2025-02-22 11:24:48,136 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-02 00:00:00+00:00: scheduled__2024-08-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:24:48,137 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-02 00:00:00+00:00, run_id=scheduled__2024-08-02T00:00:00+00:00, run_start_date=2025-02-22 11:24:33.964188+00:00, run_end_date=2025-02-22 11:24:48.137049+00:00, run_duration=14.172861, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-02 00:00:00+00:00, data_interval_end=2024-08-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:24:48,140 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-03T00:00:00+00:00, run_after=2024-08-04T00:00:00+00:00
2025-02-22 11:24:48,191 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:48,192 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:48,192 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:48,192 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:48,192 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:48,195 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:24:48,195 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:48,196 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:48,196 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:48,196 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:48,196 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:48,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:50,395 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:52,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:54,178 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:54,178 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:54,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:24:54,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:53.650779+00:00, run_end_date=2025-02-22 11:24:53.831631+00:00, run_duration=0.180852, state=success, executor_state=success, try_number=1, max_tries=1, job_id=685, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:48.193271+00:00, queued_by_job_id=7, pid=63546
2025-02-22 11:24:54,187 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:51.752860+00:00, run_end_date=2025-02-22 11:24:51.961363+00:00, run_duration=0.208503, state=success, executor_state=success, try_number=1, max_tries=1, job_id=684, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:48.193271+00:00, queued_by_job_id=7, pid=63527
2025-02-22 11:24:54,187 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:49.806507+00:00, run_end_date=2025-02-22 11:24:49.960453+00:00, run_duration=0.153946, state=success, executor_state=success, try_number=1, max_tries=1, job_id=683, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:24:48.193271+00:00, queued_by_job_id=7, pid=63508
2025-02-22 11:24:54,473 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-04T00:00:00+00:00, run_after=2024-08-05T00:00:00+00:00
2025-02-22 11:24:54,566 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:54,567 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:24:54,567 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:24:54,567 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:24:54,567 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:24:54,571 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:24:54,571 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:54,571 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:24:54,572 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:54,572 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:24:54,572 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:54,633 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:56,432 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:24:58,338 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:00,119 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:00,120 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:00,120 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:00,128 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:59.654522+00:00, run_end_date=2025-02-22 11:24:59.799450+00:00, run_duration=0.144928, state=success, executor_state=success, try_number=1, max_tries=1, job_id=688, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:24:54.568210+00:00, queued_by_job_id=7, pid=63612
2025-02-22 11:25:00,128 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:57.824465+00:00, run_end_date=2025-02-22 11:24:57.968639+00:00, run_duration=0.144174, state=success, executor_state=success, try_number=1, max_tries=1, job_id=687, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:24:54.568210+00:00, queued_by_job_id=7, pid=63593
2025-02-22 11:25:00,128 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:24:55.961108+00:00, run_end_date=2025-02-22 11:24:56.124601+00:00, run_duration=0.163493, state=success, executor_state=success, try_number=1, max_tries=1, job_id=686, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:24:54.568210+00:00, queued_by_job_id=7, pid=63566
2025-02-22 11:25:00,408 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-05T00:00:00+00:00, run_after=2024-08-06T00:00:00+00:00
2025-02-22 11:25:00,472 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-03 00:00:00+00:00: scheduled__2024-08-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:00,472 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-03 00:00:00+00:00, run_id=scheduled__2024-08-03T00:00:00+00:00, run_start_date=2025-02-22 11:24:38.320904+00:00, run_end_date=2025-02-22 11:25:00.472728+00:00, run_duration=22.151824, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-03 00:00:00+00:00, data_interval_end=2024-08-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:00,478 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-04T00:00:00+00:00, run_after=2024-08-05T00:00:00+00:00
2025-02-22 11:25:00,502 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:00,502 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:00,502 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:00,502 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:00,504 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:00,504 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:00,504 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:00,505 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:00,517 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:02,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:04,466 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:04,467 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:04,475 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:03.894179+00:00, run_end_date=2025-02-22 11:25:04.131440+00:00, run_duration=0.237261, state=success, executor_state=success, try_number=1, max_tries=1, job_id=690, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:00.502903+00:00, queued_by_job_id=7, pid=63651
2025-02-22 11:25:04,475 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:02.066581+00:00, run_end_date=2025-02-22 11:25:02.221949+00:00, run_duration=0.155368, state=success, executor_state=success, try_number=1, max_tries=1, job_id=689, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:00.502903+00:00, queued_by_job_id=7, pid=63632
2025-02-22 11:25:04,612 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-05T00:00:00+00:00, run_after=2024-08-06T00:00:00+00:00
2025-02-22 11:25:04,660 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-04 00:00:00+00:00: scheduled__2024-08-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:04,660 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-04 00:00:00+00:00, run_id=scheduled__2024-08-04T00:00:00+00:00, run_start_date=2025-02-22 11:24:42.313786+00:00, run_end_date=2025-02-22 11:25:04.660675+00:00, run_duration=22.346889, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-04 00:00:00+00:00, data_interval_end=2024-08-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:04,666 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-05T00:00:00+00:00, run_after=2024-08-06T00:00:00+00:00
2025-02-22 11:25:04,693 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:04,693 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:04,693 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:04,696 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:04,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:04,710 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:06,482 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:06,489 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:06.032106+00:00, run_end_date=2025-02-22 11:25:06.183175+00:00, run_duration=0.151069, state=success, executor_state=success, try_number=1, max_tries=1, job_id=691, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:04.694546+00:00, queued_by_job_id=7, pid=63671
2025-02-22 11:25:06,651 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-06T00:00:00+00:00, run_after=2024-08-07T00:00:00+00:00
2025-02-22 11:25:06,695 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-05 00:00:00+00:00: scheduled__2024-08-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:06,696 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-05 00:00:00+00:00, run_id=scheduled__2024-08-05T00:00:00+00:00, run_start_date=2025-02-22 11:24:48.096142+00:00, run_end_date=2025-02-22 11:25:06.696238+00:00, run_duration=18.600096, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-05 00:00:00+00:00, data_interval_end=2024-08-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:06,704 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-06T00:00:00+00:00, run_after=2024-08-07T00:00:00+00:00
2025-02-22 11:25:08,114 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-07T00:00:00+00:00, run_after=2024-08-08T00:00:00+00:00
2025-02-22 11:25:08,177 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:08,177 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:08,177 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:08,178 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:08,179 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:08,191 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:10,162 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:10,169 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:09.689730+00:00, run_end_date=2025-02-22 11:25:09.842610+00:00, run_duration=0.15288, state=success, executor_state=success, try_number=1, max_tries=1, job_id=692, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:08.178144+00:00, queued_by_job_id=7, pid=63702
2025-02-22 11:25:10,319 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-08T00:00:00+00:00, run_after=2024-08-09T00:00:00+00:00
2025-02-22 11:25:10,395 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:10,395 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:10,395 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:10,396 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:10,398 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:10,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:10,398 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:10,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:10,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:12,154 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:13,947 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:13,947 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:13,955 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:13.470164+00:00, run_end_date=2025-02-22 11:25:13.624662+00:00, run_duration=0.154498, state=success, executor_state=success, try_number=1, max_tries=1, job_id=694, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:10.396424+00:00, queued_by_job_id=7, pid=63740
2025-02-22 11:25:13,956 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:11.713932+00:00, run_end_date=2025-02-22 11:25:11.886192+00:00, run_duration=0.17226, state=success, executor_state=success, try_number=1, max_tries=1, job_id=693, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:10.396424+00:00, queued_by_job_id=7, pid=63721
2025-02-22 11:25:14,121 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-09T00:00:00+00:00, run_after=2024-08-10T00:00:00+00:00
2025-02-22 11:25:14,205 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:14,206 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:14,206 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:14,206 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:25:14,206 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:14,208 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:14,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:14,208 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:14,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:14,208 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:14,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:14,228 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:16,124 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:18,083 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:19,909 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:19,909 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:19,909 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:19,915 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:19.430333+00:00, run_end_date=2025-02-22 11:25:19.581575+00:00, run_duration=0.151242, state=success, executor_state=success, try_number=1, max_tries=1, job_id=697, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:14.206715+00:00, queued_by_job_id=7, pid=63807
2025-02-22 11:25:19,915 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:17.491583+00:00, run_end_date=2025-02-22 11:25:17.695431+00:00, run_duration=0.203848, state=success, executor_state=success, try_number=1, max_tries=1, job_id=696, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:14.206715+00:00, queued_by_job_id=7, pid=63780
2025-02-22 11:25:19,915 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:15.543268+00:00, run_end_date=2025-02-22 11:25:15.776735+00:00, run_duration=0.233467, state=success, executor_state=success, try_number=1, max_tries=1, job_id=695, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:14.206715+00:00, queued_by_job_id=7, pid=63760
2025-02-22 11:25:20,081 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-10T00:00:00+00:00, run_after=2024-08-11T00:00:00+00:00
2025-02-22 11:25:20,145 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:20,145 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:20,145 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:20,146 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:25:20,146 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:25:20,146 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:20,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:20,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:20,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:20,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:20,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:20,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:20,148 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:20,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:20,159 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:22,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:23,914 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:25,692 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:27,818 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:27,819 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:27,819 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:27,819 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:27,827 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:27.053138+00:00, run_end_date=2025-02-22 11:25:27.311863+00:00, run_duration=0.258725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=701, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:20.146371+00:00, queued_by_job_id=7, pid=63883
2025-02-22 11:25:27,828 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:25.223860+00:00, run_end_date=2025-02-22 11:25:25.376657+00:00, run_duration=0.152797, state=success, executor_state=success, try_number=1, max_tries=1, job_id=700, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:20.146371+00:00, queued_by_job_id=7, pid=63865
2025-02-22 11:25:27,828 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:23.339898+00:00, run_end_date=2025-02-22 11:25:23.495568+00:00, run_duration=0.15567, state=success, executor_state=success, try_number=1, max_tries=1, job_id=699, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:20.146371+00:00, queued_by_job_id=7, pid=63845
2025-02-22 11:25:27,828 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:21.489578+00:00, run_end_date=2025-02-22 11:25:21.696515+00:00, run_duration=0.206937, state=success, executor_state=success, try_number=1, max_tries=1, job_id=698, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:20.146371+00:00, queued_by_job_id=7, pid=63827
2025-02-22 11:25:28,062 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-11T00:00:00+00:00, run_after=2024-08-12T00:00:00+00:00
2025-02-22 11:25:28,230 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-06 00:00:00+00:00: scheduled__2024-08-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:28,230 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-06 00:00:00+00:00, run_id=scheduled__2024-08-06T00:00:00+00:00, run_start_date=2025-02-22 11:25:08.138508+00:00, run_end_date=2025-02-22 11:25:28.230666+00:00, run_duration=20.092158, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-06 00:00:00+00:00, data_interval_end=2024-08-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:28,235 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-07T00:00:00+00:00, run_after=2024-08-08T00:00:00+00:00
2025-02-22 11:25:28,261 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:28,261 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:28,261 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:28,261 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:25:28,261 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:25:28,261 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:28,263 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:28,264 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:28,264 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:28,264 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:28,264 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:28,264 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:28,264 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:28,264 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:28,279 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:30,370 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:32,309 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:34,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:36,184 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:36,185 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:36,185 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:36,185 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:36,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:35.685447+00:00, run_end_date=2025-02-22 11:25:35.868482+00:00, run_duration=0.183035, state=success, executor_state=success, try_number=1, max_tries=1, job_id=705, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:28.262146+00:00, queued_by_job_id=7, pid=63969
2025-02-22 11:25:36,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:33.719734+00:00, run_end_date=2025-02-22 11:25:33.867512+00:00, run_duration=0.147778, state=success, executor_state=success, try_number=1, max_tries=1, job_id=704, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:28.262146+00:00, queued_by_job_id=7, pid=63950
2025-02-22 11:25:36,199 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:31.706360+00:00, run_end_date=2025-02-22 11:25:31.932127+00:00, run_duration=0.225767, state=success, executor_state=success, try_number=1, max_tries=1, job_id=703, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:28.262146+00:00, queued_by_job_id=7, pid=63931
2025-02-22 11:25:36,199 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:29.752768+00:00, run_end_date=2025-02-22 11:25:30.008902+00:00, run_duration=0.256134, state=success, executor_state=success, try_number=1, max_tries=1, job_id=702, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:28.262146+00:00, queued_by_job_id=7, pid=63912
2025-02-22 11:25:36,384 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-08T00:00:00+00:00, run_after=2024-08-09T00:00:00+00:00
2025-02-22 11:25:36,454 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-07 00:00:00+00:00: scheduled__2024-08-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:36,454 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-07 00:00:00+00:00, run_id=scheduled__2024-08-07T00:00:00+00:00, run_start_date=2025-02-22 11:25:10.344709+00:00, run_end_date=2025-02-22 11:25:36.454548+00:00, run_duration=26.109839, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-07 00:00:00+00:00, data_interval_end=2024-08-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:36,459 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-08T00:00:00+00:00, run_after=2024-08-09T00:00:00+00:00
2025-02-22 11:25:36,487 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:36,487 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:36,487 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:36,487 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:25:36,487 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:36,490 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:36,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:36,491 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:36,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:36,491 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:36,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:36,505 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:38,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:40,365 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:42,177 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:42,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:42,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:42,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:41.659142+00:00, run_end_date=2025-02-22 11:25:41.825844+00:00, run_duration=0.166702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=708, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:36.488494+00:00, queued_by_job_id=7, pid=64034
2025-02-22 11:25:42,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:39.893046+00:00, run_end_date=2025-02-22 11:25:40.050626+00:00, run_duration=0.15758, state=success, executor_state=success, try_number=1, max_tries=1, job_id=707, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:36.488494+00:00, queued_by_job_id=7, pid=64015
2025-02-22 11:25:42,186 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:37.975984+00:00, run_end_date=2025-02-22 11:25:38.231229+00:00, run_duration=0.255245, state=success, executor_state=success, try_number=1, max_tries=1, job_id=706, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:36.488494+00:00, queued_by_job_id=7, pid=63989
2025-02-22 11:25:42,569 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-09T00:00:00+00:00, run_after=2024-08-10T00:00:00+00:00
2025-02-22 11:25:42,627 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-08 00:00:00+00:00: scheduled__2024-08-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:42,628 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-08 00:00:00+00:00, run_id=scheduled__2024-08-08T00:00:00+00:00, run_start_date=2025-02-22 11:25:14.146955+00:00, run_end_date=2025-02-22 11:25:42.628040+00:00, run_duration=28.481085, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-08 00:00:00+00:00, data_interval_end=2024-08-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:42,633 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-09T00:00:00+00:00, run_after=2024-08-10T00:00:00+00:00
2025-02-22 11:25:42,658 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:42,658 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:42,659 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:42,659 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:42,662 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:42,662 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:42,662 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:42,662 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:42,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:44,925 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:46,910 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:46,911 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:46,919 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:46.230565+00:00, run_end_date=2025-02-22 11:25:46.594236+00:00, run_duration=0.363671, state=success, executor_state=success, try_number=1, max_tries=1, job_id=710, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:42.659676+00:00, queued_by_job_id=7, pid=64073
2025-02-22 11:25:46,919 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:44.382870+00:00, run_end_date=2025-02-22 11:25:44.544223+00:00, run_duration=0.161353, state=success, executor_state=success, try_number=1, max_tries=1, job_id=709, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:42.659676+00:00, queued_by_job_id=7, pid=64054
2025-02-22 11:25:47,059 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-10T00:00:00+00:00, run_after=2024-08-11T00:00:00+00:00
2025-02-22 11:25:47,112 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-09 00:00:00+00:00: scheduled__2024-08-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:47,113 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-09 00:00:00+00:00, run_id=scheduled__2024-08-09T00:00:00+00:00, run_start_date=2025-02-22 11:25:20.100977+00:00, run_end_date=2025-02-22 11:25:47.113295+00:00, run_duration=27.012318, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-09 00:00:00+00:00, data_interval_end=2024-08-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:47,119 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-10T00:00:00+00:00, run_after=2024-08-11T00:00:00+00:00
2025-02-22 11:25:47,148 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:47,149 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:47,149 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:47,152 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:25:47,153 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:47,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:48,918 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:48,925 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:48.464101+00:00, run_end_date=2025-02-22 11:25:48.609093+00:00, run_duration=0.144992, state=success, executor_state=success, try_number=1, max_tries=1, job_id=711, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:25:47.150334+00:00, queued_by_job_id=7, pid=64093
2025-02-22 11:25:49,087 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-11T00:00:00+00:00, run_after=2024-08-12T00:00:00+00:00
2025-02-22 11:25:49,132 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-10 00:00:00+00:00: scheduled__2024-08-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:25:49,132 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-10 00:00:00+00:00, run_id=scheduled__2024-08-10T00:00:00+00:00, run_start_date=2025-02-22 11:25:28.136596+00:00, run_end_date=2025-02-22 11:25:49.132563+00:00, run_duration=20.995967, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-10 00:00:00+00:00, data_interval_end=2024-08-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:25:49,138 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-11T00:00:00+00:00, run_after=2024-08-12T00:00:00+00:00
2025-02-22 11:25:50,315 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-12T00:00:00+00:00, run_after=2024-08-13T00:00:00+00:00
2025-02-22 11:25:50,385 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:50,385 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:50,385 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:50,387 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:50,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:50,399 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:52,274 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:52,287 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:51.697650+00:00, run_end_date=2025-02-22 11:25:51.854604+00:00, run_duration=0.156954, state=success, executor_state=success, try_number=1, max_tries=1, job_id=712, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:50.386192+00:00, queued_by_job_id=7, pid=64123
2025-02-22 11:25:52,440 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-13T00:00:00+00:00, run_after=2024-08-14T00:00:00+00:00
2025-02-22 11:25:52,517 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:52,517 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:52,517 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:52,518 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:52,519 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:52,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:52,520 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:52,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:52,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:54,289 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:56,070 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:56,070 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:25:56,076 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:55.591809+00:00, run_end_date=2025-02-22 11:25:55.742292+00:00, run_duration=0.150483, state=success, executor_state=success, try_number=1, max_tries=1, job_id=714, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:52.518402+00:00, queued_by_job_id=7, pid=64162
2025-02-22 11:25:56,076 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:53.823557+00:00, run_end_date=2025-02-22 11:25:53.973008+00:00, run_duration=0.149451, state=success, executor_state=success, try_number=1, max_tries=1, job_id=713, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:52.518402+00:00, queued_by_job_id=7, pid=64143
2025-02-22 11:25:56,248 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-14T00:00:00+00:00, run_after=2024-08-15T00:00:00+00:00
2025-02-22 11:25:56,323 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:56,323 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:25:56,323 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:25:56,323 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:25:56,323 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:25:56,325 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:25:56,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:56,325 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:25:56,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:56,325 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:25:56,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:56,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:58,126 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:25:59,933 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:01,777 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:01,777 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:01,778 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:01,786 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:01.251222+00:00, run_end_date=2025-02-22 11:26:01.428458+00:00, run_duration=0.177236, state=success, executor_state=success, try_number=1, max_tries=1, job_id=717, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:25:56.324125+00:00, queued_by_job_id=7, pid=64228
2025-02-22 11:26:01,786 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:59.428015+00:00, run_end_date=2025-02-22 11:25:59.578192+00:00, run_duration=0.150177, state=success, executor_state=success, try_number=1, max_tries=1, job_id=716, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:25:56.324125+00:00, queued_by_job_id=7, pid=64200
2025-02-22 11:26:01,786 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:25:57.667661+00:00, run_end_date=2025-02-22 11:25:57.832407+00:00, run_duration=0.164746, state=success, executor_state=success, try_number=1, max_tries=1, job_id=715, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:25:56.324125+00:00, queued_by_job_id=7, pid=64182
2025-02-22 11:26:01,955 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-15T00:00:00+00:00, run_after=2024-08-16T00:00:00+00:00
2025-02-22 11:26:02,035 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:02,035 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:02,035 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:02,035 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:02,035 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:26:02,036 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:02,038 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:02,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:02,038 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:02,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:02,038 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:02,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:02,038 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:02,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:02,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:03,848 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:05,623 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:07,370 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:09,093 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:09,093 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:09,094 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:09,094 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:09,102 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:08.654036+00:00, run_end_date=2025-02-22 11:26:08.797338+00:00, run_duration=0.143302, state=success, executor_state=success, try_number=1, max_tries=1, job_id=721, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:02.036406+00:00, queued_by_job_id=7, pid=64304
2025-02-22 11:26:09,103 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:06.921640+00:00, run_end_date=2025-02-22 11:26:07.070343+00:00, run_duration=0.148703, state=success, executor_state=success, try_number=1, max_tries=1, job_id=720, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:02.036406+00:00, queued_by_job_id=7, pid=64285
2025-02-22 11:26:09,103 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:05.136206+00:00, run_end_date=2025-02-22 11:26:05.284878+00:00, run_duration=0.148672, state=success, executor_state=success, try_number=1, max_tries=1, job_id=719, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:02.036406+00:00, queued_by_job_id=7, pid=64266
2025-02-22 11:26:09,103 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:03.366982+00:00, run_end_date=2025-02-22 11:26:03.518039+00:00, run_duration=0.151057, state=success, executor_state=success, try_number=1, max_tries=1, job_id=718, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:02.036406+00:00, queued_by_job_id=7, pid=64248
2025-02-22 11:26:09,281 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-16T00:00:00+00:00, run_after=2024-08-17T00:00:00+00:00
2025-02-22 11:26:09,348 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-11 00:00:00+00:00: scheduled__2024-08-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:09,348 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-11 00:00:00+00:00, run_id=scheduled__2024-08-11T00:00:00+00:00, run_start_date=2025-02-22 11:25:50.337270+00:00, run_end_date=2025-02-22 11:26:09.348796+00:00, run_duration=19.011526, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-11 00:00:00+00:00, data_interval_end=2024-08-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:09,351 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-12T00:00:00+00:00, run_after=2024-08-13T00:00:00+00:00
2025-02-22 11:26:09,374 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:09,375 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:09,375 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:09,375 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:09,375 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:26:09,375 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:09,377 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:09,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:09,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:09,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:09,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:09,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:09,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:09,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:09,392 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:11,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:13,014 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:14,871 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:16,811 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:16,812 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:16,812 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:16,812 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:16,818 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:16.219866+00:00, run_end_date=2025-02-22 11:26:16.365617+00:00, run_duration=0.145751, state=success, executor_state=success, try_number=1, max_tries=1, job_id=725, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:09.375903+00:00, queued_by_job_id=7, pid=64388
2025-02-22 11:26:16,818 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:14.318206+00:00, run_end_date=2025-02-22 11:26:14.462923+00:00, run_duration=0.144717, state=success, executor_state=success, try_number=1, max_tries=1, job_id=724, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:09.375903+00:00, queued_by_job_id=7, pid=64369
2025-02-22 11:26:16,818 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:12.556465+00:00, run_end_date=2025-02-22 11:26:12.704072+00:00, run_duration=0.147607, state=success, executor_state=success, try_number=1, max_tries=1, job_id=723, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:09.375903+00:00, queued_by_job_id=7, pid=64351
2025-02-22 11:26:16,818 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:10.696654+00:00, run_end_date=2025-02-22 11:26:10.850983+00:00, run_duration=0.154329, state=success, executor_state=success, try_number=1, max_tries=1, job_id=722, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:09.375903+00:00, queued_by_job_id=7, pid=64324
2025-02-22 11:26:16,979 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-13T00:00:00+00:00, run_after=2024-08-14T00:00:00+00:00
2025-02-22 11:26:17,049 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-12 00:00:00+00:00: scheduled__2024-08-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:17,049 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-12 00:00:00+00:00, run_id=scheduled__2024-08-12T00:00:00+00:00, run_start_date=2025-02-22 11:25:52.465810+00:00, run_end_date=2025-02-22 11:26:17.049883+00:00, run_duration=24.584073, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-12 00:00:00+00:00, data_interval_end=2024-08-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:17,054 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-13T00:00:00+00:00, run_after=2024-08-14T00:00:00+00:00
2025-02-22 11:26:17,082 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:17,082 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:17,082 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:17,082 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:17,082 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:17,085 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:17,086 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:17,086 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:17,086 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:17,086 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:17,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:17,109 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:18,887 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:20,660 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:22,415 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:22,415 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:22,416 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:22,430 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:21.970901+00:00, run_end_date=2025-02-22 11:26:22.118226+00:00, run_duration=0.147325, state=success, executor_state=success, try_number=1, max_tries=1, job_id=728, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:17.083369+00:00, queued_by_job_id=7, pid=64454
2025-02-22 11:26:22,430 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:20.188095+00:00, run_end_date=2025-02-22 11:26:20.338600+00:00, run_duration=0.150505, state=success, executor_state=success, try_number=1, max_tries=1, job_id=727, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:17.083369+00:00, queued_by_job_id=7, pid=64427
2025-02-22 11:26:22,430 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:18.415321+00:00, run_end_date=2025-02-22 11:26:18.572316+00:00, run_duration=0.156995, state=success, executor_state=success, try_number=1, max_tries=1, job_id=726, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:17.083369+00:00, queued_by_job_id=7, pid=64409
2025-02-22 11:26:22,598 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-14T00:00:00+00:00, run_after=2024-08-15T00:00:00+00:00
2025-02-22 11:26:22,662 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-13 00:00:00+00:00: scheduled__2024-08-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:22,662 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-13 00:00:00+00:00, run_id=scheduled__2024-08-13T00:00:00+00:00, run_start_date=2025-02-22 11:25:56.274457+00:00, run_end_date=2025-02-22 11:26:22.662478+00:00, run_duration=26.388021, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-13 00:00:00+00:00, data_interval_end=2024-08-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:22,667 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-14T00:00:00+00:00, run_after=2024-08-15T00:00:00+00:00
2025-02-22 11:26:22,695 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:22,695 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:22,695 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:22,696 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:22,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:22,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:22,699 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:22,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:22,712 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:24,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:26,247 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:26,248 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:26,262 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:25.779811+00:00, run_end_date=2025-02-22 11:26:25.930977+00:00, run_duration=0.151166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=730, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:22.696646+00:00, queued_by_job_id=7, pid=64492
2025-02-22 11:26:26,262 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:24.028534+00:00, run_end_date=2025-02-22 11:26:24.177099+00:00, run_duration=0.148565, state=success, executor_state=success, try_number=1, max_tries=1, job_id=729, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:22.696646+00:00, queued_by_job_id=7, pid=64473
2025-02-22 11:26:26,408 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-15T00:00:00+00:00, run_after=2024-08-16T00:00:00+00:00
2025-02-22 11:26:26,464 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-14 00:00:00+00:00: scheduled__2024-08-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:26,465 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-14 00:00:00+00:00, run_id=scheduled__2024-08-14T00:00:00+00:00, run_start_date=2025-02-22 11:26:01.978248+00:00, run_end_date=2025-02-22 11:26:26.465138+00:00, run_duration=24.48689, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-14 00:00:00+00:00, data_interval_end=2024-08-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:26,470 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-15T00:00:00+00:00, run_after=2024-08-16T00:00:00+00:00
2025-02-22 11:26:26,493 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:26,494 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:26,494 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:26,495 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:26,496 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:26,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:28,503 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:28,511 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:27.813204+00:00, run_end_date=2025-02-22 11:26:28.149524+00:00, run_duration=0.33632, state=success, executor_state=success, try_number=1, max_tries=1, job_id=731, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:26.494649+00:00, queued_by_job_id=7, pid=64512
2025-02-22 11:26:28,683 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-16T00:00:00+00:00, run_after=2024-08-17T00:00:00+00:00
2025-02-22 11:26:28,727 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-15 00:00:00+00:00: scheduled__2024-08-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:28,727 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-15 00:00:00+00:00, run_id=scheduled__2024-08-15T00:00:00+00:00, run_start_date=2025-02-22 11:26:09.306739+00:00, run_end_date=2025-02-22 11:26:28.727763+00:00, run_duration=19.421024, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-15 00:00:00+00:00, data_interval_end=2024-08-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:28,734 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-16T00:00:00+00:00, run_after=2024-08-17T00:00:00+00:00
2025-02-22 11:26:29,909 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-17T00:00:00+00:00, run_after=2024-08-18T00:00:00+00:00
2025-02-22 11:26:29,988 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:29,988 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:29,989 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:29,991 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:29,992 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:30,004 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:31,762 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:31,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:31.285962+00:00, run_end_date=2025-02-22 11:26:31.441874+00:00, run_duration=0.155912, state=success, executor_state=success, try_number=1, max_tries=1, job_id=732, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:29.989916+00:00, queued_by_job_id=7, pid=64534
2025-02-22 11:26:31,919 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-18T00:00:00+00:00, run_after=2024-08-19T00:00:00+00:00
2025-02-22 11:26:31,990 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:31,991 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:31,991 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:31,991 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:31,993 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:31,993 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:31,993 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:31,993 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:32,009 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:33,809 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:35,567 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:35,568 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:35,576 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:35.098856+00:00, run_end_date=2025-02-22 11:26:35.252246+00:00, run_duration=0.15339, state=success, executor_state=success, try_number=1, max_tries=1, job_id=734, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:31.991670+00:00, queued_by_job_id=7, pid=64581
2025-02-22 11:26:35,576 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:33.305774+00:00, run_end_date=2025-02-22 11:26:33.455247+00:00, run_duration=0.149473, state=success, executor_state=success, try_number=1, max_tries=1, job_id=733, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:31.991670+00:00, queued_by_job_id=7, pid=64562
2025-02-22 11:26:35,748 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-19T00:00:00+00:00, run_after=2024-08-20T00:00:00+00:00
2025-02-22 11:26:35,826 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:35,826 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:35,827 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:35,827 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:35,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:35,829 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:35,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:35,829 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:35,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:35,829 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:35,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:35,843 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:37,613 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:39,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:41,236 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:41,237 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:41,237 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:41,251 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:40.770033+00:00, run_end_date=2025-02-22 11:26:40.921057+00:00, run_duration=0.151024, state=success, executor_state=success, try_number=1, max_tries=1, job_id=737, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:35.827620+00:00, queued_by_job_id=7, pid=64639
2025-02-22 11:26:41,252 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:38.901522+00:00, run_end_date=2025-02-22 11:26:39.057975+00:00, run_duration=0.156453, state=success, executor_state=success, try_number=1, max_tries=1, job_id=736, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:35.827620+00:00, queued_by_job_id=7, pid=64619
2025-02-22 11:26:41,252 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:37.144863+00:00, run_end_date=2025-02-22 11:26:37.295471+00:00, run_duration=0.150608, state=success, executor_state=success, try_number=1, max_tries=1, job_id=735, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:35.827620+00:00, queued_by_job_id=7, pid=64601
2025-02-22 11:26:41,445 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-20T00:00:00+00:00, run_after=2024-08-21T00:00:00+00:00
2025-02-22 11:26:41,531 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:41,531 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:41,531 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:41,531 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:41,532 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:26:41,532 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:41,534 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:41,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:41,534 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:41,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:41,534 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:41,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:41,534 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:41,535 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:41,550 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:43,316 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:45,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:46,861 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:48,648 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:48,649 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:48,649 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:48,650 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:48,664 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:48.179734+00:00, run_end_date=2025-02-22 11:26:48.328182+00:00, run_duration=0.148448, state=success, executor_state=success, try_number=1, max_tries=1, job_id=741, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:41.532490+00:00, queued_by_job_id=7, pid=64723
2025-02-22 11:26:48,664 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:46.372489+00:00, run_end_date=2025-02-22 11:26:46.536645+00:00, run_duration=0.164156, state=success, executor_state=success, try_number=1, max_tries=1, job_id=740, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:41.532490+00:00, queued_by_job_id=7, pid=64703
2025-02-22 11:26:48,665 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:44.619234+00:00, run_end_date=2025-02-22 11:26:44.777492+00:00, run_duration=0.158258, state=success, executor_state=success, try_number=1, max_tries=1, job_id=739, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:41.532490+00:00, queued_by_job_id=7, pid=64685
2025-02-22 11:26:48,665 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:42.851687+00:00, run_end_date=2025-02-22 11:26:43.001387+00:00, run_duration=0.1497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=738, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:41.532490+00:00, queued_by_job_id=7, pid=64658
2025-02-22 11:26:48,841 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-21T00:00:00+00:00, run_after=2024-08-22T00:00:00+00:00
2025-02-22 11:26:48,914 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-16 00:00:00+00:00: scheduled__2024-08-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:48,915 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-16 00:00:00+00:00, run_id=scheduled__2024-08-16T00:00:00+00:00, run_start_date=2025-02-22 11:26:29.934664+00:00, run_end_date=2025-02-22 11:26:48.914992+00:00, run_duration=18.980328, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-16 00:00:00+00:00, data_interval_end=2024-08-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:48,918 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-17T00:00:00+00:00, run_after=2024-08-18T00:00:00+00:00
2025-02-22 11:26:48,940 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:48,940 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:48,940 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:48,940 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:48,940 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:26:48,940 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:48,942 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:26:48,943 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:48,943 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:48,943 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:48,943 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:48,943 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:48,943 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:48,943 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:48,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:50,769 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:52,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:54,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:56,069 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:56,070 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:56,071 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:56,071 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:26:56,091 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:55.614581+00:00, run_end_date=2025-02-22 11:26:55.777657+00:00, run_duration=0.163076, state=success, executor_state=success, try_number=1, max_tries=1, job_id=745, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:48.941136+00:00, queued_by_job_id=7, pid=64799
2025-02-22 11:26:56,092 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:53.857987+00:00, run_end_date=2025-02-22 11:26:54.009805+00:00, run_duration=0.151818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=744, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:48.941136+00:00, queued_by_job_id=7, pid=64780
2025-02-22 11:26:56,093 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:52.115103+00:00, run_end_date=2025-02-22 11:26:52.281942+00:00, run_duration=0.166839, state=success, executor_state=success, try_number=1, max_tries=1, job_id=743, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:48.941136+00:00, queued_by_job_id=7, pid=64762
2025-02-22 11:26:56,093 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:50.269300+00:00, run_end_date=2025-02-22 11:26:50.415260+00:00, run_duration=0.14596, state=success, executor_state=success, try_number=1, max_tries=1, job_id=742, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:26:48.941136+00:00, queued_by_job_id=7, pid=64742
2025-02-22 11:26:56,259 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-18T00:00:00+00:00, run_after=2024-08-19T00:00:00+00:00
2025-02-22 11:26:56,325 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-17 00:00:00+00:00: scheduled__2024-08-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:26:56,325 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-17 00:00:00+00:00, run_id=scheduled__2024-08-17T00:00:00+00:00, run_start_date=2025-02-22 11:26:31.941847+00:00, run_end_date=2025-02-22 11:26:56.325364+00:00, run_duration=24.383517, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-17 00:00:00+00:00, data_interval_end=2024-08-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:26:56,330 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-18T00:00:00+00:00, run_after=2024-08-19T00:00:00+00:00
2025-02-22 11:26:56,353 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:56,354 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:26:56,354 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:26:56,354 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:26:56,354 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:26:56,356 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:26:56,356 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:56,357 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:26:56,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:56,357 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:26:56,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:56,371 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:58,153 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:26:59,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:01,639 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:01,639 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:01,639 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:01,647 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:01.190212+00:00, run_end_date=2025-02-22 11:27:01.339807+00:00, run_duration=0.149595, state=success, executor_state=success, try_number=1, max_tries=1, job_id=748, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:26:56.354858+00:00, queued_by_job_id=7, pid=64865
2025-02-22 11:27:01,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:59.455098+00:00, run_end_date=2025-02-22 11:26:59.621789+00:00, run_duration=0.166691, state=success, executor_state=success, try_number=1, max_tries=1, job_id=747, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:26:56.354858+00:00, queued_by_job_id=7, pid=64845
2025-02-22 11:27:01,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:26:57.675339+00:00, run_end_date=2025-02-22 11:26:57.829355+00:00, run_duration=0.154016, state=success, executor_state=success, try_number=1, max_tries=1, job_id=746, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:26:56.354858+00:00, queued_by_job_id=7, pid=64826
2025-02-22 11:27:01,682 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:27:02,171 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-19T00:00:00+00:00, run_after=2024-08-20T00:00:00+00:00
2025-02-22 11:27:02,234 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-18 00:00:00+00:00: scheduled__2024-08-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:02,234 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-18 00:00:00+00:00, run_id=scheduled__2024-08-18T00:00:00+00:00, run_start_date=2025-02-22 11:26:35.773489+00:00, run_end_date=2025-02-22 11:27:02.234417+00:00, run_duration=26.460928, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-18 00:00:00+00:00, data_interval_end=2024-08-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:02,239 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-19T00:00:00+00:00, run_after=2024-08-20T00:00:00+00:00
2025-02-22 11:27:02,263 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:02,263 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:02,263 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:02,263 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:02,265 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:02,265 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:02,265 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:02,265 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:02,279 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:04,164 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:05,924 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:05,925 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:05,932 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:05.470144+00:00, run_end_date=2025-02-22 11:27:05.639055+00:00, run_duration=0.168911, state=success, executor_state=success, try_number=1, max_tries=1, job_id=750, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:02.263845+00:00, queued_by_job_id=7, pid=64912
2025-02-22 11:27:05,933 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:03.693164+00:00, run_end_date=2025-02-22 11:27:03.846624+00:00, run_duration=0.15346, state=success, executor_state=success, try_number=1, max_tries=1, job_id=749, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:02.263845+00:00, queued_by_job_id=7, pid=64894
2025-02-22 11:27:06,368 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-20T00:00:00+00:00, run_after=2024-08-21T00:00:00+00:00
2025-02-22 11:27:06,423 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-19 00:00:00+00:00: scheduled__2024-08-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:06,424 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-19 00:00:00+00:00, run_id=scheduled__2024-08-19T00:00:00+00:00, run_start_date=2025-02-22 11:26:41.468284+00:00, run_end_date=2025-02-22 11:27:06.424204+00:00, run_duration=24.95592, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-19 00:00:00+00:00, data_interval_end=2024-08-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:06,429 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-20T00:00:00+00:00, run_after=2024-08-21T00:00:00+00:00
2025-02-22 11:27:06,460 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:06,461 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:06,461 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:06,465 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:06,465 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:06,480 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:08,272 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:08,279 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:07.790339+00:00, run_end_date=2025-02-22 11:27:07.942056+00:00, run_duration=0.151717, state=success, executor_state=success, try_number=1, max_tries=1, job_id=751, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:06.462468+00:00, queued_by_job_id=7, pid=64948
2025-02-22 11:27:08,736 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-22T00:00:00+00:00, run_after=2024-08-23T00:00:00+00:00
2025-02-22 11:27:08,777 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-20 00:00:00+00:00: scheduled__2024-08-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:08,777 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-20 00:00:00+00:00, run_id=scheduled__2024-08-20T00:00:00+00:00, run_start_date=2025-02-22 11:26:48.870225+00:00, run_end_date=2025-02-22 11:27:08.777236+00:00, run_duration=19.907011, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-20 00:00:00+00:00, data_interval_end=2024-08-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:08,779 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-21T00:00:00+00:00, run_after=2024-08-22T00:00:00+00:00
2025-02-22 11:27:08,795 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:08,795 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:08,795 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:08,796 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:08,797 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:08,808 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:11,083 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:11,091 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:10.114296+00:00, run_end_date=2025-02-22 11:27:10.636756+00:00, run_duration=0.52246, state=success, executor_state=success, try_number=1, max_tries=1, job_id=752, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:08.796079+00:00, queued_by_job_id=7, pid=64977
2025-02-22 11:27:11,223 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-22T00:00:00+00:00, run_after=2024-08-23T00:00:00+00:00
2025-02-22 11:27:11,303 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:11,303 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:11,303 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:11,306 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:11,307 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:11,320 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:13,140 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:13,154 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:12.642678+00:00, run_end_date=2025-02-22 11:27:12.793409+00:00, run_duration=0.150731, state=success, executor_state=success, try_number=1, max_tries=1, job_id=753, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:11.304476+00:00, queued_by_job_id=7, pid=64997
2025-02-22 11:27:13,320 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-23T00:00:00+00:00, run_after=2024-08-24T00:00:00+00:00
2025-02-22 11:27:13,395 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:13,395 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:13,395 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:13,395 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:13,397 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:13,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:13,397 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:13,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:13,410 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:15,237 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:16,982 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:16,983 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:16,991 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:16.520143+00:00, run_end_date=2025-02-22 11:27:16.687784+00:00, run_duration=0.167641, state=success, executor_state=success, try_number=1, max_tries=1, job_id=755, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:13.396026+00:00, queued_by_job_id=7, pid=65044
2025-02-22 11:27:16,991 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:14.756267+00:00, run_end_date=2025-02-22 11:27:14.902248+00:00, run_duration=0.145981, state=success, executor_state=success, try_number=1, max_tries=1, job_id=754, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:13.396026+00:00, queued_by_job_id=7, pid=65017
2025-02-22 11:27:17,159 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-24T00:00:00+00:00, run_after=2024-08-25T00:00:00+00:00
2025-02-22 11:27:17,242 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:17,242 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:17,242 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:17,243 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:27:17,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:17,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:17,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:17,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:17,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:17,245 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:17,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:17,259 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:19,030 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:20,771 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:22,541 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:22,541 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:22,542 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:22,550 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:22.062997+00:00, run_end_date=2025-02-22 11:27:22.219431+00:00, run_duration=0.156434, state=success, executor_state=success, try_number=1, max_tries=1, job_id=758, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:17.243501+00:00, queued_by_job_id=7, pid=65101
2025-02-22 11:27:22,550 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:20.316914+00:00, run_end_date=2025-02-22 11:27:20.473489+00:00, run_duration=0.156575, state=success, executor_state=success, try_number=1, max_tries=1, job_id=757, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:17.243501+00:00, queued_by_job_id=7, pid=65083
2025-02-22 11:27:22,550 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:18.555825+00:00, run_end_date=2025-02-22 11:27:18.719860+00:00, run_duration=0.164035, state=success, executor_state=success, try_number=1, max_tries=1, job_id=756, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:17.243501+00:00, queued_by_job_id=7, pid=65064
2025-02-22 11:27:22,721 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-25T00:00:00+00:00, run_after=2024-08-26T00:00:00+00:00
2025-02-22 11:27:22,781 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-21 00:00:00+00:00: scheduled__2024-08-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:22,781 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-21 00:00:00+00:00, run_id=scheduled__2024-08-21T00:00:00+00:00, run_start_date=2025-02-22 11:27:08.755371+00:00, run_end_date=2025-02-22 11:27:22.781256+00:00, run_duration=14.025885, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-21 00:00:00+00:00, data_interval_end=2024-08-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:22,784 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-22T00:00:00+00:00, run_after=2024-08-23T00:00:00+00:00
2025-02-22 11:27:22,807 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:22,807 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:22,807 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:22,807 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:27:22,807 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:22,809 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:22,809 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:22,810 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:22,810 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:22,810 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:22,810 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:22,824 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:24,726 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:26,509 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:28,273 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:28,273 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:28,274 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:28,282 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:27.794667+00:00, run_end_date=2025-02-22 11:27:27.938202+00:00, run_duration=0.143535, state=success, executor_state=success, try_number=1, max_tries=1, job_id=761, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:22.808213+00:00, queued_by_job_id=7, pid=65158
2025-02-22 11:27:28,282 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:26.008688+00:00, run_end_date=2025-02-22 11:27:26.157493+00:00, run_duration=0.148805, state=success, executor_state=success, try_number=1, max_tries=1, job_id=760, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:22.808213+00:00, queued_by_job_id=7, pid=65140
2025-02-22 11:27:28,282 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:24.128498+00:00, run_end_date=2025-02-22 11:27:24.355617+00:00, run_duration=0.227119, state=success, executor_state=success, try_number=1, max_tries=1, job_id=759, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:22.808213+00:00, queued_by_job_id=7, pid=65121
2025-02-22 11:27:28,446 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-23T00:00:00+00:00, run_after=2024-08-24T00:00:00+00:00
2025-02-22 11:27:28,511 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:28,511 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:28,512 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:28,512 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:27:28,512 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:28,515 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:28,515 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:28,515 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:28,516 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:28,516 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:28,516 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:28,529 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:30,389 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:32,181 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:33,958 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:33,958 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:33,958 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:33,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:33.473493+00:00, run_end_date=2025-02-22 11:27:33.621500+00:00, run_duration=0.148007, state=success, executor_state=success, try_number=1, max_tries=1, job_id=764, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:28.512877+00:00, queued_by_job_id=7, pid=65225
2025-02-22 11:27:33,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:31.684658+00:00, run_end_date=2025-02-22 11:27:31.856486+00:00, run_duration=0.171828, state=success, executor_state=success, try_number=1, max_tries=1, job_id=763, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:28.512877+00:00, queued_by_job_id=7, pid=65198
2025-02-22 11:27:33,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:29.894021+00:00, run_end_date=2025-02-22 11:27:30.060735+00:00, run_duration=0.166714, state=success, executor_state=success, try_number=1, max_tries=1, job_id=762, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:28.512877+00:00, queued_by_job_id=7, pid=65179
2025-02-22 11:27:34,214 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-24T00:00:00+00:00, run_after=2024-08-25T00:00:00+00:00
2025-02-22 11:27:34,280 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-22 00:00:00+00:00: scheduled__2024-08-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:34,280 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-22 00:00:00+00:00, run_id=scheduled__2024-08-22T00:00:00+00:00, run_start_date=2025-02-22 11:27:13.345421+00:00, run_end_date=2025-02-22 11:27:34.280869+00:00, run_duration=20.935448, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-22 00:00:00+00:00, data_interval_end=2024-08-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:34,285 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-23T00:00:00+00:00, run_after=2024-08-24T00:00:00+00:00
2025-02-22 11:27:34,311 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:34,311 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:34,311 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:34,312 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:34,315 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:34,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:34,315 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:34,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:34,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:36,121 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:37,855 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:37,856 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:37,864 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:37.404116+00:00, run_end_date=2025-02-22 11:27:37.555103+00:00, run_duration=0.150987, state=success, executor_state=success, try_number=1, max_tries=1, job_id=766, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:34.312575+00:00, queued_by_job_id=7, pid=65263
2025-02-22 11:27:37,864 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:35.647183+00:00, run_end_date=2025-02-22 11:27:35.796699+00:00, run_duration=0.149516, state=success, executor_state=success, try_number=1, max_tries=1, job_id=765, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:34.312575+00:00, queued_by_job_id=7, pid=65244
2025-02-22 11:27:38,000 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-24T00:00:00+00:00, run_after=2024-08-25T00:00:00+00:00
2025-02-22 11:27:38,032 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-23 00:00:00+00:00: scheduled__2024-08-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:38,033 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-23 00:00:00+00:00, run_id=scheduled__2024-08-23T00:00:00+00:00, run_start_date=2025-02-22 11:27:17.185252+00:00, run_end_date=2025-02-22 11:27:38.033141+00:00, run_duration=20.847889, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-23 00:00:00+00:00, data_interval_end=2024-08-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:38,036 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-24T00:00:00+00:00, run_after=2024-08-25T00:00:00+00:00
2025-02-22 11:27:38,058 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:38,059 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:38,059 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:38,060 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:38,061 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:38,074 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:39,812 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:39,820 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:39.371779+00:00, run_end_date=2025-02-22 11:27:39.527453+00:00, run_duration=0.155674, state=success, executor_state=success, try_number=1, max_tries=1, job_id=767, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:38.059632+00:00, queued_by_job_id=7, pid=65283
2025-02-22 11:27:39,990 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-25T00:00:00+00:00, run_after=2024-08-26T00:00:00+00:00
2025-02-22 11:27:40,029 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-24 00:00:00+00:00: scheduled__2024-08-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:27:40,029 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-24 00:00:00+00:00, run_id=scheduled__2024-08-24T00:00:00+00:00, run_start_date=2025-02-22 11:27:22.744362+00:00, run_end_date=2025-02-22 11:27:40.029768+00:00, run_duration=17.285406, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-24 00:00:00+00:00, data_interval_end=2024-08-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:27:40,035 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-25T00:00:00+00:00, run_after=2024-08-26T00:00:00+00:00
2025-02-22 11:27:41,209 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-26T00:00:00+00:00, run_after=2024-08-27T00:00:00+00:00
2025-02-22 11:27:41,283 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:41,284 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:41,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:41,285 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:41,285 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:41,299 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:43,230 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:43,238 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:42.682580+00:00, run_end_date=2025-02-22 11:27:42.833665+00:00, run_duration=0.151085, state=success, executor_state=success, try_number=1, max_tries=1, job_id=768, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:41.284676+00:00, queued_by_job_id=7, pid=65306
2025-02-22 11:27:43,406 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-27T00:00:00+00:00, run_after=2024-08-28T00:00:00+00:00
2025-02-22 11:27:43,478 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:43,478 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:43,478 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:43,478 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:43,480 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:43,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:43,481 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:43,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:43,498 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:45,348 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:47,147 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:47,148 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:47,156 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:46.698909+00:00, run_end_date=2025-02-22 11:27:46.850747+00:00, run_duration=0.151838, state=success, executor_state=success, try_number=1, max_tries=1, job_id=770, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:43.479134+00:00, queued_by_job_id=7, pid=65352
2025-02-22 11:27:47,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:44.869228+00:00, run_end_date=2025-02-22 11:27:45.019369+00:00, run_duration=0.150141, state=success, executor_state=success, try_number=1, max_tries=1, job_id=769, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:43.479134+00:00, queued_by_job_id=7, pid=65333
2025-02-22 11:27:47,322 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-28T00:00:00+00:00, run_after=2024-08-29T00:00:00+00:00
2025-02-22 11:27:47,402 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:47,402 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:47,403 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:47,403 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:27:47,403 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:47,405 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:47,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:47,405 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:47,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:47,405 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:47,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:47,419 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:49,334 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:51,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:52,988 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:52,989 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:52,989 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:27:52,996 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:52.468791+00:00, run_end_date=2025-02-22 11:27:52.620463+00:00, run_duration=0.151672, state=success, executor_state=success, try_number=1, max_tries=1, job_id=773, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:47.403529+00:00, queued_by_job_id=7, pid=65410
2025-02-22 11:27:52,997 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:50.636216+00:00, run_end_date=2025-02-22 11:27:50.795790+00:00, run_duration=0.159574, state=success, executor_state=success, try_number=1, max_tries=1, job_id=772, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:47.403529+00:00, queued_by_job_id=7, pid=65391
2025-02-22 11:27:52,997 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:48.727962+00:00, run_end_date=2025-02-22 11:27:48.985951+00:00, run_duration=0.257989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=771, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:47.403529+00:00, queued_by_job_id=7, pid=65372
2025-02-22 11:27:53,163 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-29T00:00:00+00:00, run_after=2024-08-30T00:00:00+00:00
2025-02-22 11:27:53,243 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:53,243 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:27:53,243 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:27:53,243 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:27:53,244 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:27:53,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:27:53,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:27:53,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:53,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:27:53,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:53,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:27:53,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:53,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:27:53,247 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:53,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:55,088 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:56,947 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:27:58,700 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:00,453 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:00,453 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:00,454 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:00,454 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:00,462 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:59.985991+00:00, run_end_date=2025-02-22 11:28:00.149511+00:00, run_duration=0.16352, state=success, executor_state=success, try_number=1, max_tries=1, job_id=777, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:27:53.244509+00:00, queued_by_job_id=7, pid=65493
2025-02-22 11:28:00,462 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:58.241688+00:00, run_end_date=2025-02-22 11:27:58.389303+00:00, run_duration=0.147615, state=success, executor_state=success, try_number=1, max_tries=1, job_id=776, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:27:53.244509+00:00, queued_by_job_id=7, pid=65475
2025-02-22 11:28:00,462 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:56.486571+00:00, run_end_date=2025-02-22 11:27:56.636388+00:00, run_duration=0.149817, state=success, executor_state=success, try_number=1, max_tries=1, job_id=775, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:27:53.244509+00:00, queued_by_job_id=7, pid=65456
2025-02-22 11:28:00,462 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:27:54.568599+00:00, run_end_date=2025-02-22 11:27:54.717444+00:00, run_duration=0.148845, state=success, executor_state=success, try_number=1, max_tries=1, job_id=774, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:27:53.244509+00:00, queued_by_job_id=7, pid=65438
2025-02-22 11:28:00,632 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-30T00:00:00+00:00, run_after=2024-08-31T00:00:00+00:00
2025-02-22 11:28:00,699 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-25 00:00:00+00:00: scheduled__2024-08-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:00,699 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-25 00:00:00+00:00, run_id=scheduled__2024-08-25T00:00:00+00:00, run_start_date=2025-02-22 11:27:41.236999+00:00, run_end_date=2025-02-22 11:28:00.699554+00:00, run_duration=19.462555, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-25 00:00:00+00:00, data_interval_end=2024-08-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:00,702 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-26T00:00:00+00:00, run_after=2024-08-27T00:00:00+00:00
2025-02-22 11:28:00,723 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:00,723 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:00,723 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:00,723 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:00,723 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:28:00,723 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:00,725 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:00,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:00,726 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:00,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:00,726 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:00,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:00,726 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:00,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:00,740 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:02,531 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:04,295 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:06,123 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:07,867 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:07,867 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:07,867 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:07,867 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:07,875 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:07.413011+00:00, run_end_date=2025-02-22 11:28:07.589244+00:00, run_duration=0.176233, state=success, executor_state=success, try_number=1, max_tries=1, job_id=781, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:00.724292+00:00, queued_by_job_id=7, pid=65578
2025-02-22 11:28:07,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:05.644991+00:00, run_end_date=2025-02-22 11:28:05.808157+00:00, run_duration=0.163166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=780, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:00.724292+00:00, queued_by_job_id=7, pid=65559
2025-02-22 11:28:07,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:03.824546+00:00, run_end_date=2025-02-22 11:28:03.976980+00:00, run_duration=0.152434, state=success, executor_state=success, try_number=1, max_tries=1, job_id=779, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:00.724292+00:00, queued_by_job_id=7, pid=65533
2025-02-22 11:28:07,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:02.043792+00:00, run_end_date=2025-02-22 11:28:02.190668+00:00, run_duration=0.146876, state=success, executor_state=success, try_number=1, max_tries=1, job_id=778, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:00.724292+00:00, queued_by_job_id=7, pid=65514
2025-02-22 11:28:08,040 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-27T00:00:00+00:00, run_after=2024-08-28T00:00:00+00:00
2025-02-22 11:28:08,109 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-26 00:00:00+00:00: scheduled__2024-08-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:08,110 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-26 00:00:00+00:00, run_id=scheduled__2024-08-26T00:00:00+00:00, run_start_date=2025-02-22 11:27:43.428398+00:00, run_end_date=2025-02-22 11:28:08.110218+00:00, run_duration=24.68182, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-26 00:00:00+00:00, data_interval_end=2024-08-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:08,114 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-27T00:00:00+00:00, run_after=2024-08-28T00:00:00+00:00
2025-02-22 11:28:08,138 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:08,139 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:08,139 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:08,139 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:08,139 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:08,141 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:08,141 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:08,141 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:08,142 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:08,142 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:08,142 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:08,156 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:09,913 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:11,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:13,433 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:13,433 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:13,434 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:13,442 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:12.971838+00:00, run_end_date=2025-02-22 11:28:13.116798+00:00, run_duration=0.14496, state=success, executor_state=success, try_number=1, max_tries=1, job_id=784, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:08.139721+00:00, queued_by_job_id=7, pid=65635
2025-02-22 11:28:13,443 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:11.215379+00:00, run_end_date=2025-02-22 11:28:11.363174+00:00, run_duration=0.147795, state=success, executor_state=success, try_number=1, max_tries=1, job_id=783, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:08.139721+00:00, queued_by_job_id=7, pid=65617
2025-02-22 11:28:13,443 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:09.453838+00:00, run_end_date=2025-02-22 11:28:09.602032+00:00, run_duration=0.148194, state=success, executor_state=success, try_number=1, max_tries=1, job_id=782, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:08.139721+00:00, queued_by_job_id=7, pid=65598
2025-02-22 11:28:13,625 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-28T00:00:00+00:00, run_after=2024-08-29T00:00:00+00:00
2025-02-22 11:28:13,682 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-27 00:00:00+00:00: scheduled__2024-08-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:13,682 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-27 00:00:00+00:00, run_id=scheduled__2024-08-27T00:00:00+00:00, run_start_date=2025-02-22 11:27:47.344582+00:00, run_end_date=2025-02-22 11:28:13.682772+00:00, run_duration=26.33819, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-27 00:00:00+00:00, data_interval_end=2024-08-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:13,687 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-28T00:00:00+00:00, run_after=2024-08-29T00:00:00+00:00
2025-02-22 11:28:13,715 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:13,715 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:13,715 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:13,715 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:13,719 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:13,719 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:13,719 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:13,719 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:13,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:15,522 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:17,331 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:17,331 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:17,339 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:16.835513+00:00, run_end_date=2025-02-22 11:28:16.987632+00:00, run_duration=0.152119, state=success, executor_state=success, try_number=1, max_tries=1, job_id=786, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:13.716492+00:00, queued_by_job_id=7, pid=65682
2025-02-22 11:28:17,339 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:15.032576+00:00, run_end_date=2025-02-22 11:28:15.185334+00:00, run_duration=0.152758, state=success, executor_state=success, try_number=1, max_tries=1, job_id=785, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:13.716492+00:00, queued_by_job_id=7, pid=65655
2025-02-22 11:28:17,479 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-29T00:00:00+00:00, run_after=2024-08-30T00:00:00+00:00
2025-02-22 11:28:17,512 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-28 00:00:00+00:00: scheduled__2024-08-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:17,513 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-28 00:00:00+00:00, run_id=scheduled__2024-08-28T00:00:00+00:00, run_start_date=2025-02-22 11:27:53.185323+00:00, run_end_date=2025-02-22 11:28:17.512964+00:00, run_duration=24.327641, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-28 00:00:00+00:00, data_interval_end=2024-08-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:17,516 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-29T00:00:00+00:00, run_after=2024-08-30T00:00:00+00:00
2025-02-22 11:28:17,539 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:17,539 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:17,539 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:17,541 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:17,541 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:17,555 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:19,309 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:19,317 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:18.842745+00:00, run_end_date=2025-02-22 11:28:18.988782+00:00, run_duration=0.146037, state=success, executor_state=success, try_number=1, max_tries=1, job_id=787, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:17.540345+00:00, queued_by_job_id=7, pid=65702
2025-02-22 11:28:19,481 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-30T00:00:00+00:00, run_after=2024-08-31T00:00:00+00:00
2025-02-22 11:28:19,519 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-29 00:00:00+00:00: scheduled__2024-08-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:19,520 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-29 00:00:00+00:00, run_id=scheduled__2024-08-29T00:00:00+00:00, run_start_date=2025-02-22 11:28:00.657982+00:00, run_end_date=2025-02-22 11:28:19.520336+00:00, run_duration=18.862354, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-29 00:00:00+00:00, data_interval_end=2024-08-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:19,526 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-30T00:00:00+00:00, run_after=2024-08-31T00:00:00+00:00
2025-02-22 11:28:20,698 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-31T00:00:00+00:00, run_after=2024-09-01T00:00:00+00:00
2025-02-22 11:28:20,774 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:20,774 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:20,774 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:20,776 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:20,776 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:20,789 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:22,607 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:22,615 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:22.146771+00:00, run_end_date=2025-02-22 11:28:22.301038+00:00, run_duration=0.154267, state=success, executor_state=success, try_number=1, max_tries=1, job_id=788, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:20.775369+00:00, queued_by_job_id=7, pid=65725
2025-02-22 11:28:22,764 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-01T00:00:00+00:00, run_after=2024-09-02T00:00:00+00:00
2025-02-22 11:28:22,849 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:22,850 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:22,850 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:22,850 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:22,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:22,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:22,852 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:22,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:22,866 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:24,665 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:26,442 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-08-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:26,442 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:26,450 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:25.955396+00:00, run_end_date=2025-02-22 11:28:26.105094+00:00, run_duration=0.149698, state=success, executor_state=success, try_number=1, max_tries=1, job_id=790, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:22.850649+00:00, queued_by_job_id=7, pid=65763
2025-02-22 11:28:26,451 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-08-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:24.153021+00:00, run_end_date=2025-02-22 11:28:24.309995+00:00, run_duration=0.156974, state=success, executor_state=success, try_number=1, max_tries=1, job_id=789, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:22.850649+00:00, queued_by_job_id=7, pid=65744
2025-02-22 11:28:26,626 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-02T00:00:00+00:00, run_after=2024-09-03T00:00:00+00:00
2025-02-22 11:28:26,711 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:26,711 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:26,712 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:26,712 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:26,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:26,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:26,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:26,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:26,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:26,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:26,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:26,736 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:28,514 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:30,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:32,025 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:32,025 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-08-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:32,025 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:32,034 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:31.553732+00:00, run_end_date=2025-02-22 11:28:31.699633+00:00, run_duration=0.145901, state=success, executor_state=success, try_number=1, max_tries=1, job_id=793, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:26.712588+00:00, queued_by_job_id=7, pid=65827
2025-02-22 11:28:32,034 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-08-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:29.797651+00:00, run_end_date=2025-02-22 11:28:29.954143+00:00, run_duration=0.156492, state=success, executor_state=success, try_number=1, max_tries=1, job_id=792, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:26.712588+00:00, queued_by_job_id=7, pid=65809
2025-02-22 11:28:32,034 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:28.039256+00:00, run_end_date=2025-02-22 11:28:28.188729+00:00, run_duration=0.149473, state=success, executor_state=success, try_number=1, max_tries=1, job_id=791, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:26.712588+00:00, queued_by_job_id=7, pid=65790
2025-02-22 11:28:32,208 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-03T00:00:00+00:00, run_after=2024-09-04T00:00:00+00:00
2025-02-22 11:28:32,295 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:32,295 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:32,295 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:32,295 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:32,295 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:28:32,295 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:32,297 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:32,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:32,298 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:32,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:32,298 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:32,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:32,298 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:32,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:32,308 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:34,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:36,089 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:37,810 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:40,804 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:40,805 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:40,805 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-08-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:40,805 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:40,813 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:39.220476+00:00, run_end_date=2025-02-22 11:28:40.331616+00:00, run_duration=1.11114, state=success, executor_state=success, try_number=1, max_tries=1, job_id=797, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:32.296320+00:00, queued_by_job_id=7, pid=65912
2025-02-22 11:28:40,814 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-08-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:37.379131+00:00, run_end_date=2025-02-22 11:28:37.534104+00:00, run_duration=0.154973, state=success, executor_state=success, try_number=1, max_tries=1, job_id=796, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:32.296320+00:00, queued_by_job_id=7, pid=65885
2025-02-22 11:28:40,814 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:35.580503+00:00, run_end_date=2025-02-22 11:28:35.731121+00:00, run_duration=0.150618, state=success, executor_state=success, try_number=1, max_tries=1, job_id=795, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:32.296320+00:00, queued_by_job_id=7, pid=65867
2025-02-22 11:28:40,814 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:33.603302+00:00, run_end_date=2025-02-22 11:28:33.934490+00:00, run_duration=0.331188, state=success, executor_state=success, try_number=1, max_tries=1, job_id=794, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:32.296320+00:00, queued_by_job_id=7, pid=65848
2025-02-22 11:28:40,995 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-04T00:00:00+00:00, run_after=2024-09-05T00:00:00+00:00
2025-02-22 11:28:41,059 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-30 00:00:00+00:00: scheduled__2024-08-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:41,059 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-30 00:00:00+00:00, run_id=scheduled__2024-08-30T00:00:00+00:00, run_start_date=2025-02-22 11:28:20.725646+00:00, run_end_date=2025-02-22 11:28:41.059293+00:00, run_duration=20.333647, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-30 00:00:00+00:00, data_interval_end=2024-08-31 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:41,062 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-08-31T00:00:00+00:00, run_after=2024-09-01T00:00:00+00:00
2025-02-22 11:28:41,086 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:41,087 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:41,087 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:41,087 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:41,087 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:28:41,087 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-08-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:41,089 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:28:41,089 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:41,090 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:41,090 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:41,090 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:41,090 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:41,090 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-08-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:41,090 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:41,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:42,950 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:44,740 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:46,497 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-08-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:48,407 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:48,408 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:48,408 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:48,408 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-08-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:48,417 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-08-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:47.789736+00:00, run_end_date=2025-02-22 11:28:48.056668+00:00, run_duration=0.266932, state=success, executor_state=success, try_number=1, max_tries=1, job_id=801, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:41.087883+00:00, queued_by_job_id=7, pid=65989
2025-02-22 11:28:48,417 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:46.032356+00:00, run_end_date=2025-02-22 11:28:46.187924+00:00, run_duration=0.155568, state=success, executor_state=success, try_number=1, max_tries=1, job_id=800, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:41.087883+00:00, queued_by_job_id=7, pid=65970
2025-02-22 11:28:48,417 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:44.243549+00:00, run_end_date=2025-02-22 11:28:44.404188+00:00, run_duration=0.160639, state=success, executor_state=success, try_number=1, max_tries=1, job_id=799, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:41.087883+00:00, queued_by_job_id=7, pid=65952
2025-02-22 11:28:48,418 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:42.463326+00:00, run_end_date=2025-02-22 11:28:42.613351+00:00, run_duration=0.150025, state=success, executor_state=success, try_number=1, max_tries=1, job_id=798, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:28:41.087883+00:00, queued_by_job_id=7, pid=65933
2025-02-22 11:28:48,606 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-01T00:00:00+00:00, run_after=2024-09-02T00:00:00+00:00
2025-02-22 11:28:48,677 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-08-31 00:00:00+00:00: scheduled__2024-08-31T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:48,677 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-08-31 00:00:00+00:00, run_id=scheduled__2024-08-31T00:00:00+00:00, run_start_date=2025-02-22 11:28:22.792492+00:00, run_end_date=2025-02-22 11:28:48.677594+00:00, run_duration=25.885102, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-08-31 00:00:00+00:00, data_interval_end=2024-09-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:48,682 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-01T00:00:00+00:00, run_after=2024-09-02T00:00:00+00:00
2025-02-22 11:28:48,710 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:48,710 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:48,710 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:48,711 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:28:48,711 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:48,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:28:48,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:48,715 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:48,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:48,715 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:48,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:48,730 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:50,529 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:52,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:54,060 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:54,061 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:54,061 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:54,069 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:53.585896+00:00, run_end_date=2025-02-22 11:28:53.743075+00:00, run_duration=0.157179, state=success, executor_state=success, try_number=1, max_tries=1, job_id=804, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:48.711775+00:00, queued_by_job_id=7, pid=66055
2025-02-22 11:28:54,069 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:51.830482+00:00, run_end_date=2025-02-22 11:28:51.976806+00:00, run_duration=0.146324, state=success, executor_state=success, try_number=1, max_tries=1, job_id=803, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:48.711775+00:00, queued_by_job_id=7, pid=66036
2025-02-22 11:28:54,069 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:50.025338+00:00, run_end_date=2025-02-22 11:28:50.171052+00:00, run_duration=0.145714, state=success, executor_state=success, try_number=1, max_tries=1, job_id=802, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:28:48.711775+00:00, queued_by_job_id=7, pid=66009
2025-02-22 11:28:54,223 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-02T00:00:00+00:00, run_after=2024-09-03T00:00:00+00:00
2025-02-22 11:28:54,285 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-01 00:00:00+00:00: scheduled__2024-09-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:54,286 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-01 00:00:00+00:00, run_id=scheduled__2024-09-01T00:00:00+00:00, run_start_date=2025-02-22 11:28:26.653405+00:00, run_end_date=2025-02-22 11:28:54.286003+00:00, run_duration=27.632598, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-01 00:00:00+00:00, data_interval_end=2024-09-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:54,291 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-02T00:00:00+00:00, run_after=2024-09-03T00:00:00+00:00
2025-02-22 11:28:54,315 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:54,315 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:54,315 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:28:54,315 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:54,319 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:28:54,319 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:54,319 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:54,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:54,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:56,090 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:57,842 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:57,843 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:57,851 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:57.400792+00:00, run_end_date=2025-02-22 11:28:57.561119+00:00, run_duration=0.160327, state=success, executor_state=success, try_number=1, max_tries=1, job_id=806, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:54.316465+00:00, queued_by_job_id=7, pid=66093
2025-02-22 11:28:57,851 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:55.628443+00:00, run_end_date=2025-02-22 11:28:55.774663+00:00, run_duration=0.14622, state=success, executor_state=success, try_number=1, max_tries=1, job_id=805, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:28:54.316465+00:00, queued_by_job_id=7, pid=66075
2025-02-22 11:28:57,985 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-03T00:00:00+00:00, run_after=2024-09-04T00:00:00+00:00
2025-02-22 11:28:58,037 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-02 00:00:00+00:00: scheduled__2024-09-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:28:58,037 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-02 00:00:00+00:00, run_id=scheduled__2024-09-02T00:00:00+00:00, run_start_date=2025-02-22 11:28:32.233598+00:00, run_end_date=2025-02-22 11:28:58.037520+00:00, run_duration=25.803922, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-02 00:00:00+00:00, data_interval_end=2024-09-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:28:58,043 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-03T00:00:00+00:00, run_after=2024-09-04T00:00:00+00:00
2025-02-22 11:28:58,070 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:58,070 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:28:58,071 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:28:58,074 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:28:58,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:58,088 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:28:59,871 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:28:59,878 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:28:59.393755+00:00, run_end_date=2025-02-22 11:28:59.552040+00:00, run_duration=0.158285, state=success, executor_state=success, try_number=1, max_tries=1, job_id=807, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:28:58.072002+00:00, queued_by_job_id=7, pid=66113
2025-02-22 11:29:00,051 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-04T00:00:00+00:00, run_after=2024-09-05T00:00:00+00:00
2025-02-22 11:29:00,090 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-03 00:00:00+00:00: scheduled__2024-09-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:00,090 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-03 00:00:00+00:00, run_id=scheduled__2024-09-03T00:00:00+00:00, run_start_date=2025-02-22 11:28:41.017812+00:00, run_end_date=2025-02-22 11:29:00.090565+00:00, run_duration=19.072753, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-03 00:00:00+00:00, data_interval_end=2024-09-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:00,096 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-04T00:00:00+00:00, run_after=2024-09-05T00:00:00+00:00
2025-02-22 11:29:01,264 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-05T00:00:00+00:00, run_after=2024-09-06T00:00:00+00:00
2025-02-22 11:29:01,328 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:01,328 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:01,328 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:01,330 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:01,330 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:01,348 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:03,217 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:03,224 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:02.714329+00:00, run_end_date=2025-02-22 11:29:02.869563+00:00, run_duration=0.155234, state=success, executor_state=success, try_number=1, max_tries=1, job_id=808, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:01.329229+00:00, queued_by_job_id=7, pid=66143
2025-02-22 11:29:03,368 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-06T00:00:00+00:00, run_after=2024-09-07T00:00:00+00:00
2025-02-22 11:29:03,436 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:03,436 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:03,436 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:03,436 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:03,438 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:03,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:03,438 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:03,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:03,451 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:05,244 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:07,009 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:07,010 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:07,018 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:06.536683+00:00, run_end_date=2025-02-22 11:29:06.687503+00:00, run_duration=0.15082, state=success, executor_state=success, try_number=1, max_tries=1, job_id=810, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:03.436769+00:00, queued_by_job_id=7, pid=66183
2025-02-22 11:29:07,018 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:04.746823+00:00, run_end_date=2025-02-22 11:29:04.891907+00:00, run_duration=0.145084, state=success, executor_state=success, try_number=1, max_tries=1, job_id=809, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:03.436769+00:00, queued_by_job_id=7, pid=66164
2025-02-22 11:29:07,186 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-07T00:00:00+00:00, run_after=2024-09-08T00:00:00+00:00
2025-02-22 11:29:07,266 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:07,267 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:07,267 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:07,267 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:29:07,267 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:07,270 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:07,270 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:07,270 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:07,271 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:07,271 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:07,271 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:07,285 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:09,084 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:10,861 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:12,609 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:12,610 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:12,610 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:12,618 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:12.153232+00:00, run_end_date=2025-02-22 11:29:12.299589+00:00, run_duration=0.146357, state=success, executor_state=success, try_number=1, max_tries=1, job_id=813, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:07.268045+00:00, queued_by_job_id=7, pid=66240
2025-02-22 11:29:12,618 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:10.371451+00:00, run_end_date=2025-02-22 11:29:10.529448+00:00, run_duration=0.157997, state=success, executor_state=success, try_number=1, max_tries=1, job_id=812, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:07.268045+00:00, queued_by_job_id=7, pid=66221
2025-02-22 11:29:12,618 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:08.583562+00:00, run_end_date=2025-02-22 11:29:08.750316+00:00, run_duration=0.166754, state=success, executor_state=success, try_number=1, max_tries=1, job_id=811, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:07.268045+00:00, queued_by_job_id=7, pid=66202
2025-02-22 11:29:12,794 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-08T00:00:00+00:00, run_after=2024-09-09T00:00:00+00:00
2025-02-22 11:29:12,872 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:12,872 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:12,873 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:12,873 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:29:12,873 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:29:12,873 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:12,875 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:12,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:12,875 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:12,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:12,875 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:12,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:12,876 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:12,876 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:12,889 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:14,660 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:16,428 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:18,181 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:20,065 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:20,065 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:20,065 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:20,066 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:20,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:19.489142+00:00, run_end_date=2025-02-22 11:29:19.642789+00:00, run_duration=0.153647, state=success, executor_state=success, try_number=1, max_tries=1, job_id=817, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:12.873619+00:00, queued_by_job_id=7, pid=66325
2025-02-22 11:29:20,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:17.715193+00:00, run_end_date=2025-02-22 11:29:17.859776+00:00, run_duration=0.144583, state=success, executor_state=success, try_number=1, max_tries=1, job_id=816, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:12.873619+00:00, queued_by_job_id=7, pid=66305
2025-02-22 11:29:20,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:15.958210+00:00, run_end_date=2025-02-22 11:29:16.102730+00:00, run_duration=0.14452, state=success, executor_state=success, try_number=1, max_tries=1, job_id=815, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:12.873619+00:00, queued_by_job_id=7, pid=66286
2025-02-22 11:29:20,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:14.195126+00:00, run_end_date=2025-02-22 11:29:14.338026+00:00, run_duration=0.1429, state=success, executor_state=success, try_number=1, max_tries=1, job_id=814, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:12.873619+00:00, queued_by_job_id=7, pid=66268
2025-02-22 11:29:20,348 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-09T00:00:00+00:00, run_after=2024-09-10T00:00:00+00:00
2025-02-22 11:29:20,672 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-04 00:00:00+00:00: scheduled__2024-09-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:20,673 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-04 00:00:00+00:00, run_id=scheduled__2024-09-04T00:00:00+00:00, run_start_date=2025-02-22 11:29:01.285947+00:00, run_end_date=2025-02-22 11:29:20.672980+00:00, run_duration=19.387033, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-04 00:00:00+00:00, data_interval_end=2024-09-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:20,677 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-05T00:00:00+00:00, run_after=2024-09-06T00:00:00+00:00
2025-02-22 11:29:20,706 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:20,706 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:20,706 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:20,706 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:29:20,706 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:29:20,706 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:20,710 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:20,710 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:20,710 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:20,710 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:20,710 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:20,711 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:20,711 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:20,711 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:20,724 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:22,578 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:24,375 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:26,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:27,915 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:27,916 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:27,916 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:27,916 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:27,923 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:27.431591+00:00, run_end_date=2025-02-22 11:29:27.577368+00:00, run_duration=0.145777, state=success, executor_state=success, try_number=1, max_tries=1, job_id=821, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:20.707469+00:00, queued_by_job_id=7, pid=66408
2025-02-22 11:29:27,924 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:25.677045+00:00, run_end_date=2025-02-22 11:29:25.823589+00:00, run_duration=0.146544, state=success, executor_state=success, try_number=1, max_tries=1, job_id=820, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:20.707469+00:00, queued_by_job_id=7, pid=66390
2025-02-22 11:29:27,924 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:23.909011+00:00, run_end_date=2025-02-22 11:29:24.051985+00:00, run_duration=0.142974, state=success, executor_state=success, try_number=1, max_tries=1, job_id=819, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:20.707469+00:00, queued_by_job_id=7, pid=66371
2025-02-22 11:29:27,924 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:22.111504+00:00, run_end_date=2025-02-22 11:29:22.254989+00:00, run_duration=0.143485, state=success, executor_state=success, try_number=1, max_tries=1, job_id=818, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:20.707469+00:00, queued_by_job_id=7, pid=66353
2025-02-22 11:29:28,391 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-06T00:00:00+00:00, run_after=2024-09-07T00:00:00+00:00
2025-02-22 11:29:28,464 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-05 00:00:00+00:00: scheduled__2024-09-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:28,464 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-05 00:00:00+00:00, run_id=scheduled__2024-09-05T00:00:00+00:00, run_start_date=2025-02-22 11:29:03.389909+00:00, run_end_date=2025-02-22 11:29:28.464589+00:00, run_duration=25.07468, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-05 00:00:00+00:00, data_interval_end=2024-09-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:28,469 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-06T00:00:00+00:00, run_after=2024-09-07T00:00:00+00:00
2025-02-22 11:29:28,495 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:28,495 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:28,495 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:28,496 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:29:28,496 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:28,499 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:28,499 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:28,499 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:28,500 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:28,500 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:28,500 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:28,515 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:30,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:32,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:33,839 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:33,839 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:33,839 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:33,845 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:33.390593+00:00, run_end_date=2025-02-22 11:29:33.537466+00:00, run_duration=0.146873, state=success, executor_state=success, try_number=1, max_tries=1, job_id=824, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:28.496779+00:00, queued_by_job_id=7, pid=66475
2025-02-22 11:29:33,845 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:31.641046+00:00, run_end_date=2025-02-22 11:29:31.786880+00:00, run_duration=0.145834, state=success, executor_state=success, try_number=1, max_tries=1, job_id=823, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:28.496779+00:00, queued_by_job_id=7, pid=66456
2025-02-22 11:29:33,845 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:29.860895+00:00, run_end_date=2025-02-22 11:29:30.008130+00:00, run_duration=0.147235, state=success, executor_state=success, try_number=1, max_tries=1, job_id=822, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:28.496779+00:00, queued_by_job_id=7, pid=66437
2025-02-22 11:29:34,299 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-07T00:00:00+00:00, run_after=2024-09-08T00:00:00+00:00
2025-02-22 11:29:34,363 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-06 00:00:00+00:00: scheduled__2024-09-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:34,363 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-06 00:00:00+00:00, run_id=scheduled__2024-09-06T00:00:00+00:00, run_start_date=2025-02-22 11:29:07.210906+00:00, run_end_date=2025-02-22 11:29:34.363505+00:00, run_duration=27.152599, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-06 00:00:00+00:00, data_interval_end=2024-09-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:34,368 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-07T00:00:00+00:00, run_after=2024-09-08T00:00:00+00:00
2025-02-22 11:29:34,396 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:34,397 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:34,397 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:34,397 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:34,400 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:34,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:34,401 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:34,401 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:34,416 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:36,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:37,981 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:37,981 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:37,987 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:37.532522+00:00, run_end_date=2025-02-22 11:29:37.672958+00:00, run_duration=0.140436, state=success, executor_state=success, try_number=1, max_tries=1, job_id=826, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:34.398190+00:00, queued_by_job_id=7, pid=66521
2025-02-22 11:29:37,987 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:35.728872+00:00, run_end_date=2025-02-22 11:29:35.875476+00:00, run_duration=0.146604, state=success, executor_state=success, try_number=1, max_tries=1, job_id=825, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:34.398190+00:00, queued_by_job_id=7, pid=66503
2025-02-22 11:29:38,433 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-10T00:00:00+00:00, run_after=2024-09-11T00:00:00+00:00
2025-02-22 11:29:38,485 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-07 00:00:00+00:00: scheduled__2024-09-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:38,485 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-07 00:00:00+00:00, run_id=scheduled__2024-09-07T00:00:00+00:00, run_start_date=2025-02-22 11:29:12.817230+00:00, run_end_date=2025-02-22 11:29:38.485720+00:00, run_duration=25.66849, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-07 00:00:00+00:00, data_interval_end=2024-09-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:38,488 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-08T00:00:00+00:00, run_after=2024-09-09T00:00:00+00:00
2025-02-22 11:29:38,509 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:38,510 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:38,510 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:38,510 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:38,512 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:38,512 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:38,512 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:38,512 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:38,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:40,322 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:42,088 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:42,089 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:42,096 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:41.628886+00:00, run_end_date=2025-02-22 11:29:41.772709+00:00, run_duration=0.143823, state=success, executor_state=success, try_number=1, max_tries=1, job_id=828, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:38.510672+00:00, queued_by_job_id=7, pid=66568
2025-02-22 11:29:42,097 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:39.846772+00:00, run_end_date=2025-02-22 11:29:39.996395+00:00, run_duration=0.149623, state=success, executor_state=success, try_number=1, max_tries=1, job_id=827, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:38.510672+00:00, queued_by_job_id=7, pid=66550
2025-02-22 11:29:42,255 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-09T00:00:00+00:00, run_after=2024-09-10T00:00:00+00:00
2025-02-22 11:29:42,314 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-08 00:00:00+00:00: scheduled__2024-09-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:42,314 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-08 00:00:00+00:00, run_id=scheduled__2024-09-08T00:00:00+00:00, run_start_date=2025-02-22 11:29:20.603938+00:00, run_end_date=2025-02-22 11:29:42.314480+00:00, run_duration=21.710542, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-08 00:00:00+00:00, data_interval_end=2024-09-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:42,319 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-09T00:00:00+00:00, run_after=2024-09-10T00:00:00+00:00
2025-02-22 11:29:42,346 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:42,346 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:42,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:42,349 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:42,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:42,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:44,200 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:44,207 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:43.692340+00:00, run_end_date=2025-02-22 11:29:43.841604+00:00, run_duration=0.149264, state=success, executor_state=success, try_number=1, max_tries=1, job_id=829, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:42.347452+00:00, queued_by_job_id=7, pid=66596
2025-02-22 11:29:44,345 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-10T00:00:00+00:00, run_after=2024-09-11T00:00:00+00:00
2025-02-22 11:29:44,416 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:44,416 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:44,416 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:44,419 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:44,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:44,431 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:46,354 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:46,359 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:45.877119+00:00, run_end_date=2025-02-22 11:29:46.021672+00:00, run_duration=0.144553, state=success, executor_state=success, try_number=1, max_tries=1, job_id=830, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:44.417496+00:00, queued_by_job_id=7, pid=66616
2025-02-22 11:29:46,492 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-11T00:00:00+00:00, run_after=2024-09-12T00:00:00+00:00
2025-02-22 11:29:46,554 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:46,554 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:46,554 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:46,554 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:46,556 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:46,556 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:46,556 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:46,556 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:46,570 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:48,400 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:50,191 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:50,192 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:50,197 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:49.736681+00:00, run_end_date=2025-02-22 11:29:49.887306+00:00, run_duration=0.150625, state=success, executor_state=success, try_number=1, max_tries=1, job_id=832, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:46.555216+00:00, queued_by_job_id=7, pid=66655
2025-02-22 11:29:50,197 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:47.898053+00:00, run_end_date=2025-02-22 11:29:48.044036+00:00, run_duration=0.145983, state=success, executor_state=success, try_number=1, max_tries=1, job_id=831, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:46.555216+00:00, queued_by_job_id=7, pid=66636
2025-02-22 11:29:50,387 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-12T00:00:00+00:00, run_after=2024-09-13T00:00:00+00:00
2025-02-22 11:29:50,441 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-09 00:00:00+00:00: scheduled__2024-09-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:29:50,441 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-09 00:00:00+00:00, run_id=scheduled__2024-09-09T00:00:00+00:00, run_start_date=2025-02-22 11:29:38.455887+00:00, run_end_date=2025-02-22 11:29:50.441809+00:00, run_duration=11.985922, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-09 00:00:00+00:00, data_interval_end=2024-09-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:29:50,443 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-10T00:00:00+00:00, run_after=2024-09-11T00:00:00+00:00
2025-02-22 11:29:50,464 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:50,464 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:50,464 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:50,464 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:50,465 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:29:50,466 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:50,466 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:50,466 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:50,476 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:52,239 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:54,304 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:54,304 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:54,312 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:53.792053+00:00, run_end_date=2025-02-22 11:29:53.945488+00:00, run_duration=0.153435, state=success, executor_state=success, try_number=1, max_tries=1, job_id=834, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:50.464602+00:00, queued_by_job_id=7, pid=66702
2025-02-22 11:29:54,313 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:51.778726+00:00, run_end_date=2025-02-22 11:29:51.927093+00:00, run_duration=0.148367, state=success, executor_state=success, try_number=1, max_tries=1, job_id=833, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:29:50.464602+00:00, queued_by_job_id=7, pid=66675
2025-02-22 11:29:54,448 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-11T00:00:00+00:00, run_after=2024-09-12T00:00:00+00:00
2025-02-22 11:29:54,522 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:54,522 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:54,522 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:54,523 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:54,525 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:29:54,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:54,525 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:54,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:54,538 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:56,366 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:58,120 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:58,121 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:29:58,129 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:57.659248+00:00, run_end_date=2025-02-22 11:29:57.812932+00:00, run_duration=0.153684, state=success, executor_state=success, try_number=1, max_tries=1, job_id=836, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:54.523385+00:00, queued_by_job_id=7, pid=66749
2025-02-22 11:29:58,129 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:55.896399+00:00, run_end_date=2025-02-22 11:29:56.044977+00:00, run_duration=0.148578, state=success, executor_state=success, try_number=1, max_tries=1, job_id=835, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:29:54.523385+00:00, queued_by_job_id=7, pid=66730
2025-02-22 11:29:58,288 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-12T00:00:00+00:00, run_after=2024-09-13T00:00:00+00:00
2025-02-22 11:29:58,372 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:58,373 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:29:58,373 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:29:58,373 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:29:58,377 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:29:58,377 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:58,378 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:29:58,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:29:58,390 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:00,200 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:01,945 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:01,946 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:01,954 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:01.493276+00:00, run_end_date=2025-02-22 11:30:01.644704+00:00, run_duration=0.151428, state=success, executor_state=success, try_number=1, max_tries=1, job_id=838, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:29:58.374328+00:00, queued_by_job_id=7, pid=66787
2025-02-22 11:30:01,955 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:29:59.720346+00:00, run_end_date=2025-02-22 11:29:59.872486+00:00, run_duration=0.15214, state=success, executor_state=success, try_number=1, max_tries=1, job_id=837, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:29:58.374328+00:00, queued_by_job_id=7, pid=66768
2025-02-22 11:30:02,109 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-13T00:00:00+00:00, run_after=2024-09-14T00:00:00+00:00
2025-02-22 11:30:02,168 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-10 00:00:00+00:00: scheduled__2024-09-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:02,168 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-10 00:00:00+00:00, run_id=scheduled__2024-09-10T00:00:00+00:00, run_start_date=2025-02-22 11:29:46.516401+00:00, run_end_date=2025-02-22 11:30:02.168253+00:00, run_duration=15.651852, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-10 00:00:00+00:00, data_interval_end=2024-09-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:02,171 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-11T00:00:00+00:00, run_after=2024-09-12T00:00:00+00:00
2025-02-22 11:30:02,194 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:02,194 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:02,194 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:02,194 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:02,196 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:02,196 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:02,196 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:02,196 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:02,210 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:04,026 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:05,774 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:05,775 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:05,783 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:05.319038+00:00, run_end_date=2025-02-22 11:30:05.476759+00:00, run_duration=0.157721, state=success, executor_state=success, try_number=1, max_tries=1, job_id=840, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:02.194910+00:00, queued_by_job_id=7, pid=66826
2025-02-22 11:30:05,783 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:03.556557+00:00, run_end_date=2025-02-22 11:30:03.700938+00:00, run_duration=0.144381, state=success, executor_state=success, try_number=1, max_tries=1, job_id=839, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:02.194910+00:00, queued_by_job_id=7, pid=66807
2025-02-22 11:30:05,939 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-12T00:00:00+00:00, run_after=2024-09-13T00:00:00+00:00
2025-02-22 11:30:05,995 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-11 00:00:00+00:00: scheduled__2024-09-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:05,996 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-11 00:00:00+00:00, run_id=scheduled__2024-09-11T00:00:00+00:00, run_start_date=2025-02-22 11:29:50.412016+00:00, run_end_date=2025-02-22 11:30:05.995935+00:00, run_duration=15.583919, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-11 00:00:00+00:00, data_interval_end=2024-09-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:06,001 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-12T00:00:00+00:00, run_after=2024-09-13T00:00:00+00:00
2025-02-22 11:30:06,024 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:06,024 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:06,025 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:06,027 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:06,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:06,041 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:07,815 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:07,823 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:07.341264+00:00, run_end_date=2025-02-22 11:30:07.493131+00:00, run_duration=0.151867, state=success, executor_state=success, try_number=1, max_tries=1, job_id=841, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:06.025810+00:00, queued_by_job_id=7, pid=66846
2025-02-22 11:30:07,964 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-13T00:00:00+00:00, run_after=2024-09-14T00:00:00+00:00
2025-02-22 11:30:08,036 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:08,037 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:08,037 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:08,040 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:08,040 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:08,054 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:09,812 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:09,820 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:09.358367+00:00, run_end_date=2025-02-22 11:30:09.506763+00:00, run_duration=0.148396, state=success, executor_state=success, try_number=1, max_tries=1, job_id=842, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:08.038154+00:00, queued_by_job_id=7, pid=66866
2025-02-22 11:30:10,065 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-14T00:00:00+00:00, run_after=2024-09-15T00:00:00+00:00
2025-02-22 11:30:10,144 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:10,144 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:10,144 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:10,144 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:10,146 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:10,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:10,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:10,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:10,160 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:11,958 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:13,740 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:13,741 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:13,748 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:13.252549+00:00, run_end_date=2025-02-22 11:30:13.412234+00:00, run_duration=0.159685, state=success, executor_state=success, try_number=1, max_tries=1, job_id=844, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:10.145119+00:00, queued_by_job_id=7, pid=66904
2025-02-22 11:30:13,749 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:11.496513+00:00, run_end_date=2025-02-22 11:30:11.649059+00:00, run_duration=0.152546, state=success, executor_state=success, try_number=1, max_tries=1, job_id=843, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:10.145119+00:00, queued_by_job_id=7, pid=66886
2025-02-22 11:30:13,922 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-15T00:00:00+00:00, run_after=2024-09-16T00:00:00+00:00
2025-02-22 11:30:13,986 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-12 00:00:00+00:00: scheduled__2024-09-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:13,987 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-12 00:00:00+00:00, run_id=scheduled__2024-09-12T00:00:00+00:00, run_start_date=2025-02-22 11:30:02.136273+00:00, run_end_date=2025-02-22 11:30:13.987180+00:00, run_duration=11.850907, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-12 00:00:00+00:00, data_interval_end=2024-09-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:13,990 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-13T00:00:00+00:00, run_after=2024-09-14T00:00:00+00:00
2025-02-22 11:30:14,011 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:14,011 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:14,011 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:14,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:14,013 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:14,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:14,014 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:14,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:14,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:15,816 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:17,582 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:17,582 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:17,590 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:17.112681+00:00, run_end_date=2025-02-22 11:30:17.273979+00:00, run_duration=0.161298, state=success, executor_state=success, try_number=1, max_tries=1, job_id=846, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:14.012210+00:00, queued_by_job_id=7, pid=66951
2025-02-22 11:30:17,591 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:15.320485+00:00, run_end_date=2025-02-22 11:30:15.475002+00:00, run_duration=0.154517, state=success, executor_state=success, try_number=1, max_tries=1, job_id=845, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:14.012210+00:00, queued_by_job_id=7, pid=66925
2025-02-22 11:30:17,739 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-14T00:00:00+00:00, run_after=2024-09-15T00:00:00+00:00
2025-02-22 11:30:17,827 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:17,828 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:17,828 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:17,828 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:17,832 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:17,832 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:17,833 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:17,833 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:17,846 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:19,610 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:21,390 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:21,390 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:21,398 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:20.897365+00:00, run_end_date=2025-02-22 11:30:21.042084+00:00, run_duration=0.144719, state=success, executor_state=success, try_number=1, max_tries=1, job_id=848, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:17.829290+00:00, queued_by_job_id=7, pid=66990
2025-02-22 11:30:21,399 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:19.140737+00:00, run_end_date=2025-02-22 11:30:19.309259+00:00, run_duration=0.168522, state=success, executor_state=success, try_number=1, max_tries=1, job_id=847, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:17.829290+00:00, queued_by_job_id=7, pid=66971
2025-02-22 11:30:21,576 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-15T00:00:00+00:00, run_after=2024-09-16T00:00:00+00:00
2025-02-22 11:30:21,650 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:21,650 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:21,650 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:21,651 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:21,653 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:21,653 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:21,653 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:21,653 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:21,665 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:23,425 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:25,175 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:25,176 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:25,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:24.734632+00:00, run_end_date=2025-02-22 11:30:24.879945+00:00, run_duration=0.145313, state=success, executor_state=success, try_number=1, max_tries=1, job_id=850, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:21.651448+00:00, queued_by_job_id=7, pid=67029
2025-02-22 11:30:25,184 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:22.957577+00:00, run_end_date=2025-02-22 11:30:23.107928+00:00, run_duration=0.150351, state=success, executor_state=success, try_number=1, max_tries=1, job_id=849, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:21.651448+00:00, queued_by_job_id=7, pid=67010
2025-02-22 11:30:25,336 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-16T00:00:00+00:00, run_after=2024-09-17T00:00:00+00:00
2025-02-22 11:30:25,483 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-13 00:00:00+00:00: scheduled__2024-09-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:25,483 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-13 00:00:00+00:00, run_id=scheduled__2024-09-13T00:00:00+00:00, run_start_date=2025-02-22 11:30:10.092586+00:00, run_end_date=2025-02-22 11:30:25.483719+00:00, run_duration=15.391133, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-13 00:00:00+00:00, data_interval_end=2024-09-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:25,487 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-14T00:00:00+00:00, run_after=2024-09-15T00:00:00+00:00
2025-02-22 11:30:25,509 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:25,509 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:25,509 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:25,509 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:25,511 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:25,512 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:25,512 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:25,512 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:25,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:27,333 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:29,140 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:29,141 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:29,155 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:28.683230+00:00, run_end_date=2025-02-22 11:30:28.827385+00:00, run_duration=0.144155, state=success, executor_state=success, try_number=1, max_tries=1, job_id=852, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:25.510034+00:00, queued_by_job_id=7, pid=67083
2025-02-22 11:30:29,155 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:26.848027+00:00, run_end_date=2025-02-22 11:30:26.994896+00:00, run_duration=0.146869, state=success, executor_state=success, try_number=1, max_tries=1, job_id=851, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:25.510034+00:00, queued_by_job_id=7, pid=67057
2025-02-22 11:30:29,321 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-15T00:00:00+00:00, run_after=2024-09-16T00:00:00+00:00
2025-02-22 11:30:29,378 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-14 00:00:00+00:00: scheduled__2024-09-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:29,379 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-14 00:00:00+00:00, run_id=scheduled__2024-09-14T00:00:00+00:00, run_start_date=2025-02-22 11:30:13.950475+00:00, run_end_date=2025-02-22 11:30:29.379089+00:00, run_duration=15.428614, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-14 00:00:00+00:00, data_interval_end=2024-09-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:29,384 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-15T00:00:00+00:00, run_after=2024-09-16T00:00:00+00:00
2025-02-22 11:30:29,412 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:29,412 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:29,412 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:29,415 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:29,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:29,431 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:31,199 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:31,207 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:30.740587+00:00, run_end_date=2025-02-22 11:30:30.887648+00:00, run_duration=0.147061, state=success, executor_state=success, try_number=1, max_tries=1, job_id=853, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:29.413665+00:00, queued_by_job_id=7, pid=67103
2025-02-22 11:30:31,348 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-16T00:00:00+00:00, run_after=2024-09-17T00:00:00+00:00
2025-02-22 11:30:31,424 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:31,424 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:31,424 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:31,426 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:31,426 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:31,438 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:33,238 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:33,245 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:32.759919+00:00, run_end_date=2025-02-22 11:30:32.909476+00:00, run_duration=0.149557, state=success, executor_state=success, try_number=1, max_tries=1, job_id=854, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:31.425030+00:00, queued_by_job_id=7, pid=67123
2025-02-22 11:30:33,390 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-17T00:00:00+00:00, run_after=2024-09-18T00:00:00+00:00
2025-02-22 11:30:33,464 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:33,464 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:33,464 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:33,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:33,466 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:33,467 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:33,467 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:33,467 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:33,480 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:35,327 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:37,066 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:37,066 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:37,074 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:36.617438+00:00, run_end_date=2025-02-22 11:30:36.758594+00:00, run_duration=0.141156, state=success, executor_state=success, try_number=1, max_tries=1, job_id=856, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:33.465367+00:00, queued_by_job_id=7, pid=67163
2025-02-22 11:30:37,075 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:34.850826+00:00, run_end_date=2025-02-22 11:30:34.996161+00:00, run_duration=0.145335, state=success, executor_state=success, try_number=1, max_tries=1, job_id=855, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:33.465367+00:00, queued_by_job_id=7, pid=67144
2025-02-22 11:30:37,247 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-18T00:00:00+00:00, run_after=2024-09-19T00:00:00+00:00
2025-02-22 11:30:37,299 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-15 00:00:00+00:00: scheduled__2024-09-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:37,299 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-15 00:00:00+00:00, run_id=scheduled__2024-09-15T00:00:00+00:00, run_start_date=2025-02-22 11:30:25.439816+00:00, run_end_date=2025-02-22 11:30:37.299658+00:00, run_duration=11.859842, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-15 00:00:00+00:00, data_interval_end=2024-09-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:37,302 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-16T00:00:00+00:00, run_after=2024-09-17T00:00:00+00:00
2025-02-22 11:30:37,324 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:37,325 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:37,325 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:37,325 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:37,327 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:37,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:37,327 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:37,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:37,340 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:39,144 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:40,977 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:40,978 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:40,986 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:40.496620+00:00, run_end_date=2025-02-22 11:30:40.647481+00:00, run_duration=0.150861, state=success, executor_state=success, try_number=1, max_tries=1, job_id=858, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:37.325726+00:00, queued_by_job_id=7, pid=67201
2025-02-22 11:30:40,986 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:38.653425+00:00, run_end_date=2025-02-22 11:30:38.798669+00:00, run_duration=0.145244, state=success, executor_state=success, try_number=1, max_tries=1, job_id=857, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:37.325726+00:00, queued_by_job_id=7, pid=67183
2025-02-22 11:30:41,121 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-17T00:00:00+00:00, run_after=2024-09-18T00:00:00+00:00
2025-02-22 11:30:41,180 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:41,180 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:41,180 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:41,180 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:41,182 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:41,182 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:41,183 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:41,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:41,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:42,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:44,779 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:44,780 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:44,787 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:44.321655+00:00, run_end_date=2025-02-22 11:30:44.467320+00:00, run_duration=0.145665, state=success, executor_state=success, try_number=1, max_tries=1, job_id=860, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:41.180919+00:00, queued_by_job_id=7, pid=67240
2025-02-22 11:30:44,787 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:42.515530+00:00, run_end_date=2025-02-22 11:30:42.659255+00:00, run_duration=0.143725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=859, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:41.180919+00:00, queued_by_job_id=7, pid=67222
2025-02-22 11:30:44,952 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-18T00:00:00+00:00, run_after=2024-09-19T00:00:00+00:00
2025-02-22 11:30:45,036 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:45,037 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:45,037 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:45,037 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:45,041 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:45,041 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:45,042 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:45,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:45,053 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:46,853 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:48,636 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:48,636 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:48,644 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:48.159954+00:00, run_end_date=2025-02-22 11:30:48.320890+00:00, run_duration=0.160936, state=success, executor_state=success, try_number=1, max_tries=1, job_id=862, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:45.038288+00:00, queued_by_job_id=7, pid=67287
2025-02-22 11:30:48,644 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:46.370279+00:00, run_end_date=2025-02-22 11:30:46.516515+00:00, run_duration=0.146236, state=success, executor_state=success, try_number=1, max_tries=1, job_id=861, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:45.038288+00:00, queued_by_job_id=7, pid=67260
2025-02-22 11:30:48,800 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-19T00:00:00+00:00, run_after=2024-09-20T00:00:00+00:00
2025-02-22 11:30:48,852 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-16 00:00:00+00:00: scheduled__2024-09-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:48,852 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-16 00:00:00+00:00, run_id=scheduled__2024-09-16T00:00:00+00:00, run_start_date=2025-02-22 11:30:33.416949+00:00, run_end_date=2025-02-22 11:30:48.852272+00:00, run_duration=15.435323, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-16 00:00:00+00:00, data_interval_end=2024-09-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:48,855 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-17T00:00:00+00:00, run_after=2024-09-18T00:00:00+00:00
2025-02-22 11:30:48,874 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:48,875 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:48,875 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:48,875 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:48,877 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:48,877 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:48,877 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:48,877 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:48,890 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:50,681 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:52,494 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:52,495 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:52,500 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:52.030429+00:00, run_end_date=2025-02-22 11:30:52.185216+00:00, run_duration=0.154787, state=success, executor_state=success, try_number=1, max_tries=1, job_id=864, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:48.875598+00:00, queued_by_job_id=7, pid=67326
2025-02-22 11:30:52,500 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:50.212456+00:00, run_end_date=2025-02-22 11:30:50.358204+00:00, run_duration=0.145748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=863, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:48.875598+00:00, queued_by_job_id=7, pid=67307
2025-02-22 11:30:52,674 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-18T00:00:00+00:00, run_after=2024-09-19T00:00:00+00:00
2025-02-22 11:30:52,734 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-17 00:00:00+00:00: scheduled__2024-09-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:30:52,734 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-17 00:00:00+00:00, run_id=scheduled__2024-09-17T00:00:00+00:00, run_start_date=2025-02-22 11:30:37.268222+00:00, run_end_date=2025-02-22 11:30:52.734627+00:00, run_duration=15.466405, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-17 00:00:00+00:00, data_interval_end=2024-09-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:30:52,739 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-18T00:00:00+00:00, run_after=2024-09-19T00:00:00+00:00
2025-02-22 11:30:52,765 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:52,765 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:52,765 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:52,768 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:30:52,768 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:52,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:54,564 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:54,571 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:54.089946+00:00, run_end_date=2025-02-22 11:30:54.240358+00:00, run_duration=0.150412, state=success, executor_state=success, try_number=1, max_tries=1, job_id=865, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:30:52.766295+00:00, queued_by_job_id=7, pid=67346
2025-02-22 11:30:54,707 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-19T00:00:00+00:00, run_after=2024-09-20T00:00:00+00:00
2025-02-22 11:30:54,785 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:54,785 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:54,785 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:54,789 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:30:54,789 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:54,805 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:56,565 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:30:56,573 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:56.122763+00:00, run_end_date=2025-02-22 11:30:56.272703+00:00, run_duration=0.14994, state=success, executor_state=success, try_number=1, max_tries=1, job_id=866, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:30:54.786697+00:00, queued_by_job_id=7, pid=67366
2025-02-22 11:30:56,717 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-20T00:00:00+00:00, run_after=2024-09-21T00:00:00+00:00
2025-02-22 11:30:56,790 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:56,790 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:30:56,791 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:30:56,791 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:30:56,793 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:30:56,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:56,793 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:30:56,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:56,804 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:30:58,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:00,413 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:00,414 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:00,423 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:59.961595+00:00, run_end_date=2025-02-22 11:31:00.136591+00:00, run_duration=0.174996, state=success, executor_state=success, try_number=1, max_tries=1, job_id=868, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:30:56.791442+00:00, queued_by_job_id=7, pid=67412
2025-02-22 11:31:00,423 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:30:58.211947+00:00, run_end_date=2025-02-22 11:30:58.352661+00:00, run_duration=0.140714, state=success, executor_state=success, try_number=1, max_tries=1, job_id=867, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:30:56.791442+00:00, queued_by_job_id=7, pid=67394
2025-02-22 11:31:00,596 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-21T00:00:00+00:00, run_after=2024-09-22T00:00:00+00:00
2025-02-22 11:31:00,650 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-18 00:00:00+00:00: scheduled__2024-09-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:00,650 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-18 00:00:00+00:00, run_id=scheduled__2024-09-18T00:00:00+00:00, run_start_date=2025-02-22 11:30:48.822474+00:00, run_end_date=2025-02-22 11:31:00.650755+00:00, run_duration=11.828281, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-18 00:00:00+00:00, data_interval_end=2024-09-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:00,653 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-19T00:00:00+00:00, run_after=2024-09-20T00:00:00+00:00
2025-02-22 11:31:00,673 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:00,673 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:00,673 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:00,673 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:00,675 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:00,675 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:00,676 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:00,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:00,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:02,438 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:04,230 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:04,230 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:04,238 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:03.744528+00:00, run_end_date=2025-02-22 11:31:03.892171+00:00, run_duration=0.147643, state=success, executor_state=success, try_number=1, max_tries=1, job_id=870, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:00.674204+00:00, queued_by_job_id=7, pid=67451
2025-02-22 11:31:04,238 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:01.973358+00:00, run_end_date=2025-02-22 11:31:02.117609+00:00, run_duration=0.144251, state=success, executor_state=success, try_number=1, max_tries=1, job_id=869, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:00.674204+00:00, queued_by_job_id=7, pid=67432
2025-02-22 11:31:04,381 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-20T00:00:00+00:00, run_after=2024-09-21T00:00:00+00:00
2025-02-22 11:31:04,460 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:04,460 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:04,460 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:04,461 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:04,464 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:04,464 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:04,464 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:04,465 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:04,477 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:06,260 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:08,081 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:08,082 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:08,089 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:07.613162+00:00, run_end_date=2025-02-22 11:31:07.763390+00:00, run_duration=0.150228, state=success, executor_state=success, try_number=1, max_tries=1, job_id=872, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:04.461687+00:00, queued_by_job_id=7, pid=67498
2025-02-22 11:31:08,090 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:05.781440+00:00, run_end_date=2025-02-22 11:31:05.932930+00:00, run_duration=0.15149, state=success, executor_state=success, try_number=1, max_tries=1, job_id=871, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:04.461687+00:00, queued_by_job_id=7, pid=67472
2025-02-22 11:31:08,251 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-21T00:00:00+00:00, run_after=2024-09-22T00:00:00+00:00
2025-02-22 11:31:08,330 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:08,330 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:08,330 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:08,331 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:08,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:08,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:08,335 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:08,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:08,347 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:10,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:11,905 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:11,906 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:11,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:11.430478+00:00, run_end_date=2025-02-22 11:31:11.576900+00:00, run_duration=0.146422, state=success, executor_state=success, try_number=1, max_tries=1, job_id=874, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:08.331726+00:00, queued_by_job_id=7, pid=67536
2025-02-22 11:31:11,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:09.644826+00:00, run_end_date=2025-02-22 11:31:09.801641+00:00, run_duration=0.156815, state=success, executor_state=success, try_number=1, max_tries=1, job_id=873, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:08.331726+00:00, queued_by_job_id=7, pid=67518
2025-02-22 11:31:12,061 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-22T00:00:00+00:00, run_after=2024-09-23T00:00:00+00:00
2025-02-22 11:31:12,119 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-19 00:00:00+00:00: scheduled__2024-09-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:12,119 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-19 00:00:00+00:00, run_id=scheduled__2024-09-19T00:00:00+00:00, run_start_date=2025-02-22 11:30:56.743523+00:00, run_end_date=2025-02-22 11:31:12.119359+00:00, run_duration=15.375836, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-19 00:00:00+00:00, data_interval_end=2024-09-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:12,122 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-20T00:00:00+00:00, run_after=2024-09-21T00:00:00+00:00
2025-02-22 11:31:12,143 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:12,143 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:12,143 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:12,143 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:12,145 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:12,145 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:12,146 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:12,146 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:12,157 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:13,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:15,739 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:15,740 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:15,747 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:15.287887+00:00, run_end_date=2025-02-22 11:31:15.435978+00:00, run_duration=0.148091, state=success, executor_state=success, try_number=1, max_tries=1, job_id=876, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:12.144011+00:00, queued_by_job_id=7, pid=67576
2025-02-22 11:31:15,748 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:13.476202+00:00, run_end_date=2025-02-22 11:31:13.620458+00:00, run_duration=0.144256, state=success, executor_state=success, try_number=1, max_tries=1, job_id=875, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:12.144011+00:00, queued_by_job_id=7, pid=67557
2025-02-22 11:31:15,903 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-21T00:00:00+00:00, run_after=2024-09-22T00:00:00+00:00
2025-02-22 11:31:15,961 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-20 00:00:00+00:00: scheduled__2024-09-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:15,961 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-20 00:00:00+00:00, run_id=scheduled__2024-09-20T00:00:00+00:00, run_start_date=2025-02-22 11:31:00.620260+00:00, run_end_date=2025-02-22 11:31:15.961468+00:00, run_duration=15.341208, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-20 00:00:00+00:00, data_interval_end=2024-09-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:15,966 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-21T00:00:00+00:00, run_after=2024-09-22T00:00:00+00:00
2025-02-22 11:31:15,986 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:15,987 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:15,987 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:15,988 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:15,989 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:15,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:17,794 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:17,802 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:17.293546+00:00, run_end_date=2025-02-22 11:31:17.440624+00:00, run_duration=0.147078, state=success, executor_state=success, try_number=1, max_tries=1, job_id=877, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:15.987665+00:00, queued_by_job_id=7, pid=67595
2025-02-22 11:31:18,242 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-22T00:00:00+00:00, run_after=2024-09-23T00:00:00+00:00
2025-02-22 11:31:18,316 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:18,316 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:18,316 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:18,320 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:18,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:18,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:20,136 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:20,152 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:19.659291+00:00, run_end_date=2025-02-22 11:31:19.801491+00:00, run_duration=0.1422, state=success, executor_state=success, try_number=1, max_tries=1, job_id=878, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:18.317734+00:00, queued_by_job_id=7, pid=67631
2025-02-22 11:31:20,605 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-23T00:00:00+00:00, run_after=2024-09-24T00:00:00+00:00
2025-02-22 11:31:20,677 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:20,678 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:20,678 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:20,678 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:20,680 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:20,680 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:20,680 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:20,680 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:20,691 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:22,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:24,304 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:24,304 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:24,313 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:23.797021+00:00, run_end_date=2025-02-22 11:31:23.958061+00:00, run_duration=0.16104, state=success, executor_state=success, try_number=1, max_tries=1, job_id=880, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:20.678591+00:00, queued_by_job_id=7, pid=67679
2025-02-22 11:31:24,313 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:21.986041+00:00, run_end_date=2025-02-22 11:31:22.133584+00:00, run_duration=0.147543, state=success, executor_state=success, try_number=1, max_tries=1, job_id=879, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:20.678591+00:00, queued_by_job_id=7, pid=67660
2025-02-22 11:31:24,801 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-24T00:00:00+00:00, run_after=2024-09-25T00:00:00+00:00
2025-02-22 11:31:24,881 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-21 00:00:00+00:00: scheduled__2024-09-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:24,881 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-21 00:00:00+00:00, run_id=scheduled__2024-09-21T00:00:00+00:00, run_start_date=2025-02-22 11:31:12.087652+00:00, run_end_date=2025-02-22 11:31:24.881880+00:00, run_duration=12.794228, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-21 00:00:00+00:00, data_interval_end=2024-09-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:24,886 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-22T00:00:00+00:00, run_after=2024-09-23T00:00:00+00:00
2025-02-22 11:31:24,905 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:24,905 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:24,905 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:24,905 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:24,907 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:24,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:24,907 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:24,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:24,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:26,684 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:28,448 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:28,448 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:28,456 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:27.963365+00:00, run_end_date=2025-02-22 11:31:28.107065+00:00, run_duration=0.1437, state=success, executor_state=success, try_number=1, max_tries=1, job_id=882, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:24.905881+00:00, queued_by_job_id=7, pid=67734
2025-02-22 11:31:28,457 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:26.211713+00:00, run_end_date=2025-02-22 11:31:26.359005+00:00, run_duration=0.147292, state=success, executor_state=success, try_number=1, max_tries=1, job_id=881, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:24.905881+00:00, queued_by_job_id=7, pid=67707
2025-02-22 11:31:28,592 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-23T00:00:00+00:00, run_after=2024-09-24T00:00:00+00:00
2025-02-22 11:31:28,671 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:28,671 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:28,672 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:28,672 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:28,674 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:28,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:28,674 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:28,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:28,685 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:30,463 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:32,228 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:32,228 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:32,236 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:31.757395+00:00, run_end_date=2025-02-22 11:31:31.906555+00:00, run_duration=0.14916, state=success, executor_state=success, try_number=1, max_tries=1, job_id=884, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:28.672509+00:00, queued_by_job_id=7, pid=67772
2025-02-22 11:31:32,237 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:29.997087+00:00, run_end_date=2025-02-22 11:31:30.142841+00:00, run_duration=0.145754, state=success, executor_state=success, try_number=1, max_tries=1, job_id=883, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:28.672509+00:00, queued_by_job_id=7, pid=67753
2025-02-22 11:31:32,392 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-24T00:00:00+00:00, run_after=2024-09-25T00:00:00+00:00
2025-02-22 11:31:32,446 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:32,446 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:32,446 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:32,446 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:32,448 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:32,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:32,448 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:32,449 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:32,460 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:34,250 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:36,082 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:36,082 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:36,091 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:35.621054+00:00, run_end_date=2025-02-22 11:31:35.771282+00:00, run_duration=0.150228, state=success, executor_state=success, try_number=1, max_tries=1, job_id=886, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:32.446855+00:00, queued_by_job_id=7, pid=67812
2025-02-22 11:31:36,091 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:33.755708+00:00, run_end_date=2025-02-22 11:31:33.902958+00:00, run_duration=0.14725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=885, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:32.446855+00:00, queued_by_job_id=7, pid=67792
2025-02-22 11:31:36,246 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-25T00:00:00+00:00, run_after=2024-09-26T00:00:00+00:00
2025-02-22 11:31:36,298 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-22 00:00:00+00:00: scheduled__2024-09-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:36,298 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-22 00:00:00+00:00, run_id=scheduled__2024-09-22T00:00:00+00:00, run_start_date=2025-02-22 11:31:20.632263+00:00, run_end_date=2025-02-22 11:31:36.298837+00:00, run_duration=15.666574, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-22 00:00:00+00:00, data_interval_end=2024-09-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:36,301 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-23T00:00:00+00:00, run_after=2024-09-24T00:00:00+00:00
2025-02-22 11:31:36,324 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:36,324 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:36,324 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:36,324 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:36,326 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:36,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:36,326 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:36,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:36,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:38,102 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:39,852 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:39,853 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:39,861 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:39.391981+00:00, run_end_date=2025-02-22 11:31:39.537472+00:00, run_duration=0.145491, state=success, executor_state=success, try_number=1, max_tries=1, job_id=888, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:36.324727+00:00, queued_by_job_id=7, pid=67851
2025-02-22 11:31:39,861 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:37.637504+00:00, run_end_date=2025-02-22 11:31:37.780229+00:00, run_duration=0.142725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=887, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:36.324727+00:00, queued_by_job_id=7, pid=67832
2025-02-22 11:31:40,022 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-24T00:00:00+00:00, run_after=2024-09-25T00:00:00+00:00
2025-02-22 11:31:40,080 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-23 00:00:00+00:00: scheduled__2024-09-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:40,081 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-23 00:00:00+00:00, run_id=scheduled__2024-09-23T00:00:00+00:00, run_start_date=2025-02-22 11:31:24.827282+00:00, run_end_date=2025-02-22 11:31:40.081170+00:00, run_duration=15.253888, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-23 00:00:00+00:00, data_interval_end=2024-09-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:40,086 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-24T00:00:00+00:00, run_after=2024-09-25T00:00:00+00:00
2025-02-22 11:31:40,107 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:40,107 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:40,107 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:40,109 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:40,109 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:40,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:41,944 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:41,952 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:41.462215+00:00, run_end_date=2025-02-22 11:31:41.606514+00:00, run_duration=0.144299, state=success, executor_state=success, try_number=1, max_tries=1, job_id=889, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:40.108131+00:00, queued_by_job_id=7, pid=67870
2025-02-22 11:31:42,187 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-25T00:00:00+00:00, run_after=2024-09-26T00:00:00+00:00
2025-02-22 11:31:42,272 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:42,272 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:42,273 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:42,276 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:42,277 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:42,289 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:44,125 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:44,133 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:43.591524+00:00, run_end_date=2025-02-22 11:31:43.733215+00:00, run_duration=0.141691, state=success, executor_state=success, try_number=1, max_tries=1, job_id=890, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:42.274076+00:00, queued_by_job_id=7, pid=67890
2025-02-22 11:31:44,279 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-26T00:00:00+00:00, run_after=2024-09-27T00:00:00+00:00
2025-02-22 11:31:44,348 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:44,348 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:44,349 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:44,349 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:44,351 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:44,351 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:44,351 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:44,351 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:44,361 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:46,123 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:47,960 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:47,961 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:47,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:47.536184+00:00, run_end_date=2025-02-22 11:31:47.680496+00:00, run_duration=0.144312, state=success, executor_state=success, try_number=1, max_tries=1, job_id=892, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:44.349489+00:00, queued_by_job_id=7, pid=67937
2025-02-22 11:31:47,967 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:45.653199+00:00, run_end_date=2025-02-22 11:31:45.801496+00:00, run_duration=0.148297, state=success, executor_state=success, try_number=1, max_tries=1, job_id=891, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:44.349489+00:00, queued_by_job_id=7, pid=67911
2025-02-22 11:31:48,145 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-27T00:00:00+00:00, run_after=2024-09-28T00:00:00+00:00
2025-02-22 11:31:48,206 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-24 00:00:00+00:00: scheduled__2024-09-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:48,206 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-24 00:00:00+00:00, run_id=scheduled__2024-09-24T00:00:00+00:00, run_start_date=2025-02-22 11:31:36.268289+00:00, run_end_date=2025-02-22 11:31:48.206786+00:00, run_duration=11.938497, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-24 00:00:00+00:00, data_interval_end=2024-09-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:48,209 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-25T00:00:00+00:00, run_after=2024-09-26T00:00:00+00:00
2025-02-22 11:31:48,230 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:48,230 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:48,230 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:48,230 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:48,232 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:48,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:48,232 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:48,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:48,245 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:50,019 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:51,801 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:51,802 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:51,809 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:51.303193+00:00, run_end_date=2025-02-22 11:31:51.447254+00:00, run_duration=0.144061, state=success, executor_state=success, try_number=1, max_tries=1, job_id=894, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:48.230891+00:00, queued_by_job_id=7, pid=67976
2025-02-22 11:31:51,809 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:49.534145+00:00, run_end_date=2025-02-22 11:31:49.682192+00:00, run_duration=0.148047, state=success, executor_state=success, try_number=1, max_tries=1, job_id=893, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:48.230891+00:00, queued_by_job_id=7, pid=67957
2025-02-22 11:31:51,947 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-26T00:00:00+00:00, run_after=2024-09-27T00:00:00+00:00
2025-02-22 11:31:52,037 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:52,038 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:52,038 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:52,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:52,042 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:31:52,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:52,043 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:52,043 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:52,055 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:53,894 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:55,675 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:55,676 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:55,690 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:55.204165+00:00, run_end_date=2025-02-22 11:31:55.354129+00:00, run_duration=0.149964, state=success, executor_state=success, try_number=1, max_tries=1, job_id=896, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:52.039454+00:00, queued_by_job_id=7, pid=68015
2025-02-22 11:31:55,691 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:53.395531+00:00, run_end_date=2025-02-22 11:31:53.542616+00:00, run_duration=0.147085, state=success, executor_state=success, try_number=1, max_tries=1, job_id=895, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:31:52.039454+00:00, queued_by_job_id=7, pid=67996
2025-02-22 11:31:55,874 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-27T00:00:00+00:00, run_after=2024-09-28T00:00:00+00:00
2025-02-22 11:31:55,953 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:55,953 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:55,953 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:55,954 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:55,958 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:31:55,958 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:55,958 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:55,959 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:55,970 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:57,712 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:59,472 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:59,473 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:31:59,481 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:59.025704+00:00, run_end_date=2025-02-22 11:31:59.172275+00:00, run_duration=0.146571, state=success, executor_state=success, try_number=1, max_tries=1, job_id=898, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:55.954859+00:00, queued_by_job_id=7, pid=68061
2025-02-22 11:31:59,481 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:31:57.259856+00:00, run_end_date=2025-02-22 11:31:57.410894+00:00, run_duration=0.151038, state=success, executor_state=success, try_number=1, max_tries=1, job_id=897, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:31:55.954859+00:00, queued_by_job_id=7, pid=68043
2025-02-22 11:31:59,626 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-28T00:00:00+00:00, run_after=2024-09-29T00:00:00+00:00
2025-02-22 11:31:59,678 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-25 00:00:00+00:00: scheduled__2024-09-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:31:59,678 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-25 00:00:00+00:00, run_id=scheduled__2024-09-25T00:00:00+00:00, run_start_date=2025-02-22 11:31:44.304657+00:00, run_end_date=2025-02-22 11:31:59.678546+00:00, run_duration=15.373889, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-25 00:00:00+00:00, data_interval_end=2024-09-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:31:59,681 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-26T00:00:00+00:00, run_after=2024-09-27T00:00:00+00:00
2025-02-22 11:31:59,703 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:59,703 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:31:59,704 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:31:59,704 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:31:59,706 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:31:59,706 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:59,706 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:31:59,706 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:31:59,716 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:01,511 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:03,268 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:03,268 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:03,276 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:02.803241+00:00, run_end_date=2025-02-22 11:32:02.951422+00:00, run_duration=0.148181, state=success, executor_state=success, try_number=1, max_tries=1, job_id=900, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:31:59.704441+00:00, queued_by_job_id=7, pid=68100
2025-02-22 11:32:03,276 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:01.019639+00:00, run_end_date=2025-02-22 11:32:01.160925+00:00, run_duration=0.141286, state=success, executor_state=success, try_number=1, max_tries=1, job_id=899, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:31:59.704441+00:00, queued_by_job_id=7, pid=68081
2025-02-22 11:32:03,312 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:32:03,498 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-27T00:00:00+00:00, run_after=2024-09-28T00:00:00+00:00
2025-02-22 11:32:03,548 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-26 00:00:00+00:00: scheduled__2024-09-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:03,549 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-26 00:00:00+00:00, run_id=scheduled__2024-09-26T00:00:00+00:00, run_start_date=2025-02-22 11:31:48.171820+00:00, run_end_date=2025-02-22 11:32:03.548981+00:00, run_duration=15.377161, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-26 00:00:00+00:00, data_interval_end=2024-09-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:03,554 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-27T00:00:00+00:00, run_after=2024-09-28T00:00:00+00:00
2025-02-22 11:32:03,579 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:03,579 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:03,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:03,582 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:03,583 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:03,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:05,390 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:05,397 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:04.885034+00:00, run_end_date=2025-02-22 11:32:05.028211+00:00, run_duration=0.143177, state=success, executor_state=success, try_number=1, max_tries=1, job_id=901, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:03.580846+00:00, queued_by_job_id=7, pid=68120
2025-02-22 11:32:05,532 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-28T00:00:00+00:00, run_after=2024-09-29T00:00:00+00:00
2025-02-22 11:32:05,603 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:05,603 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:05,604 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:05,605 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:05,605 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:05,619 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:07,374 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:07,380 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:06.904796+00:00, run_end_date=2025-02-22 11:32:07.064267+00:00, run_duration=0.159471, state=success, executor_state=success, try_number=1, max_tries=1, job_id=902, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:05.604467+00:00, queued_by_job_id=7, pid=68140
2025-02-22 11:32:07,524 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-29T00:00:00+00:00, run_after=2024-09-30T00:00:00+00:00
2025-02-22 11:32:07,592 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:07,592 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:07,592 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:07,592 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:07,594 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:07,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:07,594 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:07,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:07,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:09,376 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:11,116 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:11,117 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:11,125 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:10.659615+00:00, run_end_date=2025-02-22 11:32:10.808334+00:00, run_duration=0.148719, state=success, executor_state=success, try_number=1, max_tries=1, job_id=904, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:07.592896+00:00, queued_by_job_id=7, pid=68187
2025-02-22 11:32:11,125 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:08.890749+00:00, run_end_date=2025-02-22 11:32:09.040295+00:00, run_duration=0.149546, state=success, executor_state=success, try_number=1, max_tries=1, job_id=903, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:07.592896+00:00, queued_by_job_id=7, pid=68168
2025-02-22 11:32:11,290 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-30T00:00:00+00:00, run_after=2024-10-01T00:00:00+00:00
2025-02-22 11:32:11,353 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-27 00:00:00+00:00: scheduled__2024-09-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:11,353 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-27 00:00:00+00:00, run_id=scheduled__2024-09-27T00:00:00+00:00, run_start_date=2025-02-22 11:31:59.651814+00:00, run_end_date=2025-02-22 11:32:11.353389+00:00, run_duration=11.701575, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-27 00:00:00+00:00, data_interval_end=2024-09-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:11,356 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-28T00:00:00+00:00, run_after=2024-09-29T00:00:00+00:00
2025-02-22 11:32:11,378 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:11,378 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:11,378 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:11,378 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:11,380 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:11,381 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:11,381 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:11,381 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:11,393 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:13,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:15,021 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:15,022 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:15,030 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:14.543377+00:00, run_end_date=2025-02-22 11:32:14.687168+00:00, run_duration=0.143791, state=success, executor_state=success, try_number=1, max_tries=1, job_id=906, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:11.379282+00:00, queued_by_job_id=7, pid=68225
2025-02-22 11:32:15,030 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:12.718125+00:00, run_end_date=2025-02-22 11:32:12.863637+00:00, run_duration=0.145512, state=success, executor_state=success, try_number=1, max_tries=1, job_id=905, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:11.379282+00:00, queued_by_job_id=7, pid=68206
2025-02-22 11:32:15,163 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-29T00:00:00+00:00, run_after=2024-09-30T00:00:00+00:00
2025-02-22 11:32:15,222 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:15,222 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:15,222 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:15,223 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:15,225 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:15,225 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:15,225 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:15,225 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:15,236 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:17,017 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:18,772 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:18,773 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:18,781 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:18.303905+00:00, run_end_date=2025-02-22 11:32:18.449821+00:00, run_duration=0.145916, state=success, executor_state=success, try_number=1, max_tries=1, job_id=908, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:15.223341+00:00, queued_by_job_id=7, pid=68272
2025-02-22 11:32:18,781 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:16.552853+00:00, run_end_date=2025-02-22 11:32:16.712061+00:00, run_duration=0.159208, state=success, executor_state=success, try_number=1, max_tries=1, job_id=907, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:15.223341+00:00, queued_by_job_id=7, pid=68246
2025-02-22 11:32:18,941 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-30T00:00:00+00:00, run_after=2024-10-01T00:00:00+00:00
2025-02-22 11:32:18,992 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:18,993 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:18,993 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:18,993 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:18,995 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:18,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:18,995 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:18,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:19,009 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:20,785 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:22,670 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:22,671 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:22,676 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:22.219434+00:00, run_end_date=2025-02-22 11:32:22.361825+00:00, run_duration=0.142391, state=success, executor_state=success, try_number=1, max_tries=1, job_id=910, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:18.993700+00:00, queued_by_job_id=7, pid=68311
2025-02-22 11:32:22,676 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:20.311055+00:00, run_end_date=2025-02-22 11:32:20.479449+00:00, run_duration=0.168394, state=success, executor_state=success, try_number=1, max_tries=1, job_id=909, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:18.993700+00:00, queued_by_job_id=7, pid=68292
2025-02-22 11:32:22,829 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-01T00:00:00+00:00, run_after=2024-10-02T00:00:00+00:00
2025-02-22 11:32:22,871 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-28 00:00:00+00:00: scheduled__2024-09-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:22,871 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-28 00:00:00+00:00, run_id=scheduled__2024-09-28T00:00:00+00:00, run_start_date=2025-02-22 11:32:07.553248+00:00, run_end_date=2025-02-22 11:32:22.871890+00:00, run_duration=15.318642, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-28 00:00:00+00:00, data_interval_end=2024-09-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:22,873 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-29T00:00:00+00:00, run_after=2024-09-30T00:00:00+00:00
2025-02-22 11:32:22,903 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:22,903 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:22,903 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:22,903 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:22,905 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:22,905 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:22,905 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:22,906 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:22,916 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:24,685 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:26,468 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-09-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:26,469 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:26,477 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:26.004706+00:00, run_end_date=2025-02-22 11:32:26.153597+00:00, run_duration=0.148891, state=success, executor_state=success, try_number=1, max_tries=1, job_id=912, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:22.903945+00:00, queued_by_job_id=7, pid=68351
2025-02-22 11:32:26,477 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-09-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:24.207837+00:00, run_end_date=2025-02-22 11:32:24.355878+00:00, run_duration=0.148041, state=success, executor_state=success, try_number=1, max_tries=1, job_id=911, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:22.903945+00:00, queued_by_job_id=7, pid=68331
2025-02-22 11:32:26,654 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-30T00:00:00+00:00, run_after=2024-10-01T00:00:00+00:00
2025-02-22 11:32:26,711 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-29 00:00:00+00:00: scheduled__2024-09-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:26,712 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-29 00:00:00+00:00, run_id=scheduled__2024-09-29T00:00:00+00:00, run_start_date=2025-02-22 11:32:11.318803+00:00, run_end_date=2025-02-22 11:32:26.712274+00:00, run_duration=15.393471, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-29 00:00:00+00:00, data_interval_end=2024-09-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:26,717 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-09-30T00:00:00+00:00, run_after=2024-10-01T00:00:00+00:00
2025-02-22 11:32:26,742 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:26,743 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:26,743 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:26,746 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:26,746 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:26,757 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:28,545 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-09-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:28,553 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-09-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:28.059197+00:00, run_end_date=2025-02-22 11:32:28.222007+00:00, run_duration=0.16281, state=success, executor_state=success, try_number=1, max_tries=1, job_id=913, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:26.743998+00:00, queued_by_job_id=7, pid=68371
2025-02-22 11:32:28,692 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-01T00:00:00+00:00, run_after=2024-10-02T00:00:00+00:00
2025-02-22 11:32:28,764 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:28,764 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:28,765 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:28,768 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:28,768 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:28,780 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:30,546 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-09-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:30,554 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-09-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:30.072939+00:00, run_end_date=2025-02-22 11:32:30.220546+00:00, run_duration=0.147607, state=success, executor_state=success, try_number=1, max_tries=1, job_id=914, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:28.765922+00:00, queued_by_job_id=7, pid=68391
2025-02-22 11:32:30,804 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-02T00:00:00+00:00, run_after=2024-10-03T00:00:00+00:00
2025-02-22 11:32:30,884 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:30,884 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:30,884 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:30,885 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-09-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:30,887 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:30,887 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:30,887 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-09-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:30,887 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:30,901 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:32,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-09-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:34,424 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:34,425 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-09-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:34,439 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-09-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:33.961416+00:00, run_end_date=2025-02-22 11:32:34.112392+00:00, run_duration=0.150976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=916, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:30.885446+00:00, queued_by_job_id=7, pid=68430
2025-02-22 11:32:34,439 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:32.201127+00:00, run_end_date=2025-02-22 11:32:32.352991+00:00, run_duration=0.151864, state=success, executor_state=success, try_number=1, max_tries=1, job_id=915, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:30.885446+00:00, queued_by_job_id=7, pid=68411
2025-02-22 11:32:34,620 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-03T00:00:00+00:00, run_after=2024-10-04T00:00:00+00:00
2025-02-22 11:32:34,674 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-09-30 00:00:00+00:00: scheduled__2024-09-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:34,675 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-09-30 00:00:00+00:00, run_id=scheduled__2024-09-30T00:00:00+00:00, run_start_date=2025-02-22 11:32:22.850301+00:00, run_end_date=2025-02-22 11:32:34.675073+00:00, run_duration=11.824772, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-09-30 00:00:00+00:00, data_interval_end=2024-10-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:34,678 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-01T00:00:00+00:00, run_after=2024-10-02T00:00:00+00:00
2025-02-22 11:32:34,702 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:34,702 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:34,702 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:34,702 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:34,704 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:34,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:34,704 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:34,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:34,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:36,530 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:38,337 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:38,338 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:38,347 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:37.869147+00:00, run_end_date=2025-02-22 11:32:38.015228+00:00, run_duration=0.146081, state=success, executor_state=success, try_number=1, max_tries=1, job_id=918, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:34.702817+00:00, queued_by_job_id=7, pid=68477
2025-02-22 11:32:38,347 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:36.040888+00:00, run_end_date=2025-02-22 11:32:36.195198+00:00, run_duration=0.15431, state=success, executor_state=success, try_number=1, max_tries=1, job_id=917, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:34.702817+00:00, queued_by_job_id=7, pid=68450
2025-02-22 11:32:38,490 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-02T00:00:00+00:00, run_after=2024-10-03T00:00:00+00:00
2025-02-22 11:32:38,548 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:38,548 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:38,549 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:38,549 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:38,551 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:38,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:38,551 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:38,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:38,562 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:40,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:42,101 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:42,102 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:42,116 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:41.628165+00:00, run_end_date=2025-02-22 11:32:41.774632+00:00, run_duration=0.146467, state=success, executor_state=success, try_number=1, max_tries=1, job_id=920, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:38.549477+00:00, queued_by_job_id=7, pid=68516
2025-02-22 11:32:42,117 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:39.861572+00:00, run_end_date=2025-02-22 11:32:40.007084+00:00, run_duration=0.145512, state=success, executor_state=success, try_number=1, max_tries=1, job_id=919, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:38.549477+00:00, queued_by_job_id=7, pid=68496
2025-02-22 11:32:42,275 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-03T00:00:00+00:00, run_after=2024-10-04T00:00:00+00:00
2025-02-22 11:32:42,332 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:42,332 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:42,332 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:42,332 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:42,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:42,334 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:42,335 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:42,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:42,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:44,115 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:45,862 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:45,863 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:45,872 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:45.408774+00:00, run_end_date=2025-02-22 11:32:45.553532+00:00, run_duration=0.144758, state=success, executor_state=success, try_number=1, max_tries=1, job_id=922, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:42.332987+00:00, queued_by_job_id=7, pid=68562
2025-02-22 11:32:45,873 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:43.632898+00:00, run_end_date=2025-02-22 11:32:43.797601+00:00, run_duration=0.164703, state=success, executor_state=success, try_number=1, max_tries=1, job_id=921, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:42.332987+00:00, queued_by_job_id=7, pid=68535
2025-02-22 11:32:46,019 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-04T00:00:00+00:00, run_after=2024-10-05T00:00:00+00:00
2025-02-22 11:32:46,073 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-01 00:00:00+00:00: scheduled__2024-10-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:46,073 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-01 00:00:00+00:00, run_id=scheduled__2024-10-01T00:00:00+00:00, run_start_date=2025-02-22 11:32:30.835480+00:00, run_end_date=2025-02-22 11:32:46.073678+00:00, run_duration=15.238198, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-01 00:00:00+00:00, data_interval_end=2024-10-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:46,076 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-02T00:00:00+00:00, run_after=2024-10-03T00:00:00+00:00
2025-02-22 11:32:46,096 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:46,096 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:46,096 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:46,096 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:46,098 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:46,098 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:46,098 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:46,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:46,109 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:47,891 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:49,594 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:49,595 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:49,603 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:49.170850+00:00, run_end_date=2025-02-22 11:32:49.334253+00:00, run_duration=0.163403, state=success, executor_state=success, try_number=1, max_tries=1, job_id=924, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:46.096990+00:00, queued_by_job_id=7, pid=68600
2025-02-22 11:32:49,603 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:47.407180+00:00, run_end_date=2025-02-22 11:32:47.563195+00:00, run_duration=0.156015, state=success, executor_state=success, try_number=1, max_tries=1, job_id=923, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:46.096990+00:00, queued_by_job_id=7, pid=68582
2025-02-22 11:32:49,772 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-03T00:00:00+00:00, run_after=2024-10-04T00:00:00+00:00
2025-02-22 11:32:49,823 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-02 00:00:00+00:00: scheduled__2024-10-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:49,823 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-02 00:00:00+00:00, run_id=scheduled__2024-10-02T00:00:00+00:00, run_start_date=2025-02-22 11:32:34.643713+00:00, run_end_date=2025-02-22 11:32:49.823848+00:00, run_duration=15.180135, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-02 00:00:00+00:00, data_interval_end=2024-10-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:49,829 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-03T00:00:00+00:00, run_after=2024-10-04T00:00:00+00:00
2025-02-22 11:32:49,854 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:49,854 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:49,854 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:49,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:49,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:49,869 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:51,650 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:51,658 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:51.170115+00:00, run_end_date=2025-02-22 11:32:51.334764+00:00, run_duration=0.164649, state=success, executor_state=success, try_number=1, max_tries=1, job_id=925, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:49.855563+00:00, queued_by_job_id=7, pid=68620
2025-02-22 11:32:51,794 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-04T00:00:00+00:00, run_after=2024-10-05T00:00:00+00:00
2025-02-22 11:32:51,864 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:51,865 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:51,865 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:51,868 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:32:51,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:51,880 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:53,677 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:53,685 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:53.174657+00:00, run_end_date=2025-02-22 11:32:53.325111+00:00, run_duration=0.150454, state=success, executor_state=success, try_number=1, max_tries=1, job_id=926, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:32:51.866156+00:00, queued_by_job_id=7, pid=68640
2025-02-22 11:32:53,831 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-05T00:00:00+00:00, run_after=2024-10-06T00:00:00+00:00
2025-02-22 11:32:53,907 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:53,907 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:53,907 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:53,907 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:53,910 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:53,910 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:53,910 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:32:53,910 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:53,921 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:55,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:57,405 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:57,405 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:32:57,413 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:56.960303+00:00, run_end_date=2025-02-22 11:32:57.105321+00:00, run_duration=0.145018, state=success, executor_state=success, try_number=1, max_tries=1, job_id=928, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:32:53.908184+00:00, queued_by_job_id=7, pid=68687
2025-02-22 11:32:57,413 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:55.211432+00:00, run_end_date=2025-02-22 11:32:55.359921+00:00, run_duration=0.148489, state=success, executor_state=success, try_number=1, max_tries=1, job_id=927, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:53.908184+00:00, queued_by_job_id=7, pid=68668
2025-02-22 11:32:57,790 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-06T00:00:00+00:00, run_after=2024-10-07T00:00:00+00:00
2025-02-22 11:32:57,844 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-03 00:00:00+00:00: scheduled__2024-10-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:32:57,844 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-03 00:00:00+00:00, run_id=scheduled__2024-10-03T00:00:00+00:00, run_start_date=2025-02-22 11:32:46.046175+00:00, run_end_date=2025-02-22 11:32:57.844557+00:00, run_duration=11.798382, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-03 00:00:00+00:00, data_interval_end=2024-10-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:32:57,847 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-04T00:00:00+00:00, run_after=2024-10-05T00:00:00+00:00
2025-02-22 11:32:57,867 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:57,867 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:32:57,867 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:32:57,867 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:32:57,869 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:32:57,869 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:57,869 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:32:57,870 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:57,882 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:32:59,714 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:01,462 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:01,463 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:01,471 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:00.992553+00:00, run_end_date=2025-02-22 11:33:01.150575+00:00, run_duration=0.158022, state=success, executor_state=success, try_number=1, max_tries=1, job_id=930, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:32:57.867980+00:00, queued_by_job_id=7, pid=68734
2025-02-22 11:33:01,471 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:32:59.232814+00:00, run_end_date=2025-02-22 11:32:59.382606+00:00, run_duration=0.149792, state=success, executor_state=success, try_number=1, max_tries=1, job_id=929, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:32:57.867980+00:00, queued_by_job_id=7, pid=68715
2025-02-22 11:33:01,812 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-05T00:00:00+00:00, run_after=2024-10-06T00:00:00+00:00
2025-02-22 11:33:01,891 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:01,891 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:01,892 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:01,892 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:01,894 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:01,894 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:01,894 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:01,894 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:01,906 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:03,671 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:05,417 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:05,418 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:05,426 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:04.946124+00:00, run_end_date=2025-02-22 11:33:05.087262+00:00, run_duration=0.141138, state=success, executor_state=success, try_number=1, max_tries=1, job_id=932, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:01.892522+00:00, queued_by_job_id=7, pid=68781
2025-02-22 11:33:05,426 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:03.200779+00:00, run_end_date=2025-02-22 11:33:03.347279+00:00, run_duration=0.1465, state=success, executor_state=success, try_number=1, max_tries=1, job_id=931, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:01.892522+00:00, queued_by_job_id=7, pid=68762
2025-02-22 11:33:05,891 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-07T00:00:00+00:00, run_after=2024-10-08T00:00:00+00:00
2025-02-22 11:33:05,966 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:05,966 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:05,966 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:05,966 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:05,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:05,968 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:05,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:05,969 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:05,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:05,969 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:05,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:05,980 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:07,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:09,519 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:11,271 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:11,272 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:11,272 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:11,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:10.793289+00:00, run_end_date=2025-02-22 11:33:10.949858+00:00, run_duration=0.156569, state=success, executor_state=success, try_number=1, max_tries=1, job_id=935, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:05.967136+00:00, queued_by_job_id=7, pid=68847
2025-02-22 11:33:11,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:09.060618+00:00, run_end_date=2025-02-22 11:33:09.215451+00:00, run_duration=0.154833, state=success, executor_state=success, try_number=1, max_tries=1, job_id=934, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:05.967136+00:00, queued_by_job_id=7, pid=68829
2025-02-22 11:33:11,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:07.277593+00:00, run_end_date=2025-02-22 11:33:07.421404+00:00, run_duration=0.143811, state=success, executor_state=success, try_number=1, max_tries=1, job_id=933, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:05.967136+00:00, queued_by_job_id=7, pid=68810
2025-02-22 11:33:11,453 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-08T00:00:00+00:00, run_after=2024-10-09T00:00:00+00:00
2025-02-22 11:33:11,518 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-04 00:00:00+00:00: scheduled__2024-10-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:11,518 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-04 00:00:00+00:00, run_id=scheduled__2024-10-04T00:00:00+00:00, run_start_date=2025-02-22 11:32:53.859020+00:00, run_end_date=2025-02-22 11:33:11.518327+00:00, run_duration=17.659307, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-04 00:00:00+00:00, data_interval_end=2024-10-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:11,521 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-05T00:00:00+00:00, run_after=2024-10-06T00:00:00+00:00
2025-02-22 11:33:11,542 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:11,542 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:11,542 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:11,542 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:11,542 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:11,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:11,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:11,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:11,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:11,545 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:11,545 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:11,558 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:13,318 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:15,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:16,913 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:16,913 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:16,913 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:16,921 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:16.459135+00:00, run_end_date=2025-02-22 11:33:16.604587+00:00, run_duration=0.145452, state=success, executor_state=success, try_number=1, max_tries=1, job_id=938, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:11.543298+00:00, queued_by_job_id=7, pid=68913
2025-02-22 11:33:16,922 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:14.622297+00:00, run_end_date=2025-02-22 11:33:14.773487+00:00, run_duration=0.15119, state=success, executor_state=success, try_number=1, max_tries=1, job_id=937, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:11.543298+00:00, queued_by_job_id=7, pid=68894
2025-02-22 11:33:16,922 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:12.864149+00:00, run_end_date=2025-02-22 11:33:13.013956+00:00, run_duration=0.149807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=936, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:11.543298+00:00, queued_by_job_id=7, pid=68876
2025-02-22 11:33:17,083 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-06T00:00:00+00:00, run_after=2024-10-07T00:00:00+00:00
2025-02-22 11:33:17,147 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-05 00:00:00+00:00: scheduled__2024-10-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:17,148 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-05 00:00:00+00:00, run_id=scheduled__2024-10-05T00:00:00+00:00, run_start_date=2025-02-22 11:32:57.813407+00:00, run_end_date=2025-02-22 11:33:17.148265+00:00, run_duration=19.334858, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-05 00:00:00+00:00, data_interval_end=2024-10-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:17,153 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-06T00:00:00+00:00, run_after=2024-10-07T00:00:00+00:00
2025-02-22 11:33:17,172 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:17,172 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:17,172 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:17,173 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:17,175 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:17,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:17,175 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:17,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:17,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:18,941 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:20,693 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:20,694 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:20,702 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:20.226958+00:00, run_end_date=2025-02-22 11:33:20.373151+00:00, run_duration=0.146193, state=success, executor_state=success, try_number=1, max_tries=1, job_id=940, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:17.173419+00:00, queued_by_job_id=7, pid=68951
2025-02-22 11:33:20,702 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:18.475935+00:00, run_end_date=2025-02-22 11:33:18.633881+00:00, run_duration=0.157946, state=success, executor_state=success, try_number=1, max_tries=1, job_id=939, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:17.173419+00:00, queued_by_job_id=7, pid=68933
2025-02-22 11:33:20,842 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-07T00:00:00+00:00, run_after=2024-10-08T00:00:00+00:00
2025-02-22 11:33:20,922 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:20,923 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:20,923 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:20,923 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:20,927 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:20,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:20,928 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:20,928 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:20,940 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:22,846 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:24,589 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:24,590 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:24,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:24.143594+00:00, run_end_date=2025-02-22 11:33:24.286133+00:00, run_duration=0.142539, state=success, executor_state=success, try_number=1, max_tries=1, job_id=942, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:20.924132+00:00, queued_by_job_id=7, pid=68998
2025-02-22 11:33:24,599 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:22.254180+00:00, run_end_date=2025-02-22 11:33:22.487673+00:00, run_duration=0.233493, state=success, executor_state=success, try_number=1, max_tries=1, job_id=941, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:20.924132+00:00, queued_by_job_id=7, pid=68980
2025-02-22 11:33:24,761 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-08T00:00:00+00:00, run_after=2024-10-09T00:00:00+00:00
2025-02-22 11:33:24,812 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-06 00:00:00+00:00: scheduled__2024-10-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:24,813 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-06 00:00:00+00:00, run_id=scheduled__2024-10-06T00:00:00+00:00, run_start_date=2025-02-22 11:33:05.913260+00:00, run_end_date=2025-02-22 11:33:24.813183+00:00, run_duration=18.899923, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-06 00:00:00+00:00, data_interval_end=2024-10-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:24,819 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-07T00:00:00+00:00, run_after=2024-10-08T00:00:00+00:00
2025-02-22 11:33:24,846 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:24,846 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:24,847 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:24,850 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:24,850 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:24,862 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:26,605 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:26,618 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:26.154779+00:00, run_end_date=2025-02-22 11:33:26.301416+00:00, run_duration=0.146637, state=success, executor_state=success, try_number=1, max_tries=1, job_id=943, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:24.847912+00:00, queued_by_job_id=7, pid=69018
2025-02-22 11:33:26,760 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-08T00:00:00+00:00, run_after=2024-10-09T00:00:00+00:00
2025-02-22 11:33:26,796 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-07 00:00:00+00:00: scheduled__2024-10-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:26,797 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-07 00:00:00+00:00, run_id=scheduled__2024-10-07T00:00:00+00:00, run_start_date=2025-02-22 11:33:11.480718+00:00, run_end_date=2025-02-22 11:33:26.797074+00:00, run_duration=15.316356, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-07 00:00:00+00:00, data_interval_end=2024-10-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:26,799 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-08T00:00:00+00:00, run_after=2024-10-09T00:00:00+00:00
2025-02-22 11:33:27,983 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-09T00:00:00+00:00, run_after=2024-10-10T00:00:00+00:00
2025-02-22 11:33:28,052 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:28,052 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:28,053 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:28,054 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:28,054 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:28,065 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:29,913 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:29,921 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:29.422169+00:00, run_end_date=2025-02-22 11:33:29.575133+00:00, run_duration=0.152964, state=success, executor_state=success, try_number=1, max_tries=1, job_id=944, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:28.053517+00:00, queued_by_job_id=7, pid=69040
2025-02-22 11:33:30,082 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-10T00:00:00+00:00, run_after=2024-10-11T00:00:00+00:00
2025-02-22 11:33:30,171 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:30,172 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:30,172 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:30,172 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:30,175 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:30,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:30,175 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:30,176 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:30,187 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:31,988 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:33,738 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:33,739 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:33,747 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:33.259008+00:00, run_end_date=2025-02-22 11:33:33.422577+00:00, run_duration=0.163569, state=success, executor_state=success, try_number=1, max_tries=1, job_id=946, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:30.172947+00:00, queued_by_job_id=7, pid=69087
2025-02-22 11:33:33,747 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:31.493748+00:00, run_end_date=2025-02-22 11:33:31.645184+00:00, run_duration=0.151436, state=success, executor_state=success, try_number=1, max_tries=1, job_id=945, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:30.172947+00:00, queued_by_job_id=7, pid=69060
2025-02-22 11:33:33,896 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-11T00:00:00+00:00, run_after=2024-10-12T00:00:00+00:00
2025-02-22 11:33:33,981 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:33,981 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:33,981 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:33,981 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:33,982 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:33,984 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:33,984 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:33,984 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:33,984 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:33,984 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:33,984 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:33,996 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:35,774 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:37,542 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:39,295 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:39,296 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:39,296 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:39,305 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:38.835654+00:00, run_end_date=2025-02-22 11:33:38.981760+00:00, run_duration=0.146106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=949, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:33.982396+00:00, queued_by_job_id=7, pid=69146
2025-02-22 11:33:39,305 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:37.052956+00:00, run_end_date=2025-02-22 11:33:37.203299+00:00, run_duration=0.150343, state=success, executor_state=success, try_number=1, max_tries=1, job_id=948, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:33.982396+00:00, queued_by_job_id=7, pid=69125
2025-02-22 11:33:39,305 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:35.291477+00:00, run_end_date=2025-02-22 11:33:35.439832+00:00, run_duration=0.148355, state=success, executor_state=success, try_number=1, max_tries=1, job_id=947, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:33.982396+00:00, queued_by_job_id=7, pid=69107
2025-02-22 11:33:39,476 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-12T00:00:00+00:00, run_after=2024-10-13T00:00:00+00:00
2025-02-22 11:33:39,581 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:39,581 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:39,581 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:39,581 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:39,581 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:33:39,582 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:39,584 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:39,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:39,584 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:39,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:39,584 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:39,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:39,585 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:39,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:39,595 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:41,366 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:43,130 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:44,932 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:46,694 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:46,695 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:46,695 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:46,695 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:46,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:46.229913+00:00, run_end_date=2025-02-22 11:33:46.387289+00:00, run_duration=0.157376, state=success, executor_state=success, try_number=1, max_tries=1, job_id=953, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:39.582364+00:00, queued_by_job_id=7, pid=69222
2025-02-22 11:33:46,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:44.466535+00:00, run_end_date=2025-02-22 11:33:44.640164+00:00, run_duration=0.173629, state=success, executor_state=success, try_number=1, max_tries=1, job_id=952, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:39.582364+00:00, queued_by_job_id=7, pid=69203
2025-02-22 11:33:46,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:42.652380+00:00, run_end_date=2025-02-22 11:33:42.795585+00:00, run_duration=0.143205, state=success, executor_state=success, try_number=1, max_tries=1, job_id=951, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:39.582364+00:00, queued_by_job_id=7, pid=69184
2025-02-22 11:33:46,704 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:40.896766+00:00, run_end_date=2025-02-22 11:33:41.059851+00:00, run_duration=0.163085, state=success, executor_state=success, try_number=1, max_tries=1, job_id=950, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:39.582364+00:00, queued_by_job_id=7, pid=69165
2025-02-22 11:33:46,975 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-13T00:00:00+00:00, run_after=2024-10-14T00:00:00+00:00
2025-02-22 11:33:47,041 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-08 00:00:00+00:00: scheduled__2024-10-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:47,041 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-08 00:00:00+00:00, run_id=scheduled__2024-10-08T00:00:00+00:00, run_start_date=2025-02-22 11:33:28.010249+00:00, run_end_date=2025-02-22 11:33:47.041340+00:00, run_duration=19.031091, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-08 00:00:00+00:00, data_interval_end=2024-10-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:47,044 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-09T00:00:00+00:00, run_after=2024-10-10T00:00:00+00:00
2025-02-22 11:33:47,066 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:47,066 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:47,066 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:47,066 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:47,066 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:33:47,066 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:47,069 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:33:47,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:47,069 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:47,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:47,069 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:47,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:47,070 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:47,070 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:47,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:48,857 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:51,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:52,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:54,804 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:54,804 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:54,804 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:54,804 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:33:54,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:54.292025+00:00, run_end_date=2025-02-22 11:33:54.441508+00:00, run_duration=0.149483, state=success, executor_state=success, try_number=1, max_tries=1, job_id=957, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:47.067313+00:00, queued_by_job_id=7, pid=69306
2025-02-22 11:33:54,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:52.490413+00:00, run_end_date=2025-02-22 11:33:52.642429+00:00, run_duration=0.152016, state=success, executor_state=success, try_number=1, max_tries=1, job_id=956, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:47.067313+00:00, queued_by_job_id=7, pid=69288
2025-02-22 11:33:54,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:50.667233+00:00, run_end_date=2025-02-22 11:33:50.824250+00:00, run_duration=0.157017, state=success, executor_state=success, try_number=1, max_tries=1, job_id=955, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:47.067313+00:00, queued_by_job_id=7, pid=69269
2025-02-22 11:33:54,811 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:48.380306+00:00, run_end_date=2025-02-22 11:33:48.526397+00:00, run_duration=0.146091, state=success, executor_state=success, try_number=1, max_tries=1, job_id=954, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:33:47.067313+00:00, queued_by_job_id=7, pid=69241
2025-02-22 11:33:54,980 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-10T00:00:00+00:00, run_after=2024-10-11T00:00:00+00:00
2025-02-22 11:33:55,043 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-09 00:00:00+00:00: scheduled__2024-10-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:33:55,044 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-09 00:00:00+00:00, run_id=scheduled__2024-10-09T00:00:00+00:00, run_start_date=2025-02-22 11:33:30.104802+00:00, run_end_date=2025-02-22 11:33:55.043980+00:00, run_duration=24.939178, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-09 00:00:00+00:00, data_interval_end=2024-10-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:33:55,050 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-10T00:00:00+00:00, run_after=2024-10-11T00:00:00+00:00
2025-02-22 11:33:55,075 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:55,075 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:33:55,075 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:33:55,075 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:33:55,076 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:33:55,079 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:33:55,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:55,079 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:33:55,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:55,079 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:33:55,080 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:55,091 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:56,938 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:33:58,694 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:00,451 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:00,452 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:00,452 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:00,460 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:59.998102+00:00, run_end_date=2025-02-22 11:34:00.144078+00:00, run_duration=0.145976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=960, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:33:55.076511+00:00, queued_by_job_id=7, pid=69372
2025-02-22 11:34:00,460 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:58.233668+00:00, run_end_date=2025-02-22 11:33:58.379640+00:00, run_duration=0.145972, state=success, executor_state=success, try_number=1, max_tries=1, job_id=959, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:33:55.076511+00:00, queued_by_job_id=7, pid=69345
2025-02-22 11:34:00,460 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:33:56.444434+00:00, run_end_date=2025-02-22 11:33:56.604789+00:00, run_duration=0.160355, state=success, executor_state=success, try_number=1, max_tries=1, job_id=958, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:33:55.076511+00:00, queued_by_job_id=7, pid=69326
2025-02-22 11:34:00,635 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-11T00:00:00+00:00, run_after=2024-10-12T00:00:00+00:00
2025-02-22 11:34:00,693 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-10 00:00:00+00:00: scheduled__2024-10-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:00,694 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-10 00:00:00+00:00, run_id=scheduled__2024-10-10T00:00:00+00:00, run_start_date=2025-02-22 11:33:33.923850+00:00, run_end_date=2025-02-22 11:34:00.694239+00:00, run_duration=26.770389, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-10 00:00:00+00:00, data_interval_end=2024-10-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:00,699 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-11T00:00:00+00:00, run_after=2024-10-12T00:00:00+00:00
2025-02-22 11:34:00,725 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:00,725 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:00,725 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:00,725 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:00,729 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:00,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:00,729 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:00,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:00,740 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:02,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:04,267 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:04,268 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:04,276 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:03.806135+00:00, run_end_date=2025-02-22 11:34:03.951450+00:00, run_duration=0.145315, state=success, executor_state=success, try_number=1, max_tries=1, job_id=962, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:00.726471+00:00, queued_by_job_id=7, pid=69410
2025-02-22 11:34:04,276 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:02.041561+00:00, run_end_date=2025-02-22 11:34:02.202319+00:00, run_duration=0.160758, state=success, executor_state=success, try_number=1, max_tries=1, job_id=961, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:00.726471+00:00, queued_by_job_id=7, pid=69391
2025-02-22 11:34:04,419 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-12T00:00:00+00:00, run_after=2024-10-13T00:00:00+00:00
2025-02-22 11:34:04,472 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-11 00:00:00+00:00: scheduled__2024-10-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:04,472 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-11 00:00:00+00:00, run_id=scheduled__2024-10-11T00:00:00+00:00, run_start_date=2025-02-22 11:33:39.502232+00:00, run_end_date=2025-02-22 11:34:04.472914+00:00, run_duration=24.970682, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-11 00:00:00+00:00, data_interval_end=2024-10-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:04,478 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-12T00:00:00+00:00, run_after=2024-10-13T00:00:00+00:00
2025-02-22 11:34:04,505 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:04,506 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:04,506 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:04,509 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:04,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:04,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:06,311 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:06,316 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:05.819194+00:00, run_end_date=2025-02-22 11:34:05.975553+00:00, run_duration=0.156359, state=success, executor_state=success, try_number=1, max_tries=1, job_id=963, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:04.507339+00:00, queued_by_job_id=7, pid=69430
2025-02-22 11:34:06,475 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-13T00:00:00+00:00, run_after=2024-10-14T00:00:00+00:00
2025-02-22 11:34:06,516 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-12 00:00:00+00:00: scheduled__2024-10-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:06,516 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-12 00:00:00+00:00, run_id=scheduled__2024-10-12T00:00:00+00:00, run_start_date=2025-02-22 11:33:47.000973+00:00, run_end_date=2025-02-22 11:34:06.516787+00:00, run_duration=19.515814, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-12 00:00:00+00:00, data_interval_end=2024-10-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:06,522 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-13T00:00:00+00:00, run_after=2024-10-14T00:00:00+00:00
2025-02-22 11:34:07,697 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-14T00:00:00+00:00, run_after=2024-10-15T00:00:00+00:00
2025-02-22 11:34:07,765 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:07,765 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:07,765 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:07,767 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:07,767 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:07,777 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:09,591 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:09,598 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:09.112439+00:00, run_end_date=2025-02-22 11:34:09.255662+00:00, run_duration=0.143223, state=success, executor_state=success, try_number=1, max_tries=1, job_id=964, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:07.765909+00:00, queued_by_job_id=7, pid=69461
2025-02-22 11:34:09,745 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-15T00:00:00+00:00, run_after=2024-10-16T00:00:00+00:00
2025-02-22 11:34:09,891 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:09,891 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:09,891 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:09,891 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:09,894 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:09,894 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:09,894 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:09,894 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:09,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:11,691 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:13,472 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:13,472 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:13,481 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:12.987737+00:00, run_end_date=2025-02-22 11:34:13.132367+00:00, run_duration=0.14463, state=success, executor_state=success, try_number=1, max_tries=1, job_id=966, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:09.892158+00:00, queued_by_job_id=7, pid=69499
2025-02-22 11:34:13,481 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:11.206880+00:00, run_end_date=2025-02-22 11:34:11.350780+00:00, run_duration=0.1439, state=success, executor_state=success, try_number=1, max_tries=1, job_id=965, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:09.892158+00:00, queued_by_job_id=7, pid=69480
2025-02-22 11:34:13,644 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-16T00:00:00+00:00, run_after=2024-10-17T00:00:00+00:00
2025-02-22 11:34:13,717 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:13,717 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:13,717 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:13,717 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:13,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:13,719 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:13,719 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:13,720 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:13,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:13,720 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:13,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:13,731 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:15,544 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:17,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:19,123 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:19,123 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:19,123 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:19,132 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:18.646754+00:00, run_end_date=2025-02-22 11:34:18.794635+00:00, run_duration=0.147881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=969, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:13.717912+00:00, queued_by_job_id=7, pid=69556
2025-02-22 11:34:19,132 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:16.863270+00:00, run_end_date=2025-02-22 11:34:17.019829+00:00, run_duration=0.156559, state=success, executor_state=success, try_number=1, max_tries=1, job_id=968, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:13.717912+00:00, queued_by_job_id=7, pid=69538
2025-02-22 11:34:19,132 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:15.047078+00:00, run_end_date=2025-02-22 11:34:15.209124+00:00, run_duration=0.162046, state=success, executor_state=success, try_number=1, max_tries=1, job_id=967, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:13.717912+00:00, queued_by_job_id=7, pid=69519
2025-02-22 11:34:19,305 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-17T00:00:00+00:00, run_after=2024-10-18T00:00:00+00:00
2025-02-22 11:34:19,388 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:19,388 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:19,388 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:19,388 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:19,389 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:34:19,389 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:19,391 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:19,391 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:19,391 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:19,391 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:19,391 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:19,391 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:19,392 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:19,392 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:19,404 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:21,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:23,035 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:24,814 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:26,603 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:26,603 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:26,604 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:26,604 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:26,612 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:26.112842+00:00, run_end_date=2025-02-22 11:34:26.268299+00:00, run_duration=0.155457, state=success, executor_state=success, try_number=1, max_tries=1, job_id=973, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:19.389442+00:00, queued_by_job_id=7, pid=69641
2025-02-22 11:34:26,613 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:24.341744+00:00, run_end_date=2025-02-22 11:34:24.484720+00:00, run_duration=0.142976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=972, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:19.389442+00:00, queued_by_job_id=7, pid=69622
2025-02-22 11:34:26,613 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:22.549433+00:00, run_end_date=2025-02-22 11:34:22.718237+00:00, run_duration=0.168804, state=success, executor_state=success, try_number=1, max_tries=1, job_id=971, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:19.389442+00:00, queued_by_job_id=7, pid=69603
2025-02-22 11:34:26,613 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:20.770313+00:00, run_end_date=2025-02-22 11:34:20.923479+00:00, run_duration=0.153166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=970, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:19.389442+00:00, queued_by_job_id=7, pid=69585
2025-02-22 11:34:26,784 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-18T00:00:00+00:00, run_after=2024-10-19T00:00:00+00:00
2025-02-22 11:34:26,834 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-13 00:00:00+00:00: scheduled__2024-10-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:26,834 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-13 00:00:00+00:00, run_id=scheduled__2024-10-13T00:00:00+00:00, run_start_date=2025-02-22 11:34:07.724142+00:00, run_end_date=2025-02-22 11:34:26.834216+00:00, run_duration=19.110074, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-13 00:00:00+00:00, data_interval_end=2024-10-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:26,836 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-14T00:00:00+00:00, run_after=2024-10-15T00:00:00+00:00
2025-02-22 11:34:26,855 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:26,855 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:26,855 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:26,855 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:26,855 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:34:26,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:26,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:26,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:26,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:26,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:26,857 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:26,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:26,858 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:26,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:26,868 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:28,673 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:30,458 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:32,263 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:34,013 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:34,013 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:34,014 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:34,014 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:34,022 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:33.556391+00:00, run_end_date=2025-02-22 11:34:33.702872+00:00, run_duration=0.146481, state=success, executor_state=success, try_number=1, max_tries=1, job_id=977, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:26.856144+00:00, queued_by_job_id=7, pid=69725
2025-02-22 11:34:34,022 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:31.806023+00:00, run_end_date=2025-02-22 11:34:31.972224+00:00, run_duration=0.166201, state=success, executor_state=success, try_number=1, max_tries=1, job_id=976, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:26.856144+00:00, queued_by_job_id=7, pid=69706
2025-02-22 11:34:34,022 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:29.970561+00:00, run_end_date=2025-02-22 11:34:30.114507+00:00, run_duration=0.143946, state=success, executor_state=success, try_number=1, max_tries=1, job_id=975, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:26.856144+00:00, queued_by_job_id=7, pid=69679
2025-02-22 11:34:34,023 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:28.192242+00:00, run_end_date=2025-02-22 11:34:28.335073+00:00, run_duration=0.142831, state=success, executor_state=success, try_number=1, max_tries=1, job_id=974, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:26.856144+00:00, queued_by_job_id=7, pid=69661
2025-02-22 11:34:34,201 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-15T00:00:00+00:00, run_after=2024-10-16T00:00:00+00:00
2025-02-22 11:34:34,269 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-14 00:00:00+00:00: scheduled__2024-10-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:34,270 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-14 00:00:00+00:00, run_id=scheduled__2024-10-14T00:00:00+00:00, run_start_date=2025-02-22 11:34:09.822826+00:00, run_end_date=2025-02-22 11:34:34.270226+00:00, run_duration=24.4474, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-14 00:00:00+00:00, data_interval_end=2024-10-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:34,274 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-15T00:00:00+00:00, run_after=2024-10-16T00:00:00+00:00
2025-02-22 11:34:34,299 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:34,299 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:34,300 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:34,300 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:34,300 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:34,303 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:34,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:34,304 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:34,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:34,304 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:34,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:34,318 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:36,194 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:37,984 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:39,718 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:39,719 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:39,719 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:39,729 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:39.280407+00:00, run_end_date=2025-02-22 11:34:39.433450+00:00, run_duration=0.153043, state=success, executor_state=success, try_number=1, max_tries=1, job_id=980, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:34.301023+00:00, queued_by_job_id=7, pid=69783
2025-02-22 11:34:39,730 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:37.514117+00:00, run_end_date=2025-02-22 11:34:37.668142+00:00, run_duration=0.154025, state=success, executor_state=success, try_number=1, max_tries=1, job_id=979, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:34.301023+00:00, queued_by_job_id=7, pid=69763
2025-02-22 11:34:39,730 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:35.685979+00:00, run_end_date=2025-02-22 11:34:35.833643+00:00, run_duration=0.147664, state=success, executor_state=success, try_number=1, max_tries=1, job_id=978, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:34.301023+00:00, queued_by_job_id=7, pid=69744
2025-02-22 11:34:39,889 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-16T00:00:00+00:00, run_after=2024-10-17T00:00:00+00:00
2025-02-22 11:34:39,950 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-15 00:00:00+00:00: scheduled__2024-10-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:39,951 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-15 00:00:00+00:00, run_id=scheduled__2024-10-15T00:00:00+00:00, run_start_date=2025-02-22 11:34:13.666899+00:00, run_end_date=2025-02-22 11:34:39.951002+00:00, run_duration=26.284103, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-15 00:00:00+00:00, data_interval_end=2024-10-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:39,955 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-16T00:00:00+00:00, run_after=2024-10-17T00:00:00+00:00
2025-02-22 11:34:39,981 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:39,982 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:39,982 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:39,982 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:39,985 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:39,985 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:39,986 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:39,986 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:39,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:41,808 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:43,594 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:43,595 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:43,604 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:43.149367+00:00, run_end_date=2025-02-22 11:34:43.304352+00:00, run_duration=0.154985, state=success, executor_state=success, try_number=1, max_tries=1, job_id=982, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:39.982950+00:00, queued_by_job_id=7, pid=69829
2025-02-22 11:34:43,604 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:41.300866+00:00, run_end_date=2025-02-22 11:34:41.443871+00:00, run_duration=0.143005, state=success, executor_state=success, try_number=1, max_tries=1, job_id=981, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:39.982950+00:00, queued_by_job_id=7, pid=69802
2025-02-22 11:34:43,748 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-17T00:00:00+00:00, run_after=2024-10-18T00:00:00+00:00
2025-02-22 11:34:43,792 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-16 00:00:00+00:00: scheduled__2024-10-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:43,793 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-16 00:00:00+00:00, run_id=scheduled__2024-10-16T00:00:00+00:00, run_start_date=2025-02-22 11:34:19.333966+00:00, run_end_date=2025-02-22 11:34:43.793380+00:00, run_duration=24.459414, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-16 00:00:00+00:00, data_interval_end=2024-10-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:43,799 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-17T00:00:00+00:00, run_after=2024-10-18T00:00:00+00:00
2025-02-22 11:34:43,822 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:43,822 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:43,822 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:43,825 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:43,825 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:43,836 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:45,684 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:45,691 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:45.208955+00:00, run_end_date=2025-02-22 11:34:45.354186+00:00, run_duration=0.145231, state=success, executor_state=success, try_number=1, max_tries=1, job_id=983, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:43.823370+00:00, queued_by_job_id=7, pid=69848
2025-02-22 11:34:45,855 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-18T00:00:00+00:00, run_after=2024-10-19T00:00:00+00:00
2025-02-22 11:34:45,894 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-17 00:00:00+00:00: scheduled__2024-10-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:34:45,899 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-17 00:00:00+00:00, run_id=scheduled__2024-10-17T00:00:00+00:00, run_start_date=2025-02-22 11:34:26.805482+00:00, run_end_date=2025-02-22 11:34:45.899061+00:00, run_duration=19.093579, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-17 00:00:00+00:00, data_interval_end=2024-10-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:34:45,904 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-18T00:00:00+00:00, run_after=2024-10-19T00:00:00+00:00
2025-02-22 11:34:47,078 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-19T00:00:00+00:00, run_after=2024-10-20T00:00:00+00:00
2025-02-22 11:34:47,149 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:47,150 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:47,150 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:47,151 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:47,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:47,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:49,014 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:49,022 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:48.469504+00:00, run_end_date=2025-02-22 11:34:48.663244+00:00, run_duration=0.19374, state=success, executor_state=success, try_number=1, max_tries=1, job_id=984, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:47.150576+00:00, queued_by_job_id=7, pid=69871
2025-02-22 11:34:49,169 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-20T00:00:00+00:00, run_after=2024-10-21T00:00:00+00:00
2025-02-22 11:34:49,243 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:49,243 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:49,243 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:49,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:49,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:49,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:49,246 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:49,246 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:49,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:51,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:52,861 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:52,862 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:52,875 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:52.394836+00:00, run_end_date=2025-02-22 11:34:52.540036+00:00, run_duration=0.1452, state=success, executor_state=success, try_number=1, max_tries=1, job_id=986, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:49.244313+00:00, queued_by_job_id=7, pid=69918
2025-02-22 11:34:52,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:50.563868+00:00, run_end_date=2025-02-22 11:34:50.705740+00:00, run_duration=0.141872, state=success, executor_state=success, try_number=1, max_tries=1, job_id=985, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:49.244313+00:00, queued_by_job_id=7, pid=69891
2025-02-22 11:34:53,058 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-21T00:00:00+00:00, run_after=2024-10-22T00:00:00+00:00
2025-02-22 11:34:53,134 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:53,134 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:53,134 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:53,134 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:53,134 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:53,137 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:53,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:53,137 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:53,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:53,137 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:53,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:53,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:54,908 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:56,758 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:58,520 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:58,521 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:58,521 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:34:58,529 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:58.047706+00:00, run_end_date=2025-02-22 11:34:58.195509+00:00, run_duration=0.147803, state=success, executor_state=success, try_number=1, max_tries=1, job_id=989, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:53.135256+00:00, queued_by_job_id=7, pid=69975
2025-02-22 11:34:58,529 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:56.261425+00:00, run_end_date=2025-02-22 11:34:56.406685+00:00, run_duration=0.14526, state=success, executor_state=success, try_number=1, max_tries=1, job_id=988, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:53.135256+00:00, queued_by_job_id=7, pid=69956
2025-02-22 11:34:58,530 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:34:54.438739+00:00, run_end_date=2025-02-22 11:34:54.584909+00:00, run_duration=0.14617, state=success, executor_state=success, try_number=1, max_tries=1, job_id=987, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:53.135256+00:00, queued_by_job_id=7, pid=69938
2025-02-22 11:34:58,704 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-22T00:00:00+00:00, run_after=2024-10-23T00:00:00+00:00
2025-02-22 11:34:58,789 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:58,789 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:34:58,790 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:34:58,790 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:34:58,790 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:34:58,790 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:34:58,792 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:34:58,792 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:58,792 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:34:58,792 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:58,793 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:34:58,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:58,793 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:34:58,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:34:58,805 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:00,614 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:02,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:04,183 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:06,026 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:06,027 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:06,027 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:06,028 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:06,035 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:05.538346+00:00, run_end_date=2025-02-22 11:35:05.686073+00:00, run_duration=0.147727, state=success, executor_state=success, try_number=1, max_tries=1, job_id=993, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:34:58.790687+00:00, queued_by_job_id=7, pid=70058
2025-02-22 11:35:06,036 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:03.698384+00:00, run_end_date=2025-02-22 11:35:03.842482+00:00, run_duration=0.144098, state=success, executor_state=success, try_number=1, max_tries=1, job_id=992, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:34:58.790687+00:00, queued_by_job_id=7, pid=70032
2025-02-22 11:35:06,036 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:01.925843+00:00, run_end_date=2025-02-22 11:35:02.066344+00:00, run_duration=0.140501, state=success, executor_state=success, try_number=1, max_tries=1, job_id=991, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:34:58.790687+00:00, queued_by_job_id=7, pid=70014
2025-02-22 11:35:06,036 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:00.143253+00:00, run_end_date=2025-02-22 11:35:00.299225+00:00, run_duration=0.155972, state=success, executor_state=success, try_number=1, max_tries=1, job_id=990, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:34:58.790687+00:00, queued_by_job_id=7, pid=69995
2025-02-22 11:35:06,500 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-23T00:00:00+00:00, run_after=2024-10-24T00:00:00+00:00
2025-02-22 11:35:06,566 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-18 00:00:00+00:00: scheduled__2024-10-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:06,567 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-18 00:00:00+00:00, run_id=scheduled__2024-10-18T00:00:00+00:00, run_start_date=2025-02-22 11:34:47.105204+00:00, run_end_date=2025-02-22 11:35:06.567069+00:00, run_duration=19.461865, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-18 00:00:00+00:00, data_interval_end=2024-10-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:06,570 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-19T00:00:00+00:00, run_after=2024-10-20T00:00:00+00:00
2025-02-22 11:35:06,593 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:06,593 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:06,594 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:06,594 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:06,594 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:35:06,594 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:06,596 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:06,596 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:06,596 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:06,596 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:06,597 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:06,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:06,597 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:06,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:06,608 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:08,407 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:10,165 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:11,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:13,716 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:13,717 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:13,717 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:13,717 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:13,726 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:13.244108+00:00, run_end_date=2025-02-22 11:35:13.390521+00:00, run_duration=0.146413, state=success, executor_state=success, try_number=1, max_tries=1, job_id=997, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:06.594641+00:00, queued_by_job_id=7, pid=70145
2025-02-22 11:35:13,727 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:11.461175+00:00, run_end_date=2025-02-22 11:35:11.604628+00:00, run_duration=0.143453, state=success, executor_state=success, try_number=1, max_tries=1, job_id=996, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:06.594641+00:00, queued_by_job_id=7, pid=70126
2025-02-22 11:35:13,727 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:09.689851+00:00, run_end_date=2025-02-22 11:35:09.830069+00:00, run_duration=0.140218, state=success, executor_state=success, try_number=1, max_tries=1, job_id=995, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:06.594641+00:00, queued_by_job_id=7, pid=70108
2025-02-22 11:35:13,727 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:07.921498+00:00, run_end_date=2025-02-22 11:35:08.073389+00:00, run_duration=0.151891, state=success, executor_state=success, try_number=1, max_tries=1, job_id=994, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:06.594641+00:00, queued_by_job_id=7, pid=70087
2025-02-22 11:35:14,192 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-20T00:00:00+00:00, run_after=2024-10-21T00:00:00+00:00
2025-02-22 11:35:14,258 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-19 00:00:00+00:00: scheduled__2024-10-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:14,258 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-19 00:00:00+00:00, run_id=scheduled__2024-10-19T00:00:00+00:00, run_start_date=2025-02-22 11:34:49.195798+00:00, run_end_date=2025-02-22 11:35:14.258446+00:00, run_duration=25.062648, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-19 00:00:00+00:00, data_interval_end=2024-10-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:14,263 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-20T00:00:00+00:00, run_after=2024-10-21T00:00:00+00:00
2025-02-22 11:35:14,289 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:14,290 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:14,290 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:14,290 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:14,290 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:14,294 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:14,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:14,294 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:14,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:14,295 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:14,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:14,307 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:16,100 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:17,851 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:19,677 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:19,677 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:19,677 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:19,686 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:19.223026+00:00, run_end_date=2025-02-22 11:35:19.389569+00:00, run_duration=0.166543, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1000, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:14.291249+00:00, queued_by_job_id=7, pid=70219
2025-02-22 11:35:19,686 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:17.380774+00:00, run_end_date=2025-02-22 11:35:17.544685+00:00, run_duration=0.163911, state=success, executor_state=success, try_number=1, max_tries=1, job_id=999, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:14.291249+00:00, queued_by_job_id=7, pid=70199
2025-02-22 11:35:19,687 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:15.618673+00:00, run_end_date=2025-02-22 11:35:15.766826+00:00, run_duration=0.148153, state=success, executor_state=success, try_number=1, max_tries=1, job_id=998, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:14.291249+00:00, queued_by_job_id=7, pid=70180
2025-02-22 11:35:20,154 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
2025-02-22 11:35:20,209 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-20 00:00:00+00:00: scheduled__2024-10-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:20,210 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-20 00:00:00+00:00, run_id=scheduled__2024-10-20T00:00:00+00:00, run_start_date=2025-02-22 11:34:53.080764+00:00, run_end_date=2025-02-22 11:35:20.210186+00:00, run_duration=27.129422, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-20 00:00:00+00:00, data_interval_end=2024-10-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:20,213 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-21T00:00:00+00:00, run_after=2024-10-22T00:00:00+00:00
2025-02-22 11:35:20,238 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:20,238 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:20,238 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:20,238 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:20,238 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:20,241 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:20,241 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:20,241 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:20,241 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:20,241 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:20,241 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:20,252 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:22,110 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:23,914 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:25,659 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:25,659 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:25,659 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:25,668 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:25.220286+00:00, run_end_date=2025-02-22 11:35:25.364042+00:00, run_duration=0.143756, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1003, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:20.239210+00:00, queued_by_job_id=7, pid=70293
2025-02-22 11:35:25,668 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:23.402415+00:00, run_end_date=2025-02-22 11:35:23.549369+00:00, run_duration=0.146954, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1002, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:20.239210+00:00, queued_by_job_id=7, pid=70266
2025-02-22 11:35:25,668 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:21.638576+00:00, run_end_date=2025-02-22 11:35:21.799366+00:00, run_duration=0.16079, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1001, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:20.239210+00:00, queued_by_job_id=7, pid=70247
2025-02-22 11:35:25,832 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-22T00:00:00+00:00, run_after=2024-10-23T00:00:00+00:00
2025-02-22 11:35:25,885 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-21 00:00:00+00:00: scheduled__2024-10-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:25,886 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-21 00:00:00+00:00, run_id=scheduled__2024-10-21T00:00:00+00:00, run_start_date=2025-02-22 11:34:58.731149+00:00, run_end_date=2025-02-22 11:35:25.886133+00:00, run_duration=27.154984, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-21 00:00:00+00:00, data_interval_end=2024-10-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:25,890 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-22T00:00:00+00:00, run_after=2024-10-23T00:00:00+00:00
2025-02-22 11:35:25,914 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:25,915 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:25,915 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:25,915 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:25,918 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:25,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:25,919 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:25,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:25,930 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:27,742 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:29,558 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:29,559 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:29,567 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:29.080956+00:00, run_end_date=2025-02-22 11:35:29.231062+00:00, run_duration=0.150106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1005, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:25.916197+00:00, queued_by_job_id=7, pid=70333
2025-02-22 11:35:29,568 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:27.267762+00:00, run_end_date=2025-02-22 11:35:27.425411+00:00, run_duration=0.157649, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1004, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:25.916197+00:00, queued_by_job_id=7, pid=70312
2025-02-22 11:35:29,705 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-23T00:00:00+00:00, run_after=2024-10-24T00:00:00+00:00
2025-02-22 11:35:29,777 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-22 00:00:00+00:00: scheduled__2024-10-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:29,778 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-22 00:00:00+00:00, run_id=scheduled__2024-10-22T00:00:00+00:00, run_start_date=2025-02-22 11:35:06.527867+00:00, run_end_date=2025-02-22 11:35:29.778010+00:00, run_duration=23.250143, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-22 00:00:00+00:00, data_interval_end=2024-10-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:29,783 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-23T00:00:00+00:00, run_after=2024-10-24T00:00:00+00:00
2025-02-22 11:35:29,807 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:29,807 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:29,807 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:29,809 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:29,809 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:29,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:31,703 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:31,711 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:31.154310+00:00, run_end_date=2025-02-22 11:35:31.365521+00:00, run_duration=0.211211, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1006, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:29.808134+00:00, queued_by_job_id=7, pid=70352
2025-02-22 11:35:31,875 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
2025-02-22 11:35:31,926 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:31,927 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:31,927 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:31,930 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:31,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:31,941 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:33,732 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:33,740 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:33.273741+00:00, run_end_date=2025-02-22 11:35:33.414905+00:00, run_duration=0.141164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1007, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:31.928078+00:00, queued_by_job_id=7, pid=70372
2025-02-22 11:35:33,884 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
2025-02-22 11:35:33,936 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-23 00:00:00+00:00: scheduled__2024-10-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:33,936 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-23 00:00:00+00:00, run_id=scheduled__2024-10-23T00:00:00+00:00, run_start_date=2025-02-22 11:35:20.176394+00:00, run_end_date=2025-02-22 11:35:33.936792+00:00, run_duration=13.760398, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-23 00:00:00+00:00, data_interval_end=2024-10-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:33,939 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-24T00:00:00+00:00, run_after=2024-10-25T00:00:00+00:00
2025-02-22 11:35:33,966 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:33,966 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:33,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:33,968 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:33,968 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:33,977 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:35,768 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:35,776 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:35.273487+00:00, run_end_date=2025-02-22 11:35:35.443208+00:00, run_duration=0.169721, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1008, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:33.967084+00:00, queued_by_job_id=7, pid=70392
2025-02-22 11:35:35,918 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
2025-02-22 11:35:35,996 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:35,997 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:35,997 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:36,001 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:36,001 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:36,013 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:37,862 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:37,868 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:37.404919+00:00, run_end_date=2025-02-22 11:35:37.559026+00:00, run_duration=0.154107, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1009, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:35.998532+00:00, queued_by_job_id=7, pid=70412
2025-02-22 11:35:38,050 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-26T00:00:00+00:00, run_after=2024-10-27T00:00:00+00:00
2025-02-22 11:35:38,144 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:38,144 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:38,144 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:38,144 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:38,146 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:38,146 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:38,147 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:38,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:38,158 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:39,949 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:41,711 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:41,712 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:41,718 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:41.238855+00:00, run_end_date=2025-02-22 11:35:41.384096+00:00, run_duration=0.145241, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1011, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:38.144964+00:00, queued_by_job_id=7, pid=70460
2025-02-22 11:35:41,718 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:39.471527+00:00, run_end_date=2025-02-22 11:35:39.632082+00:00, run_duration=0.160555, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1010, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:38.144964+00:00, queued_by_job_id=7, pid=70433
2025-02-22 11:35:41,864 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-27T00:00:00+00:00, run_after=2024-10-28T00:00:00+00:00
2025-02-22 11:35:41,941 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:41,941 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:41,941 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:41,941 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:41,941 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:41,943 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:41,944 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:41,944 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:41,944 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:41,944 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:41,944 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:41,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:43,739 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:45,515 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:47,272 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:47,272 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:47,272 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:47,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:46.798128+00:00, run_end_date=2025-02-22 11:35:46.940604+00:00, run_duration=0.142476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1014, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:41.942252+00:00, queued_by_job_id=7, pid=70517
2025-02-22 11:35:47,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:45.025193+00:00, run_end_date=2025-02-22 11:35:45.178981+00:00, run_duration=0.153788, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1013, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:41.942252+00:00, queued_by_job_id=7, pid=70499
2025-02-22 11:35:47,280 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:43.247710+00:00, run_end_date=2025-02-22 11:35:43.398476+00:00, run_duration=0.150766, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1012, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:41.942252+00:00, queued_by_job_id=7, pid=70479
2025-02-22 11:35:47,448 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-28T00:00:00+00:00, run_after=2024-10-29T00:00:00+00:00
2025-02-22 11:35:47,503 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-24 00:00:00+00:00: scheduled__2024-10-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:47,503 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-24 00:00:00+00:00, run_id=scheduled__2024-10-24T00:00:00+00:00, run_start_date=2025-02-22 11:35:33.909481+00:00, run_end_date=2025-02-22 11:35:47.503889+00:00, run_duration=13.594408, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-24 00:00:00+00:00, data_interval_end=2024-10-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:47,506 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-25T00:00:00+00:00, run_after=2024-10-26T00:00:00+00:00
2025-02-22 11:35:47,527 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:47,527 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:47,527 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:47,527 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:47,527 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:47,530 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:35:47,530 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:47,530 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:47,530 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:47,530 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:47,530 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:47,543 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:49,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:51,075 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:52,842 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:52,842 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:52,842 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:52,848 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:52.377565+00:00, run_end_date=2025-02-22 11:35:52.526824+00:00, run_duration=0.149259, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1017, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:47.528275+00:00, queued_by_job_id=7, pid=70582
2025-02-22 11:35:52,848 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:50.609201+00:00, run_end_date=2025-02-22 11:35:50.776514+00:00, run_duration=0.167313, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1016, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:47.528275+00:00, queued_by_job_id=7, pid=70564
2025-02-22 11:35:52,848 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:48.834922+00:00, run_end_date=2025-02-22 11:35:48.994143+00:00, run_duration=0.159221, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1015, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:35:47.528275+00:00, queued_by_job_id=7, pid=70545
2025-02-22 11:35:53,008 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-26T00:00:00+00:00, run_after=2024-10-27T00:00:00+00:00
2025-02-22 11:35:53,093 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:53,093 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:53,094 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:53,094 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:35:53,094 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:53,098 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:35:53,098 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:53,098 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:53,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:53,099 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:53,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:53,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:54,900 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:56,677 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:58,406 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:58,407 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:58,407 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:35:58,415 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:57.963677+00:00, run_end_date=2025-02-22 11:35:58.109572+00:00, run_duration=0.145895, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1020, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:53.095054+00:00, queued_by_job_id=7, pid=70648
2025-02-22 11:35:58,415 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:56.199855+00:00, run_end_date=2025-02-22 11:35:56.345176+00:00, run_duration=0.145321, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1019, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:53.095054+00:00, queued_by_job_id=7, pid=70621
2025-02-22 11:35:58,416 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:54.416145+00:00, run_end_date=2025-02-22 11:35:54.571520+00:00, run_duration=0.155375, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1018, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:35:53.095054+00:00, queued_by_job_id=7, pid=70602
2025-02-22 11:35:58,578 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-27T00:00:00+00:00, run_after=2024-10-28T00:00:00+00:00
2025-02-22 11:35:58,631 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-25 00:00:00+00:00: scheduled__2024-10-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:35:58,631 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-25 00:00:00+00:00, run_id=scheduled__2024-10-25T00:00:00+00:00, run_start_date=2025-02-22 11:35:38.093670+00:00, run_end_date=2025-02-22 11:35:58.631509+00:00, run_duration=20.537839, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-25 00:00:00+00:00, data_interval_end=2024-10-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:35:58,636 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-26T00:00:00+00:00, run_after=2024-10-27T00:00:00+00:00
2025-02-22 11:35:58,662 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:58,662 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:35:58,662 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:35:58,662 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:35:58,665 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:35:58,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:58,666 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:35:58,666 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:35:58,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:00,580 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:02,401 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:02,401 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:02,409 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:01.944792+00:00, run_end_date=2025-02-22 11:36:02.090975+00:00, run_duration=0.146183, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1022, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:35:58.663328+00:00, queued_by_job_id=7, pid=70687
2025-02-22 11:36:02,410 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:35:59.979979+00:00, run_end_date=2025-02-22 11:36:00.225197+00:00, run_duration=0.245218, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1021, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:35:58.663328+00:00, queued_by_job_id=7, pid=70667
2025-02-22 11:36:02,550 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-27T00:00:00+00:00, run_after=2024-10-28T00:00:00+00:00
2025-02-22 11:36:02,603 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-26 00:00:00+00:00: scheduled__2024-10-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:02,604 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-26 00:00:00+00:00, run_id=scheduled__2024-10-26T00:00:00+00:00, run_start_date=2025-02-22 11:35:41.888572+00:00, run_end_date=2025-02-22 11:36:02.604400+00:00, run_duration=20.715828, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-26 00:00:00+00:00, data_interval_end=2024-10-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:02,610 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-27T00:00:00+00:00, run_after=2024-10-28T00:00:00+00:00
2025-02-22 11:36:02,637 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:02,638 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:02,638 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:02,641 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:02,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:02,653 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:04,404 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:04,412 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:03.954639+00:00, run_end_date=2025-02-22 11:36:04.136407+00:00, run_duration=0.181768, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1023, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:02.639072+00:00, queued_by_job_id=7, pid=70706
2025-02-22 11:36:04,570 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-28T00:00:00+00:00, run_after=2024-10-29T00:00:00+00:00
2025-02-22 11:36:04,612 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-27 00:00:00+00:00: scheduled__2024-10-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:04,613 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-27 00:00:00+00:00, run_id=scheduled__2024-10-27T00:00:00+00:00, run_start_date=2025-02-22 11:35:47.470181+00:00, run_end_date=2025-02-22 11:36:04.613057+00:00, run_duration=17.142876, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-27 00:00:00+00:00, data_interval_end=2024-10-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:04,619 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-28T00:00:00+00:00, run_after=2024-10-29T00:00:00+00:00
2025-02-22 11:36:05,787 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-29T00:00:00+00:00, run_after=2024-10-30T00:00:00+00:00
2025-02-22 11:36:05,855 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:05,855 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:05,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:05,856 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:05,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:05,867 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:07,648 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:07,655 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:07.166809+00:00, run_end_date=2025-02-22 11:36:07.310860+00:00, run_duration=0.144051, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1024, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:05.855756+00:00, queued_by_job_id=7, pid=70729
2025-02-22 11:36:07,802 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-30T00:00:00+00:00, run_after=2024-10-31T00:00:00+00:00
2025-02-22 11:36:07,876 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:07,876 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:07,877 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:07,877 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:07,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:07,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:07,879 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:07,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:07,889 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:09,664 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:11,392 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:11,393 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:11,407 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:10.956905+00:00, run_end_date=2025-02-22 11:36:11.105135+00:00, run_duration=0.14823, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1026, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:07.877520+00:00, queued_by_job_id=7, pid=70769
2025-02-22 11:36:11,407 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:09.185171+00:00, run_end_date=2025-02-22 11:36:09.331734+00:00, run_duration=0.146563, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1025, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:07.877520+00:00, queued_by_job_id=7, pid=70749
2025-02-22 11:36:11,603 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
2025-02-22 11:36:11,683 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:11,683 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:11,683 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:11,683 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:11,683 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:11,685 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:11,685 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:11,686 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:11,686 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:11,686 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:11,686 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:11,698 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:13,484 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:15,248 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:17,054 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:17,054 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:17,054 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:17,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:16.566511+00:00, run_end_date=2025-02-22 11:36:16.712500+00:00, run_duration=0.145989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1029, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:11.683942+00:00, queued_by_job_id=7, pid=70834
2025-02-22 11:36:17,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:14.768116+00:00, run_end_date=2025-02-22 11:36:14.922439+00:00, run_duration=0.154323, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1028, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:11.683942+00:00, queued_by_job_id=7, pid=70807
2025-02-22 11:36:17,063 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:12.999866+00:00, run_end_date=2025-02-22 11:36:13.140540+00:00, run_duration=0.140674, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1027, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:11.683942+00:00, queued_by_job_id=7, pid=70788
2025-02-22 11:36:17,228 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
2025-02-22 11:36:17,314 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:17,314 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:17,314 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:17,314 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:17,314 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:36:17,314 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:17,317 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-10-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:17,317 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:17,317 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:17,317 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:17,317 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:17,317 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:17,317 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:17,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:17,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:19,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:20,904 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:22,691 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:24,456 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-10-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:24,456 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:24,456 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:24,456 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:24,465 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:23.991718+00:00, run_end_date=2025-02-22 11:36:24.133244+00:00, run_duration=0.141526, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1033, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:17.315260+00:00, queued_by_job_id=7, pid=70909
2025-02-22 11:36:24,465 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:22.199273+00:00, run_end_date=2025-02-22 11:36:22.343965+00:00, run_duration=0.144692, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1032, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:17.315260+00:00, queued_by_job_id=7, pid=70891
2025-02-22 11:36:24,465 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:20.411643+00:00, run_end_date=2025-02-22 11:36:20.554982+00:00, run_duration=0.143339, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1031, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:17.315260+00:00, queued_by_job_id=7, pid=70872
2025-02-22 11:36:24,465 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-10-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:18.624747+00:00, run_end_date=2025-02-22 11:36:18.769681+00:00, run_duration=0.144934, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1030, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:17.315260+00:00, queued_by_job_id=7, pid=70853
2025-02-22 11:36:24,635 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-02T00:00:00+00:00, run_after=2024-11-03T00:00:00+00:00
2025-02-22 11:36:24,700 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-28 00:00:00+00:00: scheduled__2024-10-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:24,700 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-28 00:00:00+00:00, run_id=scheduled__2024-10-28T00:00:00+00:00, run_start_date=2025-02-22 11:36:05.815139+00:00, run_end_date=2025-02-22 11:36:24.700929+00:00, run_duration=18.88579, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-28 00:00:00+00:00, data_interval_end=2024-10-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:24,704 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-29T00:00:00+00:00, run_after=2024-10-30T00:00:00+00:00
2025-02-22 11:36:24,737 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:24,737 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:24,737 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:24,738 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:24,738 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:36:24,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:24,740 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:24,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:24,740 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-10-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:24,740 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:24,741 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:24,741 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:24,741 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:24,741 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:24,752 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:26,543 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:28,346 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:30,066 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:31,832 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:31,833 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-10-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:31,833 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:31,833 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:31,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:31.381588+00:00, run_end_date=2025-02-22 11:36:31.531150+00:00, run_duration=0.149562, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1037, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:24.738568+00:00, queued_by_job_id=7, pid=70994
2025-02-22 11:36:31,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:29.630297+00:00, run_end_date=2025-02-22 11:36:29.771687+00:00, run_duration=0.14139, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1036, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:24.738568+00:00, queued_by_job_id=7, pid=70975
2025-02-22 11:36:31,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-10-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:27.855791+00:00, run_end_date=2025-02-22 11:36:28.001408+00:00, run_duration=0.145617, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1035, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:24.738568+00:00, queued_by_job_id=7, pid=70956
2025-02-22 11:36:31,842 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:26.053056+00:00, run_end_date=2025-02-22 11:36:26.195227+00:00, run_duration=0.142171, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1034, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:24.738568+00:00, queued_by_job_id=7, pid=70929
2025-02-22 11:36:32,006 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-30T00:00:00+00:00, run_after=2024-10-31T00:00:00+00:00
2025-02-22 11:36:32,074 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-29 00:00:00+00:00: scheduled__2024-10-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:32,074 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-29 00:00:00+00:00, run_id=scheduled__2024-10-29T00:00:00+00:00, run_start_date=2025-02-22 11:36:07.829706+00:00, run_end_date=2025-02-22 11:36:32.074731+00:00, run_duration=24.245025, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-29 00:00:00+00:00, data_interval_end=2024-10-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:32,079 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-30T00:00:00+00:00, run_after=2024-10-31T00:00:00+00:00
2025-02-22 11:36:32,103 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:32,104 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:32,104 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:32,104 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:32,104 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:32,107 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:32,108 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:32,108 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-10-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:32,108 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:32,108 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:32,108 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:32,119 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:33,959 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:35,728 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:37,496 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:37,496 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-10-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:37,496 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:37,505 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:37.035482+00:00, run_end_date=2025-02-22 11:36:37.182212+00:00, run_duration=0.14673, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1040, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:32.105009+00:00, queued_by_job_id=7, pid=71059
2025-02-22 11:36:37,506 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-10-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:35.250904+00:00, run_end_date=2025-02-22 11:36:35.403068+00:00, run_duration=0.152164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1039, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:32.105009+00:00, queued_by_job_id=7, pid=71032
2025-02-22 11:36:37,506 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:33.439047+00:00, run_end_date=2025-02-22 11:36:33.584934+00:00, run_duration=0.145887, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1038, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:32.105009+00:00, queued_by_job_id=7, pid=71014
2025-02-22 11:36:37,673 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
2025-02-22 11:36:37,729 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-30 00:00:00+00:00: scheduled__2024-10-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:37,729 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-30 00:00:00+00:00, run_id=scheduled__2024-10-30T00:00:00+00:00, run_start_date=2025-02-22 11:36:11.626557+00:00, run_end_date=2025-02-22 11:36:37.729690+00:00, run_duration=26.103133, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-30 00:00:00+00:00, data_interval_end=2024-10-31 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:37,734 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-10-31T00:00:00+00:00, run_after=2024-11-01T00:00:00+00:00
2025-02-22 11:36:37,760 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:37,760 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:37,761 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:37,761 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-10-31T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:37,764 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:37,764 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:37,765 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-10-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:37,765 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:37,776 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:39,616 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-10-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:41,400 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:41,400 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-10-31T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:41,411 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-10-31T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:40.934693+00:00, run_end_date=2025-02-22 11:36:41.079214+00:00, run_duration=0.144521, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1042, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:37.761783+00:00, queued_by_job_id=7, pid=71098
2025-02-22 11:36:41,411 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:39.128228+00:00, run_end_date=2025-02-22 11:36:39.275849+00:00, run_duration=0.147621, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1041, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:37.761783+00:00, queued_by_job_id=7, pid=71079
2025-02-22 11:36:41,663 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
2025-02-22 11:36:41,711 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-10-31 00:00:00+00:00: scheduled__2024-10-31T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:41,712 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-10-31 00:00:00+00:00, run_id=scheduled__2024-10-31T00:00:00+00:00, run_start_date=2025-02-22 11:36:17.256929+00:00, run_end_date=2025-02-22 11:36:41.712440+00:00, run_duration=24.455511, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-10-31 00:00:00+00:00, data_interval_end=2024-11-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:41,718 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-01T00:00:00+00:00, run_after=2024-11-02T00:00:00+00:00
2025-02-22 11:36:41,747 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:41,747 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:41,747 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:41,751 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:41,751 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:41,763 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:43,577 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:43,585 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:43.103939+00:00, run_end_date=2025-02-22 11:36:43.247158+00:00, run_duration=0.143219, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1043, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:41.748638+00:00, queued_by_job_id=7, pid=71118
2025-02-22 11:36:43,746 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-02T00:00:00+00:00, run_after=2024-11-03T00:00:00+00:00
2025-02-22 11:36:43,785 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-01 00:00:00+00:00: scheduled__2024-11-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:36:43,785 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-01 00:00:00+00:00, run_id=scheduled__2024-11-01T00:00:00+00:00, run_start_date=2025-02-22 11:36:24.662529+00:00, run_end_date=2025-02-22 11:36:43.785777+00:00, run_duration=19.123248, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-01 00:00:00+00:00, data_interval_end=2024-11-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:36:43,791 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-02T00:00:00+00:00, run_after=2024-11-03T00:00:00+00:00
2025-02-22 11:36:44,965 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-03T00:00:00+00:00, run_after=2024-11-04T00:00:00+00:00
2025-02-22 11:36:45,034 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:45,035 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:45,035 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:45,036 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:45,036 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:45,047 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:46,802 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:46,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:46.384193+00:00, run_end_date=2025-02-22 11:36:46.523184+00:00, run_duration=0.138991, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1044, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:45.035602+00:00, queued_by_job_id=7, pid=71140
2025-02-22 11:36:47,054 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
2025-02-22 11:36:47,130 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:47,131 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:47,131 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:47,131 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:47,133 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:47,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:47,133 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:47,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:47,145 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:48,942 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:50,745 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:50,746 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:50,751 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:50.258586+00:00, run_end_date=2025-02-22 11:36:50.399697+00:00, run_duration=0.141111, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1046, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:47.131651+00:00, queued_by_job_id=7, pid=71188
2025-02-22 11:36:50,752 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:48.471285+00:00, run_end_date=2025-02-22 11:36:48.638862+00:00, run_duration=0.167577, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1045, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:47.131651+00:00, queued_by_job_id=7, pid=71168
2025-02-22 11:36:50,914 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-05T00:00:00+00:00, run_after=2024-11-06T00:00:00+00:00
2025-02-22 11:36:50,984 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:50,984 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:50,984 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:50,985 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:50,985 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:50,986 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:50,986 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:50,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:50,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:50,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:50,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:50,998 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:52,781 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:54,551 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:56,306 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:56,307 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:56,308 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:36:56,325 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:55.845637+00:00, run_end_date=2025-02-22 11:36:55.988031+00:00, run_duration=0.142394, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1049, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:50.985322+00:00, queued_by_job_id=7, pid=71246
2025-02-22 11:36:56,326 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:54.074734+00:00, run_end_date=2025-02-22 11:36:54.214611+00:00, run_duration=0.139877, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1048, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:50.985322+00:00, queued_by_job_id=7, pid=71227
2025-02-22 11:36:56,326 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:52.299960+00:00, run_end_date=2025-02-22 11:36:52.441436+00:00, run_duration=0.141476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1047, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:50.985322+00:00, queued_by_job_id=7, pid=71207
2025-02-22 11:36:56,508 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-06T00:00:00+00:00, run_after=2024-11-07T00:00:00+00:00
2025-02-22 11:36:56,597 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:56,597 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:36:56,597 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:36:56,597 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:36:56,597 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:36:56,598 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:36:56,600 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:36:56,600 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:56,600 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:36:56,600 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:56,600 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:36:56,600 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:56,601 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:36:56,601 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:56,618 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:36:58,452 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:00,218 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:01,985 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:03,761 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:03,761 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:03,762 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:03,762 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:03,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:03.309307+00:00, run_end_date=2025-02-22 11:37:03.456642+00:00, run_duration=0.147335, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1053, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:36:56.598357+00:00, queued_by_job_id=7, pid=71322
2025-02-22 11:37:03,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:01.508723+00:00, run_end_date=2025-02-22 11:37:01.653169+00:00, run_duration=0.144446, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1052, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:36:56.598357+00:00, queued_by_job_id=7, pid=71303
2025-02-22 11:37:03,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:59.737931+00:00, run_end_date=2025-02-22 11:36:59.884005+00:00, run_duration=0.146074, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1051, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:36:56.598357+00:00, queued_by_job_id=7, pid=71284
2025-02-22 11:37:03,770 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:36:57.955545+00:00, run_end_date=2025-02-22 11:36:58.113633+00:00, run_duration=0.158088, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1050, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:36:56.598357+00:00, queued_by_job_id=7, pid=71266
2025-02-22 11:37:03,803 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:37:03,996 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-07T00:00:00+00:00, run_after=2024-11-08T00:00:00+00:00
2025-02-22 11:37:04,057 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-02 00:00:00+00:00: scheduled__2024-11-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:04,058 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-02 00:00:00+00:00, run_id=scheduled__2024-11-02T00:00:00+00:00, run_start_date=2025-02-22 11:36:44.993618+00:00, run_end_date=2025-02-22 11:37:04.058102+00:00, run_duration=19.064484, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-02 00:00:00+00:00, data_interval_end=2024-11-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:04,061 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-03T00:00:00+00:00, run_after=2024-11-04T00:00:00+00:00
2025-02-22 11:37:04,084 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:04,084 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:04,084 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:04,084 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:04,084 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:37:04,085 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:04,087 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:04,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:04,087 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:04,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:04,087 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:04,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:04,088 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:04,088 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:04,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:05,862 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:07,651 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:09,369 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:11,115 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:11,115 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:11,115 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:11,115 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:11,124 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:10.659103+00:00, run_end_date=2025-02-22 11:37:10.798293+00:00, run_duration=0.13919, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1057, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:04.085418+00:00, queued_by_job_id=7, pid=71407
2025-02-22 11:37:11,124 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:08.954741+00:00, run_end_date=2025-02-22 11:37:09.095785+00:00, run_duration=0.141044, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1056, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:04.085418+00:00, queued_by_job_id=7, pid=71387
2025-02-22 11:37:11,124 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:07.148915+00:00, run_end_date=2025-02-22 11:37:07.287611+00:00, run_duration=0.138696, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1055, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:04.085418+00:00, queued_by_job_id=7, pid=71368
2025-02-22 11:37:11,124 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:05.393299+00:00, run_end_date=2025-02-22 11:37:05.537023+00:00, run_duration=0.143724, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1054, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:04.085418+00:00, queued_by_job_id=7, pid=71342
2025-02-22 11:37:11,281 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
2025-02-22 11:37:11,350 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-03 00:00:00+00:00: scheduled__2024-11-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:11,350 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-03 00:00:00+00:00, run_id=scheduled__2024-11-03T00:00:00+00:00, run_start_date=2025-02-22 11:36:47.082090+00:00, run_end_date=2025-02-22 11:37:11.350443+00:00, run_duration=24.268353, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-03 00:00:00+00:00, data_interval_end=2024-11-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:11,355 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-04T00:00:00+00:00, run_after=2024-11-05T00:00:00+00:00
2025-02-22 11:37:11,379 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:11,379 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:11,379 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:11,379 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:11,379 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:11,382 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:11,383 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:11,383 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:11,383 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:11,383 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:11,384 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:11,396 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:13,443 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:15,239 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:16,983 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:16,983 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:16,983 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:16,992 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:16.525443+00:00, run_end_date=2025-02-22 11:37:16.672076+00:00, run_duration=0.146633, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1060, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:11.380227+00:00, queued_by_job_id=7, pid=71472
2025-02-22 11:37:16,992 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:14.737616+00:00, run_end_date=2025-02-22 11:37:14.883514+00:00, run_duration=0.145898, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1059, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:11.380227+00:00, queued_by_job_id=7, pid=71453
2025-02-22 11:37:16,992 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:12.883852+00:00, run_end_date=2025-02-22 11:37:13.084234+00:00, run_duration=0.200382, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1058, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:11.380227+00:00, queued_by_job_id=7, pid=71427
2025-02-22 11:37:17,171 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-05T00:00:00+00:00, run_after=2024-11-06T00:00:00+00:00
2025-02-22 11:37:17,224 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-04 00:00:00+00:00: scheduled__2024-11-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:17,224 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-04 00:00:00+00:00, run_id=scheduled__2024-11-04T00:00:00+00:00, run_start_date=2025-02-22 11:36:50.940274+00:00, run_end_date=2025-02-22 11:37:17.224682+00:00, run_duration=26.284408, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-04 00:00:00+00:00, data_interval_end=2024-11-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:17,229 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-05T00:00:00+00:00, run_after=2024-11-06T00:00:00+00:00
2025-02-22 11:37:17,254 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:17,254 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:17,254 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:17,254 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:17,258 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:17,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:17,258 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:17,259 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:17,270 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:19,060 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:20,859 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:20,860 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:20,868 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:20.389848+00:00, run_end_date=2025-02-22 11:37:20.545665+00:00, run_duration=0.155817, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1062, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:17.255493+00:00, queued_by_job_id=7, pid=71511
2025-02-22 11:37:20,868 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:18.561590+00:00, run_end_date=2025-02-22 11:37:18.707864+00:00, run_duration=0.146274, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1061, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:17.255493+00:00, queued_by_job_id=7, pid=71492
2025-02-22 11:37:21,009 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-06T00:00:00+00:00, run_after=2024-11-07T00:00:00+00:00
2025-02-22 11:37:21,063 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-05 00:00:00+00:00: scheduled__2024-11-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:21,063 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-05 00:00:00+00:00, run_id=scheduled__2024-11-05T00:00:00+00:00, run_start_date=2025-02-22 11:36:56.539217+00:00, run_end_date=2025-02-22 11:37:21.063603+00:00, run_duration=24.524386, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-05 00:00:00+00:00, data_interval_end=2024-11-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:21,072 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-06T00:00:00+00:00, run_after=2024-11-07T00:00:00+00:00
2025-02-22 11:37:21,098 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:21,099 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:21,099 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:21,102 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:21,102 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:21,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:22,900 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:22,909 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:22.413339+00:00, run_end_date=2025-02-22 11:37:22.591905+00:00, run_duration=0.178566, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1063, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:21.100199+00:00, queued_by_job_id=7, pid=71539
2025-02-22 11:37:23,374 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-07T00:00:00+00:00, run_after=2024-11-08T00:00:00+00:00
2025-02-22 11:37:23,415 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-06 00:00:00+00:00: scheduled__2024-11-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:23,415 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-06 00:00:00+00:00, run_id=scheduled__2024-11-06T00:00:00+00:00, run_start_date=2025-02-22 11:37:04.020584+00:00, run_end_date=2025-02-22 11:37:23.415772+00:00, run_duration=19.395188, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-06 00:00:00+00:00, data_interval_end=2024-11-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:23,418 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-07T00:00:00+00:00, run_after=2024-11-08T00:00:00+00:00
2025-02-22 11:37:24,892 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-08T00:00:00+00:00, run_after=2024-11-09T00:00:00+00:00
2025-02-22 11:37:24,963 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:24,963 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:24,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:24,965 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:24,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:24,976 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:26,778 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:26,786 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:26.292594+00:00, run_end_date=2025-02-22 11:37:26.436114+00:00, run_duration=0.14352, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1064, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:24.963930+00:00, queued_by_job_id=7, pid=71578
2025-02-22 11:37:27,226 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-09T00:00:00+00:00, run_after=2024-11-10T00:00:00+00:00
2025-02-22 11:37:27,299 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:27,299 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:27,299 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:27,299 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:27,301 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:27,301 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:27,302 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:27,302 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:27,311 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:29,024 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:30,802 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:30,802 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:30,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:30.312246+00:00, run_end_date=2025-02-22 11:37:30.459871+00:00, run_duration=0.147625, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1066, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:27.300010+00:00, queued_by_job_id=7, pid=71624
2025-02-22 11:37:30,811 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:28.602230+00:00, run_end_date=2025-02-22 11:37:28.744096+00:00, run_duration=0.141866, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1065, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:27.300010+00:00, queued_by_job_id=7, pid=71606
2025-02-22 11:37:30,980 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-10T00:00:00+00:00, run_after=2024-11-11T00:00:00+00:00
2025-02-22 11:37:31,059 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:31,059 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:31,059 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:31,059 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:31,059 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:31,062 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:31,063 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:31,063 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:31,063 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:31,063 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:31,063 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:31,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:32,875 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:34,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:36,316 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:36,317 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:36,317 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:36,332 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:35.907035+00:00, run_end_date=2025-02-22 11:37:36.044009+00:00, run_duration=0.136974, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1069, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:31.060320+00:00, queued_by_job_id=7, pid=71682
2025-02-22 11:37:36,332 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:34.176238+00:00, run_end_date=2025-02-22 11:37:34.314284+00:00, run_duration=0.138046, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1068, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:31.060320+00:00, queued_by_job_id=7, pid=71663
2025-02-22 11:37:36,333 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:32.366513+00:00, run_end_date=2025-02-22 11:37:32.507880+00:00, run_duration=0.141367, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1067, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:31.060320+00:00, queued_by_job_id=7, pid=71645
2025-02-22 11:37:36,508 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-11T00:00:00+00:00, run_after=2024-11-12T00:00:00+00:00
2025-02-22 11:37:36,617 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:36,618 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:36,618 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:36,618 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:36,618 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:37:36,618 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:36,622 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:36,622 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:36,622 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:36,622 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:36,623 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:36,623 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:36,623 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:36,623 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:36,637 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:38,341 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:40,194 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:41,934 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:43,679 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:43,680 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:43,680 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:43,680 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:43,689 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:43.220492+00:00, run_end_date=2025-02-22 11:37:43.367592+00:00, run_duration=0.1471, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1073, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:36.619341+00:00, queued_by_job_id=7, pid=71766
2025-02-22 11:37:43,689 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:41.471935+00:00, run_end_date=2025-02-22 11:37:41.637638+00:00, run_duration=0.165703, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1072, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:36.619341+00:00, queued_by_job_id=7, pid=71748
2025-02-22 11:37:43,689 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:39.713626+00:00, run_end_date=2025-02-22 11:37:39.851598+00:00, run_duration=0.137972, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1071, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:36.619341+00:00, queued_by_job_id=7, pid=71721
2025-02-22 11:37:43,689 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:37.925124+00:00, run_end_date=2025-02-22 11:37:38.060622+00:00, run_duration=0.135498, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1070, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:36.619341+00:00, queued_by_job_id=7, pid=71702
2025-02-22 11:37:43,860 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-12T00:00:00+00:00, run_after=2024-11-13T00:00:00+00:00
2025-02-22 11:37:43,929 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-07 00:00:00+00:00: scheduled__2024-11-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:43,929 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-07 00:00:00+00:00, run_id=scheduled__2024-11-07T00:00:00+00:00, run_start_date=2025-02-22 11:37:24.921082+00:00, run_end_date=2025-02-22 11:37:43.929883+00:00, run_duration=19.008801, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-07 00:00:00+00:00, data_interval_end=2024-11-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:43,932 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-08T00:00:00+00:00, run_after=2024-11-09T00:00:00+00:00
2025-02-22 11:37:43,959 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:43,959 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:43,959 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:43,959 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:43,959 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:37:43,959 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:43,961 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:37:43,961 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:43,962 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:43,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:43,962 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:43,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:43,962 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:43,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:43,977 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:45,768 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:47,478 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:49,362 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:51,190 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:51,190 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:51,190 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:51,190 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:51,198 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:50.699056+00:00, run_end_date=2025-02-22 11:37:50.844100+00:00, run_duration=0.145044, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1077, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:43.959960+00:00, queued_by_job_id=7, pid=71851
2025-02-22 11:37:51,199 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:48.934719+00:00, run_end_date=2025-02-22 11:37:49.079560+00:00, run_duration=0.144841, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1076, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:43.959960+00:00, queued_by_job_id=7, pid=71824
2025-02-22 11:37:51,199 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:47.060919+00:00, run_end_date=2025-02-22 11:37:47.196793+00:00, run_duration=0.135874, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1075, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:43.959960+00:00, queued_by_job_id=7, pid=71806
2025-02-22 11:37:51,199 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:45.281991+00:00, run_end_date=2025-02-22 11:37:45.425012+00:00, run_duration=0.143021, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1074, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:37:43.959960+00:00, queued_by_job_id=7, pid=71787
2025-02-22 11:37:51,372 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-09T00:00:00+00:00, run_after=2024-11-10T00:00:00+00:00
2025-02-22 11:37:51,441 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-08 00:00:00+00:00: scheduled__2024-11-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:51,442 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-08 00:00:00+00:00, run_id=scheduled__2024-11-08T00:00:00+00:00, run_start_date=2025-02-22 11:37:27.252625+00:00, run_end_date=2025-02-22 11:37:51.441945+00:00, run_duration=24.18932, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-08 00:00:00+00:00, data_interval_end=2024-11-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:51,446 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-09T00:00:00+00:00, run_after=2024-11-10T00:00:00+00:00
2025-02-22 11:37:51,471 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:51,471 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:51,471 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:51,471 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:37:51,471 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:51,475 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:37:51,475 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:51,475 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:51,475 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:51,476 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:51,476 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:51,492 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:53,243 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:55,004 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:56,933 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:56,934 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:56,934 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:37:56,942 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:56.433849+00:00, run_end_date=2025-02-22 11:37:56.668042+00:00, run_duration=0.234193, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1080, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:51.472293+00:00, queued_by_job_id=7, pid=71909
2025-02-22 11:37:56,943 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:54.529050+00:00, run_end_date=2025-02-22 11:37:54.670192+00:00, run_duration=0.141142, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1079, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:51.472293+00:00, queued_by_job_id=7, pid=71889
2025-02-22 11:37:56,943 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:52.795323+00:00, run_end_date=2025-02-22 11:37:52.934407+00:00, run_duration=0.139084, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1078, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:37:51.472293+00:00, queued_by_job_id=7, pid=71871
2025-02-22 11:37:57,106 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-10T00:00:00+00:00, run_after=2024-11-11T00:00:00+00:00
2025-02-22 11:37:57,165 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-09 00:00:00+00:00: scheduled__2024-11-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:37:57,165 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-09 00:00:00+00:00, run_id=scheduled__2024-11-09T00:00:00+00:00, run_start_date=2025-02-22 11:37:31.004456+00:00, run_end_date=2025-02-22 11:37:57.165758+00:00, run_duration=26.161302, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-09 00:00:00+00:00, data_interval_end=2024-11-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:37:57,170 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-10T00:00:00+00:00, run_after=2024-11-11T00:00:00+00:00
2025-02-22 11:37:57,199 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:57,199 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:37:57,199 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:37:57,200 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:37:57,203 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:37:57,203 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:57,204 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:37:57,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:57,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:37:58,935 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:00,628 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:00,628 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:00,636 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:00.228734+00:00, run_end_date=2025-02-22 11:38:00.370216+00:00, run_duration=0.141482, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1082, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:37:57.200757+00:00, queued_by_job_id=7, pid=71955
2025-02-22 11:38:00,637 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:37:58.508434+00:00, run_end_date=2025-02-22 11:37:58.645724+00:00, run_duration=0.13729, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1081, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:37:57.200757+00:00, queued_by_job_id=7, pid=71928
2025-02-22 11:38:00,777 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-11T00:00:00+00:00, run_after=2024-11-12T00:00:00+00:00
2025-02-22 11:38:00,828 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-10 00:00:00+00:00: scheduled__2024-11-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:00,829 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-10 00:00:00+00:00, run_id=scheduled__2024-11-10T00:00:00+00:00, run_start_date=2025-02-22 11:37:36.535084+00:00, run_end_date=2025-02-22 11:38:00.829457+00:00, run_duration=24.294373, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-10 00:00:00+00:00, data_interval_end=2024-11-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:00,835 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-11T00:00:00+00:00, run_after=2024-11-12T00:00:00+00:00
2025-02-22 11:38:00,864 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:00,865 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:00,865 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:00,868 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:00,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:00,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:02,663 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:02,671 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:02.198232+00:00, run_end_date=2025-02-22 11:38:02.341892+00:00, run_duration=0.14366, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1083, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:00.866311+00:00, queued_by_job_id=7, pid=71975
2025-02-22 11:38:02,826 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-12T00:00:00+00:00, run_after=2024-11-13T00:00:00+00:00
2025-02-22 11:38:02,863 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-11 00:00:00+00:00: scheduled__2024-11-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:02,863 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-11 00:00:00+00:00, run_id=scheduled__2024-11-11T00:00:00+00:00, run_start_date=2025-02-22 11:37:43.888507+00:00, run_end_date=2025-02-22 11:38:02.863789+00:00, run_duration=18.975282, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-11 00:00:00+00:00, data_interval_end=2024-11-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:02,869 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-12T00:00:00+00:00, run_after=2024-11-13T00:00:00+00:00
2025-02-22 11:38:04,052 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-13T00:00:00+00:00, run_after=2024-11-14T00:00:00+00:00
2025-02-22 11:38:04,127 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:04,128 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:04,128 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:04,129 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:04,129 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:04,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:05,939 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:05,947 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:05.437013+00:00, run_end_date=2025-02-22 11:38:05.593339+00:00, run_duration=0.156326, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1084, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:04.128534+00:00, queued_by_job_id=7, pid=71997
2025-02-22 11:38:06,094 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-14T00:00:00+00:00, run_after=2024-11-15T00:00:00+00:00
2025-02-22 11:38:06,168 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:06,168 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:06,168 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:06,168 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:06,170 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:06,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:06,171 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:06,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:06,182 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:07,963 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:09,736 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:09,736 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:09,744 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:09.266085+00:00, run_end_date=2025-02-22 11:38:09.420421+00:00, run_duration=0.154336, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1086, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:06.169001+00:00, queued_by_job_id=7, pid=72036
2025-02-22 11:38:09,745 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:07.477623+00:00, run_end_date=2025-02-22 11:38:07.619216+00:00, run_duration=0.141593, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1085, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:06.169001+00:00, queued_by_job_id=7, pid=72017
2025-02-22 11:38:10,008 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-15T00:00:00+00:00, run_after=2024-11-16T00:00:00+00:00
2025-02-22 11:38:10,081 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:10,081 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:10,081 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:10,081 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:38:10,081 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:10,084 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:10,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:10,084 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:10,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:10,084 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:10,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:10,097 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:11,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:13,609 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:15,299 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:15,300 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:15,300 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:15,308 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:14.884934+00:00, run_end_date=2025-02-22 11:38:15.021987+00:00, run_duration=0.137053, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1089, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:10.082288+00:00, queued_by_job_id=7, pid=72093
2025-02-22 11:38:15,308 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:13.195846+00:00, run_end_date=2025-02-22 11:38:13.330788+00:00, run_duration=0.134942, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1088, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:10.082288+00:00, queued_by_job_id=7, pid=72075
2025-02-22 11:38:15,308 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:11.416827+00:00, run_end_date=2025-02-22 11:38:11.578336+00:00, run_duration=0.161509, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1087, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:10.082288+00:00, queued_by_job_id=7, pid=72057
2025-02-22 11:38:15,478 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-16T00:00:00+00:00, run_after=2024-11-17T00:00:00+00:00
2025-02-22 11:38:15,573 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:15,573 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:15,573 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:15,573 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:38:15,573 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:38:15,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:15,576 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:15,576 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:15,576 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:15,576 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:15,577 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:15,577 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:15,577 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:15,577 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:15,589 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:17,319 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:19,079 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:20,845 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:22,651 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:22,652 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:22,652 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:22,652 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:22,660 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:22.192788+00:00, run_end_date=2025-02-22 11:38:22.339276+00:00, run_duration=0.146488, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1093, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:15.574379+00:00, queued_by_job_id=7, pid=72185
2025-02-22 11:38:22,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:20.402403+00:00, run_end_date=2025-02-22 11:38:20.545121+00:00, run_duration=0.142718, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1092, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:15.574379+00:00, queued_by_job_id=7, pid=72150
2025-02-22 11:38:22,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:18.595966+00:00, run_end_date=2025-02-22 11:38:18.744119+00:00, run_duration=0.148153, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1091, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:15.574379+00:00, queued_by_job_id=7, pid=72132
2025-02-22 11:38:22,661 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:16.892467+00:00, run_end_date=2025-02-22 11:38:17.031696+00:00, run_duration=0.139229, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1090, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:15.574379+00:00, queued_by_job_id=7, pid=72113
2025-02-22 11:38:22,948 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-17T00:00:00+00:00, run_after=2024-11-18T00:00:00+00:00
2025-02-22 11:38:23,015 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-12 00:00:00+00:00: scheduled__2024-11-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:23,016 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-12 00:00:00+00:00, run_id=scheduled__2024-11-12T00:00:00+00:00, run_start_date=2025-02-22 11:38:04.086847+00:00, run_end_date=2025-02-22 11:38:23.016132+00:00, run_duration=18.929285, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-12 00:00:00+00:00, data_interval_end=2024-11-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:23,019 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-13T00:00:00+00:00, run_after=2024-11-14T00:00:00+00:00
2025-02-22 11:38:23,044 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:23,044 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:23,045 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:23,045 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:38:23,045 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:38:23,045 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:23,047 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:23,047 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:23,048 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:23,048 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:23,048 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:23,048 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:23,048 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:23,048 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:23,059 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:24,847 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:26,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:28,866 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:30,552 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:30,553 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:30,553 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:30,553 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:30,568 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:30.150405+00:00, run_end_date=2025-02-22 11:38:30.288475+00:00, run_duration=0.13807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1097, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:23.045739+00:00, queued_by_job_id=7, pid=72262
2025-02-22 11:38:30,568 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:28.385723+00:00, run_end_date=2025-02-22 11:38:28.533681+00:00, run_duration=0.147958, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1096, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:23.045739+00:00, queued_by_job_id=7, pid=72243
2025-02-22 11:38:30,569 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:26.442607+00:00, run_end_date=2025-02-22 11:38:26.599273+00:00, run_duration=0.156666, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1095, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:23.045739+00:00, queued_by_job_id=7, pid=72224
2025-02-22 11:38:30,569 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:24.363110+00:00, run_end_date=2025-02-22 11:38:24.504137+00:00, run_duration=0.141027, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1094, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:23.045739+00:00, queued_by_job_id=7, pid=72205
2025-02-22 11:38:30,735 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-14T00:00:00+00:00, run_after=2024-11-15T00:00:00+00:00
2025-02-22 11:38:30,802 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-13 00:00:00+00:00: scheduled__2024-11-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:30,803 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-13 00:00:00+00:00, run_id=scheduled__2024-11-13T00:00:00+00:00, run_start_date=2025-02-22 11:38:06.121260+00:00, run_end_date=2025-02-22 11:38:30.803036+00:00, run_duration=24.681776, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-13 00:00:00+00:00, data_interval_end=2024-11-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:30,807 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-14T00:00:00+00:00, run_after=2024-11-15T00:00:00+00:00
2025-02-22 11:38:30,833 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:30,833 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:30,833 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:30,834 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:38:30,834 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:30,837 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:30,837 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:30,837 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:30,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:30,838 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:30,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:30,848 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:32,604 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:34,348 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:36,228 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:36,229 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:36,229 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:36,237 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:35.669942+00:00, run_end_date=2025-02-22 11:38:35.902063+00:00, run_duration=0.232121, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1100, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:30.834776+00:00, queued_by_job_id=7, pid=72327
2025-02-22 11:38:36,238 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:33.892757+00:00, run_end_date=2025-02-22 11:38:34.037038+00:00, run_duration=0.144281, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1099, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:30.834776+00:00, queued_by_job_id=7, pid=72308
2025-02-22 11:38:36,238 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:32.172028+00:00, run_end_date=2025-02-22 11:38:32.312639+00:00, run_duration=0.140611, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1098, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:30.834776+00:00, queued_by_job_id=7, pid=72290
2025-02-22 11:38:36,447 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-15T00:00:00+00:00, run_after=2024-11-16T00:00:00+00:00
2025-02-22 11:38:36,544 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-14 00:00:00+00:00: scheduled__2024-11-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:36,544 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-14 00:00:00+00:00, run_id=scheduled__2024-11-14T00:00:00+00:00, run_start_date=2025-02-22 11:38:10.032258+00:00, run_end_date=2025-02-22 11:38:36.544770+00:00, run_duration=26.512512, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-14 00:00:00+00:00, data_interval_end=2024-11-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:36,550 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-15T00:00:00+00:00, run_after=2024-11-16T00:00:00+00:00
2025-02-22 11:38:36,582 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:36,582 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:36,583 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:36,583 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:36,587 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:36,587 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:36,587 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:36,588 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:36,623 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:38,674 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:41,644 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:41,644 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:41,652 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:40.980362+00:00, run_end_date=2025-02-22 11:38:41.230558+00:00, run_duration=0.250196, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1102, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:36.583954+00:00, queued_by_job_id=7, pid=72367
2025-02-22 11:38:41,652 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:37.963016+00:00, run_end_date=2025-02-22 11:38:38.207370+00:00, run_duration=0.244354, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1101, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:36.583954+00:00, queued_by_job_id=7, pid=72347
2025-02-22 11:38:41,844 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-16T00:00:00+00:00, run_after=2024-11-17T00:00:00+00:00
2025-02-22 11:38:41,931 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-15 00:00:00+00:00: scheduled__2024-11-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:41,931 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-15 00:00:00+00:00, run_id=scheduled__2024-11-15T00:00:00+00:00, run_start_date=2025-02-22 11:38:15.508311+00:00, run_end_date=2025-02-22 11:38:41.931504+00:00, run_duration=26.423193, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-15 00:00:00+00:00, data_interval_end=2024-11-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:41,938 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-16T00:00:00+00:00, run_after=2024-11-17T00:00:00+00:00
2025-02-22 11:38:42,146 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:42,146 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:42,147 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:42,151 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:38:42,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:42,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:44,151 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:44,157 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:43.574652+00:00, run_end_date=2025-02-22 11:38:43.792128+00:00, run_duration=0.217476, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1103, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:38:42.148175+00:00, queued_by_job_id=7, pid=72388
2025-02-22 11:38:44,398 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-17T00:00:00+00:00, run_after=2024-11-18T00:00:00+00:00
2025-02-22 11:38:44,478 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-16 00:00:00+00:00: scheduled__2024-11-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:38:44,478 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-16 00:00:00+00:00, run_id=scheduled__2024-11-16T00:00:00+00:00, run_start_date=2025-02-22 11:38:22.975920+00:00, run_end_date=2025-02-22 11:38:44.478747+00:00, run_duration=21.502827, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-16 00:00:00+00:00, data_interval_end=2024-11-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:38:44,485 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-17T00:00:00+00:00, run_after=2024-11-18T00:00:00+00:00
2025-02-22 11:38:45,678 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-18T00:00:00+00:00, run_after=2024-11-19T00:00:00+00:00
2025-02-22 11:38:45,844 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:45,845 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:45,845 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:45,849 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:45,849 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:45,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:47,894 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:47,902 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:47.240737+00:00, run_end_date=2025-02-22 11:38:47.474291+00:00, run_duration=0.233554, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1104, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:45.846707+00:00, queued_by_job_id=7, pid=72410
2025-02-22 11:38:48,215 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-19T00:00:00+00:00, run_after=2024-11-20T00:00:00+00:00
2025-02-22 11:38:48,414 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:48,414 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:48,414 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:48,415 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:48,420 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:48,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:48,421 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:48,421 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:48,472 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:50,550 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:52,874 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:52,874 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:38:52,882 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:52.090640+00:00, run_end_date=2025-02-22 11:38:52.413123+00:00, run_duration=0.322483, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1106, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:48.416056+00:00, queued_by_job_id=7, pid=72450
2025-02-22 11:38:52,883 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:49.860133+00:00, run_end_date=2025-02-22 11:38:50.130967+00:00, run_duration=0.270834, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1105, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:48.416056+00:00, queued_by_job_id=7, pid=72431
2025-02-22 11:38:53,144 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-20T00:00:00+00:00, run_after=2024-11-21T00:00:00+00:00
2025-02-22 11:38:53,298 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:53,298 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:38:53,298 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:38:53,298 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:38:53,298 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:38:53,302 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:38:53,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:53,303 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:38:53,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:53,303 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:38:53,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:53,337 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:55,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:38:57,826 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:00,143 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:00,143 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:00,144 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:00,152 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:59.408052+00:00, run_end_date=2025-02-22 11:38:59.628960+00:00, run_duration=0.220908, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1109, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:38:53.299586+00:00, queued_by_job_id=7, pid=72526
2025-02-22 11:39:00,152 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:57.122044+00:00, run_end_date=2025-02-22 11:38:57.370013+00:00, run_duration=0.247969, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1108, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:38:53.299586+00:00, queued_by_job_id=7, pid=72506
2025-02-22 11:39:00,152 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:38:54.777542+00:00, run_end_date=2025-02-22 11:38:55.015806+00:00, run_duration=0.238264, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1107, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:38:53.299586+00:00, queued_by_job_id=7, pid=72479
2025-02-22 11:39:00,447 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-21T00:00:00+00:00, run_after=2024-11-22T00:00:00+00:00
2025-02-22 11:39:00,654 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:00,654 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:00,654 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:00,654 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:00,654 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:39:00,655 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:00,659 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:00,659 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:00,659 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:00,659 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:00,660 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:00,660 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:00,660 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:00,660 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:00,716 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:02,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:04,984 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:07,067 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:09,072 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:09,072 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:09,072 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:09,072 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:09,081 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:08.501328+00:00, run_end_date=2025-02-22 11:39:08.721236+00:00, run_duration=0.219908, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1113, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:00.655753+00:00, queued_by_job_id=7, pid=72612
2025-02-22 11:39:09,081 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:06.436036+00:00, run_end_date=2025-02-22 11:39:06.638817+00:00, run_duration=0.202781, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1112, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:00.655753+00:00, queued_by_job_id=7, pid=72592
2025-02-22 11:39:09,081 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:04.263542+00:00, run_end_date=2025-02-22 11:39:04.538963+00:00, run_duration=0.275421, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1111, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:00.655753+00:00, queued_by_job_id=7, pid=72573
2025-02-22 11:39:09,082 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:02.163444+00:00, run_end_date=2025-02-22 11:39:02.379674+00:00, run_duration=0.21623, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1110, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:00.655753+00:00, queued_by_job_id=7, pid=72546
2025-02-22 11:39:09,404 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-22T00:00:00+00:00, run_after=2024-11-23T00:00:00+00:00
2025-02-22 11:39:09,579 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-17 00:00:00+00:00: scheduled__2024-11-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:09,580 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-17 00:00:00+00:00, run_id=scheduled__2024-11-17T00:00:00+00:00, run_start_date=2025-02-22 11:38:45.741965+00:00, run_end_date=2025-02-22 11:39:09.580117+00:00, run_duration=23.838152, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-17 00:00:00+00:00, data_interval_end=2024-11-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:09,584 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-18T00:00:00+00:00, run_after=2024-11-19T00:00:00+00:00
2025-02-22 11:39:09,760 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:09,761 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:09,761 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:09,762 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:09,762 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:39:09,762 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:09,767 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:09,768 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:09,768 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:09,769 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:09,769 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:09,769 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:09,770 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:09,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:09,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:11,965 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:14,123 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:16,233 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:18,178 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:18,178 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:18,178 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:18,179 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:18,187 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:17.551974+00:00, run_end_date=2025-02-22 11:39:17.825453+00:00, run_duration=0.273479, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1117, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:09.763451+00:00, queued_by_job_id=7, pid=72690
2025-02-22 11:39:18,187 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:15.527678+00:00, run_end_date=2025-02-22 11:39:15.768030+00:00, run_duration=0.240352, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1116, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:09.763451+00:00, queued_by_job_id=7, pid=72671
2025-02-22 11:39:18,188 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:13.455514+00:00, run_end_date=2025-02-22 11:39:13.646143+00:00, run_duration=0.190629, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1115, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:09.763451+00:00, queued_by_job_id=7, pid=72652
2025-02-22 11:39:18,188 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:11.182878+00:00, run_end_date=2025-02-22 11:39:11.425754+00:00, run_duration=0.242876, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1114, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:09.763451+00:00, queued_by_job_id=7, pid=72633
2025-02-22 11:39:18,401 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-19T00:00:00+00:00, run_after=2024-11-20T00:00:00+00:00
2025-02-22 11:39:18,524 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-18 00:00:00+00:00: scheduled__2024-11-18T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:18,524 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-18 00:00:00+00:00, run_id=scheduled__2024-11-18T00:00:00+00:00, run_start_date=2025-02-22 11:38:48.308327+00:00, run_end_date=2025-02-22 11:39:18.524643+00:00, run_duration=30.216316, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-18 00:00:00+00:00, data_interval_end=2024-11-19 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:18,529 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-19T00:00:00+00:00, run_after=2024-11-20T00:00:00+00:00
2025-02-22 11:39:18,578 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:18,579 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:18,579 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:18,579 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:18,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-19T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:18,584 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:18,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:18,585 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:18,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:18,586 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:18,586 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:18,649 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:20,747 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:22,934 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:25,129 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:25,130 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:25,130 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:25,145 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:24.449029+00:00, run_end_date=2025-02-22 11:39:24.689114+00:00, run_duration=0.240085, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1120, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:18.580796+00:00, queued_by_job_id=7, pid=72749
2025-02-22 11:39:25,145 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:22.206571+00:00, run_end_date=2025-02-22 11:39:22.426537+00:00, run_duration=0.219966, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1119, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:18.580796+00:00, queued_by_job_id=7, pid=72729
2025-02-22 11:39:25,146 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:19.992410+00:00, run_end_date=2025-02-22 11:39:20.215508+00:00, run_duration=0.223098, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1118, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:18.580796+00:00, queued_by_job_id=7, pid=72710
2025-02-22 11:39:25,469 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-20T00:00:00+00:00, run_after=2024-11-21T00:00:00+00:00
2025-02-22 11:39:25,553 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-19 00:00:00+00:00: scheduled__2024-11-19T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:25,553 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-19 00:00:00+00:00, run_id=scheduled__2024-11-19T00:00:00+00:00, run_start_date=2025-02-22 11:38:53.204106+00:00, run_end_date=2025-02-22 11:39:25.553839+00:00, run_duration=32.349733, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-19 00:00:00+00:00, data_interval_end=2024-11-20 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:25,559 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-20T00:00:00+00:00, run_after=2024-11-21T00:00:00+00:00
2025-02-22 11:39:25,599 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:25,599 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:25,599 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:25,599 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-20T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:25,603 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:25,604 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:25,604 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:25,604 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:25,631 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:27,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:29,960 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:29,961 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:29,969 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:29.312380+00:00, run_end_date=2025-02-22 11:39:29.549752+00:00, run_duration=0.237372, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1122, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:25.600568+00:00, queued_by_job_id=7, pid=72789
2025-02-22 11:39:29,969 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:27.181991+00:00, run_end_date=2025-02-22 11:39:27.412205+00:00, run_duration=0.230214, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1121, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:25.600568+00:00, queued_by_job_id=7, pid=72769
2025-02-22 11:39:30,207 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-21T00:00:00+00:00, run_after=2024-11-22T00:00:00+00:00
2025-02-22 11:39:30,288 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-20 00:00:00+00:00: scheduled__2024-11-20T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:30,289 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-20 00:00:00+00:00, run_id=scheduled__2024-11-20T00:00:00+00:00, run_start_date=2025-02-22 11:39:00.530507+00:00, run_end_date=2025-02-22 11:39:30.289421+00:00, run_duration=29.758914, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-20 00:00:00+00:00, data_interval_end=2024-11-21 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:30,296 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-21T00:00:00+00:00, run_after=2024-11-22T00:00:00+00:00
2025-02-22 11:39:30,424 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:30,424 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:30,424 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-21T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:30,428 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:30,429 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:30,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:32,494 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-21T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:32,502 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-21T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:31.849528+00:00, run_end_date=2025-02-22 11:39:32.050832+00:00, run_duration=0.201304, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1123, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:30.425848+00:00, queued_by_job_id=7, pid=72817
2025-02-22 11:39:32,792 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-22T00:00:00+00:00, run_after=2024-11-23T00:00:00+00:00
2025-02-22 11:39:32,888 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-21 00:00:00+00:00: scheduled__2024-11-21T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:32,888 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-21 00:00:00+00:00, run_id=scheduled__2024-11-21T00:00:00+00:00, run_start_date=2025-02-22 11:39:09.495501+00:00, run_end_date=2025-02-22 11:39:32.888753+00:00, run_duration=23.393252, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-21 00:00:00+00:00, data_interval_end=2024-11-22 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:32,895 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-22T00:00:00+00:00, run_after=2024-11-23T00:00:00+00:00
2025-02-22 11:39:34,333 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-23T00:00:00+00:00, run_after=2024-11-24T00:00:00+00:00
2025-02-22 11:39:34,525 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:34,527 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:34,527 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:34,531 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:34,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:34,551 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:36,996 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:37,003 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:35.989886+00:00, run_end_date=2025-02-22 11:39:36.265990+00:00, run_duration=0.276104, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1124, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:34.528409+00:00, queued_by_job_id=7, pid=72847
2025-02-22 11:39:37,254 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-24T00:00:00+00:00, run_after=2024-11-25T00:00:00+00:00
2025-02-22 11:39:37,479 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:37,479 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:37,480 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:37,480 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:37,485 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:37,486 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:37,486 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:37,486 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:37,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:39,711 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:41,818 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:41,819 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:41,827 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:41.087682+00:00, run_end_date=2025-02-22 11:39:41.341955+00:00, run_duration=0.254273, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1126, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:37.481338+00:00, queued_by_job_id=7, pid=72887
2025-02-22 11:39:41,827 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:38.946285+00:00, run_end_date=2025-02-22 11:39:39.205602+00:00, run_duration=0.259317, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1125, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:37.481338+00:00, queued_by_job_id=7, pid=72867
2025-02-22 11:39:42,152 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-25T00:00:00+00:00, run_after=2024-11-26T00:00:00+00:00
2025-02-22 11:39:42,423 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:42,423 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:42,423 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:42,424 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:42,424 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:42,426 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:42,426 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:42,426 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:42,427 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:42,427 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:42,427 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:42,481 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:44,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:46,571 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:48,790 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:48,791 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:48,792 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:48,809 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:48.020924+00:00, run_end_date=2025-02-22 11:39:48.298831+00:00, run_duration=0.277907, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1129, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:42.424511+00:00, queued_by_job_id=7, pid=72953
2025-02-22 11:39:48,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:45.860178+00:00, run_end_date=2025-02-22 11:39:46.121243+00:00, run_duration=0.261065, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1128, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:42.424511+00:00, queued_by_job_id=7, pid=72935
2025-02-22 11:39:48,810 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:43.898399+00:00, run_end_date=2025-02-22 11:39:44.131442+00:00, run_duration=0.233043, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1127, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:42.424511+00:00, queued_by_job_id=7, pid=72916
2025-02-22 11:39:49,129 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-26T00:00:00+00:00, run_after=2024-11-27T00:00:00+00:00
2025-02-22 11:39:49,409 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:49,410 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:49,410 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:49,410 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:49,410 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:39:49,410 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-22T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:49,416 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:49,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:49,417 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:49,417 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:49,418 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:49,418 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:49,418 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:49,418 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:49,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:51,583 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:53,771 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:55,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:57,904 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:57,905 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:57,905 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:57,905 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-22T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:39:57,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-22T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:57.333819+00:00, run_end_date=2025-02-22 11:39:57.549097+00:00, run_duration=0.215278, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1133, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:49.411831+00:00, queued_by_job_id=7, pid=73033
2025-02-22 11:39:57,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:55.223283+00:00, run_end_date=2025-02-22 11:39:55.545932+00:00, run_duration=0.322649, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1132, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:49.411831+00:00, queued_by_job_id=7, pid=73014
2025-02-22 11:39:57,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:52.911316+00:00, run_end_date=2025-02-22 11:39:53.285817+00:00, run_duration=0.374501, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1131, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:49.411831+00:00, queued_by_job_id=7, pid=72993
2025-02-22 11:39:57,914 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:50.807021+00:00, run_end_date=2025-02-22 11:39:51.105620+00:00, run_duration=0.298599, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1130, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:49.411831+00:00, queued_by_job_id=7, pid=72974
2025-02-22 11:39:58,116 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-27T00:00:00+00:00, run_after=2024-11-28T00:00:00+00:00
2025-02-22 11:39:58,253 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-22 00:00:00+00:00: scheduled__2024-11-22T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:39:58,253 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-22 00:00:00+00:00, run_id=scheduled__2024-11-22T00:00:00+00:00, run_start_date=2025-02-22 11:39:34.424317+00:00, run_end_date=2025-02-22 11:39:58.253644+00:00, run_duration=23.829327, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-22 00:00:00+00:00, data_interval_end=2024-11-23 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:39:58,257 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-23T00:00:00+00:00, run_after=2024-11-24T00:00:00+00:00
2025-02-22 11:39:58,329 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:58,329 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:39:58,330 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:39:58,330 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:39:58,330 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:39:58,330 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-23T00:00:00+00:00 [scheduled]>
2025-02-22 11:39:58,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:39:58,334 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:58,334 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:39:58,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:58,335 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:39:58,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:58,335 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:39:58,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:39:58,368 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:00,437 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:02,788 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:05,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:07,478 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:07,479 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:07,479 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:07,479 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-23T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:07,487 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-23T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:06.823911+00:00, run_end_date=2025-02-22 11:40:07.067519+00:00, run_duration=0.243608, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1137, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:39:58.331106+00:00, queued_by_job_id=7, pid=73126
2025-02-22 11:40:07,487 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:04.260893+00:00, run_end_date=2025-02-22 11:40:04.756337+00:00, run_duration=0.495444, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1136, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:39:58.331106+00:00, queued_by_job_id=7, pid=73091
2025-02-22 11:40:07,488 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:02.004478+00:00, run_end_date=2025-02-22 11:40:02.263801+00:00, run_duration=0.259323, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1135, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:39:58.331106+00:00, queued_by_job_id=7, pid=73072
2025-02-22 11:40:07,488 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:39:59.717365+00:00, run_end_date=2025-02-22 11:39:59.964364+00:00, run_duration=0.246999, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1134, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:39:58.331106+00:00, queued_by_job_id=7, pid=73053
2025-02-22 11:40:07,662 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-24T00:00:00+00:00, run_after=2024-11-25T00:00:00+00:00
2025-02-22 11:40:07,768 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-23 00:00:00+00:00: scheduled__2024-11-23T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:07,769 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-23 00:00:00+00:00, run_id=scheduled__2024-11-23T00:00:00+00:00, run_start_date=2025-02-22 11:39:37.336167+00:00, run_end_date=2025-02-22 11:40:07.769318+00:00, run_duration=30.433151, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-23 00:00:00+00:00, data_interval_end=2024-11-24 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:07,774 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-24T00:00:00+00:00, run_after=2024-11-25T00:00:00+00:00
2025-02-22 11:40:07,836 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:07,837 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:07,837 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:07,837 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:40:07,838 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-24T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:07,843 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:40:07,843 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:07,844 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:07,844 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:07,844 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:07,845 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:07,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:10,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:12,146 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:14,196 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:14,197 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:14,198 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-24T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:14,212 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-24T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:13.483280+00:00, run_end_date=2025-02-22 11:40:13.788082+00:00, run_duration=0.304802, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1140, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:07.838938+00:00, queued_by_job_id=7, pid=73185
2025-02-22 11:40:14,213 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:11.546100+00:00, run_end_date=2025-02-22 11:40:11.785244+00:00, run_duration=0.239144, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1139, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:07.838938+00:00, queued_by_job_id=7, pid=73166
2025-02-22 11:40:14,213 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:09.237562+00:00, run_end_date=2025-02-22 11:40:09.596731+00:00, run_duration=0.359169, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1138, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:40:07.838938+00:00, queued_by_job_id=7, pid=73146
2025-02-22 11:40:14,733 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-25T00:00:00+00:00, run_after=2024-11-26T00:00:00+00:00
2025-02-22 11:40:14,832 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-24 00:00:00+00:00: scheduled__2024-11-24T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:14,833 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-24 00:00:00+00:00, run_id=scheduled__2024-11-24T00:00:00+00:00, run_start_date=2025-02-22 11:39:42.300693+00:00, run_end_date=2025-02-22 11:40:14.833283+00:00, run_duration=32.53259, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-24 00:00:00+00:00, data_interval_end=2024-11-25 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:14,839 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-25T00:00:00+00:00, run_after=2024-11-26T00:00:00+00:00
2025-02-22 11:40:14,895 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:14,896 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:14,896 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:14,896 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-25T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:14,901 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:14,902 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:14,902 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:14,902 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:14,951 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:17,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:19,331 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:19,331 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-25T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:19,340 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-25T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:18.606298+00:00, run_end_date=2025-02-22 11:40:18.821063+00:00, run_duration=0.214765, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1142, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:14.897550+00:00, queued_by_job_id=7, pid=73241
2025-02-22 11:40:19,340 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:16.375437+00:00, run_end_date=2025-02-22 11:40:16.748839+00:00, run_duration=0.373402, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1141, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:14.897550+00:00, queued_by_job_id=7, pid=73222
2025-02-22 11:40:19,932 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-26T00:00:00+00:00, run_after=2024-11-27T00:00:00+00:00
2025-02-22 11:40:20,012 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-25 00:00:00+00:00: scheduled__2024-11-25T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:20,013 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-25 00:00:00+00:00, run_id=scheduled__2024-11-25T00:00:00+00:00, run_start_date=2025-02-22 11:39:49.226155+00:00, run_end_date=2025-02-22 11:40:20.013001+00:00, run_duration=30.786846, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-25 00:00:00+00:00, data_interval_end=2024-11-26 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:20,019 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-26T00:00:00+00:00, run_after=2024-11-27T00:00:00+00:00
2025-02-22 11:40:20,075 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:20,075 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:20,076 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-26T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:20,079 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:20,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:20,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:22,394 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-26T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:22,401 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-26T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:21.649476+00:00, run_end_date=2025-02-22 11:40:21.926488+00:00, run_duration=0.277012, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1143, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:20.076958+00:00, queued_by_job_id=7, pid=73270
2025-02-22 11:40:22,836 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-28T00:00:00+00:00, run_after=2024-11-29T00:00:00+00:00
2025-02-22 11:40:23,180 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-26 00:00:00+00:00: scheduled__2024-11-26T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:23,181 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-26 00:00:00+00:00, run_id=scheduled__2024-11-26T00:00:00+00:00, run_start_date=2025-02-22 11:39:58.197671+00:00, run_end_date=2025-02-22 11:40:23.181192+00:00, run_duration=24.983521, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-26 00:00:00+00:00, data_interval_end=2024-11-27 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:23,188 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-27T00:00:00+00:00, run_after=2024-11-28T00:00:00+00:00
2025-02-22 11:40:23,270 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:23,271 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:23,271 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:23,274 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:40:23,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:23,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:25,419 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:25,427 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:24.643656+00:00, run_end_date=2025-02-22 11:40:24.992137+00:00, run_duration=0.348481, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1144, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:40:23.272074+00:00, queued_by_job_id=7, pid=73299
2025-02-22 11:40:25,712 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-28T00:00:00+00:00, run_after=2024-11-29T00:00:00+00:00
2025-02-22 11:40:25,826 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:25,827 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:25,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:25,831 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:40:25,831 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:25,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:27,935 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:27,943 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:27.203452+00:00, run_end_date=2025-02-22 11:40:27.463390+00:00, run_duration=0.259938, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1145, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:40:25.828423+00:00, queued_by_job_id=7, pid=73320
2025-02-22 11:40:28,204 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-29T00:00:00+00:00, run_after=2024-11-30T00:00:00+00:00
2025-02-22 11:40:28,402 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:28,402 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:28,403 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:28,403 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:28,408 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:40:28,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:28,413 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:28,413 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:28,457 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:30,587 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:32,890 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:32,890 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:32,899 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:32.099004+00:00, run_end_date=2025-02-22 11:40:32.375918+00:00, run_duration=0.276914, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1147, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:28.404322+00:00, queued_by_job_id=7, pid=73359
2025-02-22 11:40:32,899 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:29.822180+00:00, run_end_date=2025-02-22 11:40:30.080778+00:00, run_duration=0.258598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1146, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:40:28.404322+00:00, queued_by_job_id=7, pid=73340
2025-02-22 11:40:33,105 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-30T00:00:00+00:00, run_after=2024-12-01T00:00:00+00:00
2025-02-22 11:40:33,337 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:33,337 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:33,337 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:33,338 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:40:33,338 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-27T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:33,343 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:40:33,343 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:33,344 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:40:33,344 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:33,345 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:33,345 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:33,379 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:35,470 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:37,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:39,876 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:39,877 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:39,877 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-27T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:39,885 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-27T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:39.174185+00:00, run_end_date=2025-02-22 11:40:39.440378+00:00, run_duration=0.266193, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1150, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:33.339155+00:00, queued_by_job_id=7, pid=73426
2025-02-22 11:40:39,885 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:36.964644+00:00, run_end_date=2025-02-22 11:40:37.243059+00:00, run_duration=0.278415, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1149, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:40:33.339155+00:00, queued_by_job_id=7, pid=73407
2025-02-22 11:40:39,885 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:34.760930+00:00, run_end_date=2025-02-22 11:40:34.995765+00:00, run_duration=0.234835, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1148, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:40:33.339155+00:00, queued_by_job_id=7, pid=73380
2025-02-22 11:40:40,083 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-01T00:00:00+00:00, run_after=2024-12-02T00:00:00+00:00
2025-02-22 11:40:40,230 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-27 00:00:00+00:00: scheduled__2024-11-27T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:40,231 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-27 00:00:00+00:00, run_id=scheduled__2024-11-27T00:00:00+00:00, run_start_date=2025-02-22 11:40:22.969365+00:00, run_end_date=2025-02-22 11:40:40.231150+00:00, run_duration=17.261785, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-27 00:00:00+00:00, data_interval_end=2024-11-28 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:40,236 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-28T00:00:00+00:00, run_after=2024-11-29T00:00:00+00:00
2025-02-22 11:40:40,316 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:40,316 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:40,317 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:40,317 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:40:40,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:40,322 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-11-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:40:40,323 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:40,323 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:40:40,323 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:40,324 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:40,324 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:40,369 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:43,932 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:46,122 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:48,212 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-11-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:48,212 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:48,212 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:48,220 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:47.492658+00:00, run_end_date=2025-02-22 11:40:47.715992+00:00, run_duration=0.223334, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1153, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:40.318402+00:00, queued_by_job_id=7, pid=73484
2025-02-22 11:40:48,220 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:45.349604+00:00, run_end_date=2025-02-22 11:40:45.587269+00:00, run_duration=0.237665, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1152, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:40:40.318402+00:00, queued_by_job_id=7, pid=73465
2025-02-22 11:40:48,220 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-11-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:42.074101+00:00, run_end_date=2025-02-22 11:40:43.140293+00:00, run_duration=1.066192, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1151, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:40:40.318402+00:00, queued_by_job_id=7, pid=73447
2025-02-22 11:40:48,501 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-29T00:00:00+00:00, run_after=2024-11-30T00:00:00+00:00
2025-02-22 11:40:48,731 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:48,731 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:48,731 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:48,732 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:40:48,732 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-28T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:48,737 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-11-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:40:48,738 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:48,738 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:48,738 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:48,739 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:48,739 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:48,773 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:50,917 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:52,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:54,980 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-11-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:54,981 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:54,981 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-28T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:54,990 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-28T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:54.358689+00:00, run_end_date=2025-02-22 11:40:54.635498+00:00, run_duration=0.276809, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1156, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:48.733176+00:00, queued_by_job_id=7, pid=73559
2025-02-22 11:40:54,990 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:52.241654+00:00, run_end_date=2025-02-22 11:40:52.469774+00:00, run_duration=0.22812, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1155, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:48.733176+00:00, queued_by_job_id=7, pid=73539
2025-02-22 11:40:54,990 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-11-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:50.133405+00:00, run_end_date=2025-02-22 11:40:50.446772+00:00, run_duration=0.313367, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1154, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:40:48.733176+00:00, queued_by_job_id=7, pid=73521
2025-02-22 11:40:55,156 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-30T00:00:00+00:00, run_after=2024-12-01T00:00:00+00:00
2025-02-22 11:40:55,269 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-28 00:00:00+00:00: scheduled__2024-11-28T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:55,269 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-28 00:00:00+00:00, run_id=scheduled__2024-11-28T00:00:00+00:00, run_start_date=2025-02-22 11:40:28.282587+00:00, run_end_date=2025-02-22 11:40:55.269510+00:00, run_duration=26.986923, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-28 00:00:00+00:00, data_interval_end=2024-11-29 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:55,275 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-29T00:00:00+00:00, run_after=2024-11-30T00:00:00+00:00
2025-02-22 11:40:55,486 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:55,486 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:40:55,487 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:40:55,487 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-29T00:00:00+00:00 [scheduled]>
2025-02-22 11:40:55,492 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-11-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:40:55,493 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:55,493 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:40:55,493 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:55,537 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:57,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:40:59,716 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-11-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:59,716 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-29T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:40:59,724 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-29T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:58.958878+00:00, run_end_date=2025-02-22 11:40:59.292771+00:00, run_duration=0.333893, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1158, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:40:55.488214+00:00, queued_by_job_id=7, pid=73599
2025-02-22 11:40:59,724 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-11-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:40:56.884381+00:00, run_end_date=2025-02-22 11:40:57.128702+00:00, run_duration=0.244321, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1157, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:40:55.488214+00:00, queued_by_job_id=7, pid=73580
2025-02-22 11:40:59,875 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-30T00:00:00+00:00, run_after=2024-12-01T00:00:00+00:00
2025-02-22 11:40:59,962 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-29 00:00:00+00:00: scheduled__2024-11-29T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:40:59,963 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-29 00:00:00+00:00, run_id=scheduled__2024-11-29T00:00:00+00:00, run_start_date=2025-02-22 11:40:33.198838+00:00, run_end_date=2025-02-22 11:40:59.963142+00:00, run_duration=26.764304, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-29 00:00:00+00:00, data_interval_end=2024-11-30 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:40:59,969 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-11-30T00:00:00+00:00, run_after=2024-12-01T00:00:00+00:00
2025-02-22 11:41:00,010 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:00,010 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:00,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-11-30T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:00,014 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-11-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:00,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:00,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-11-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:02,013 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-11-30T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:02,021 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-11-30T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:01.373723+00:00, run_end_date=2025-02-22 11:41:01.611850+00:00, run_duration=0.238127, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1159, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:00.011887+00:00, queued_by_job_id=7, pid=73619
2025-02-22 11:41:02,213 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-01T00:00:00+00:00, run_after=2024-12-02T00:00:00+00:00
2025-02-22 11:41:02,300 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-11-30 00:00:00+00:00: scheduled__2024-11-30T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:02,301 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-11-30 00:00:00+00:00, run_id=scheduled__2024-11-30T00:00:00+00:00, run_start_date=2025-02-22 11:40:40.149979+00:00, run_end_date=2025-02-22 11:41:02.301352+00:00, run_duration=22.151373, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-11-30 00:00:00+00:00, data_interval_end=2024-12-01 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:02,308 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-01T00:00:00+00:00, run_after=2024-12-02T00:00:00+00:00
2025-02-22 11:41:03,510 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-02T00:00:00+00:00, run_after=2024-12-03T00:00:00+00:00
2025-02-22 11:41:03,714 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:03,714 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:03,714 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:03,716 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:03,716 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:03,751 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:06,120 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:06,128 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:05.328069+00:00, run_end_date=2025-02-22 11:41:05.612927+00:00, run_duration=0.284858, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1160, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:03.714972+00:00, queued_by_job_id=7, pid=73643
2025-02-22 11:41:06,384 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-03T00:00:00+00:00, run_after=2024-12-04T00:00:00+00:00
2025-02-22 11:41:06,552 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:06,552 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:06,552 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:06,553 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:06,557 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:06,557 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:06,557 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:06,558 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:06,574 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:08,763 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:10,957 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:10,957 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:10,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:10.229549+00:00, run_end_date=2025-02-22 11:41:10.478486+00:00, run_duration=0.248937, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1162, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:06.553707+00:00, queued_by_job_id=7, pid=73691
2025-02-22 11:41:10,966 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:07.996785+00:00, run_end_date=2025-02-22 11:41:08.239523+00:00, run_duration=0.242738, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1161, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:06.553707+00:00, queued_by_job_id=7, pid=73663
2025-02-22 11:41:11,259 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-04T00:00:00+00:00, run_after=2024-12-05T00:00:00+00:00
2025-02-22 11:41:11,451 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:11,451 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:11,451 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:11,451 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:41:11,451 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:11,454 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:11,454 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:11,454 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:11,454 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:11,455 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:41:11,455 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:11,496 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:13,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:15,916 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:18,141 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:18,142 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:18,142 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:18,150 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:17.327418+00:00, run_end_date=2025-02-22 11:41:17.608580+00:00, run_duration=0.281162, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1165, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:41:11.452313+00:00, queued_by_job_id=7, pid=73750
2025-02-22 11:41:18,150 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:15.046745+00:00, run_end_date=2025-02-22 11:41:15.437782+00:00, run_duration=0.391037, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1164, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:11.452313+00:00, queued_by_job_id=7, pid=73731
2025-02-22 11:41:18,151 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:12.890203+00:00, run_end_date=2025-02-22 11:41:13.127402+00:00, run_duration=0.237199, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1163, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:11.452313+00:00, queued_by_job_id=7, pid=73711
2025-02-22 11:41:18,464 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-05T00:00:00+00:00, run_after=2024-12-06T00:00:00+00:00
2025-02-22 11:41:18,962 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:18,963 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:18,963 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:18,963 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:41:18,963 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:41:18,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-01T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:18,968 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:18,968 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:18,969 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:18,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:18,969 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:41:18,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:18,970 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:18,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:19,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:21,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:24,046 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:26,279 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:28,355 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:28,355 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:28,355 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:28,355 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-01T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:28,364 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-01T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:27.593969+00:00, run_end_date=2025-02-22 11:41:27.853175+00:00, run_duration=0.259206, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1169, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:18.964543+00:00, queued_by_job_id=7, pid=73845
2025-02-22 11:41:28,364 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:25.512932+00:00, run_end_date=2025-02-22 11:41:25.794278+00:00, run_duration=0.281346, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1168, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:41:18.964543+00:00, queued_by_job_id=7, pid=73826
2025-02-22 11:41:28,364 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:22.914923+00:00, run_end_date=2025-02-22 11:41:23.575699+00:00, run_duration=0.660776, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1167, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:18.964543+00:00, queued_by_job_id=7, pid=73806
2025-02-22 11:41:28,365 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:20.394197+00:00, run_end_date=2025-02-22 11:41:21.007850+00:00, run_duration=0.613653, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1166, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:18.964543+00:00, queued_by_job_id=7, pid=73780
2025-02-22 11:41:28,673 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-06T00:00:00+00:00, run_after=2024-12-07T00:00:00+00:00
2025-02-22 11:41:28,818 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-01 00:00:00+00:00: scheduled__2024-12-01T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:28,818 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-01 00:00:00+00:00, run_id=scheduled__2024-12-01T00:00:00+00:00, run_start_date=2025-02-22 11:41:03.595715+00:00, run_end_date=2025-02-22 11:41:28.818421+00:00, run_duration=25.222706, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-01 00:00:00+00:00, data_interval_end=2024-12-02 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:28,822 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-02T00:00:00+00:00, run_after=2024-12-03T00:00:00+00:00
2025-02-22 11:41:28,913 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:28,913 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:28,913 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:28,914 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:41:28,914 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:41:28,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-02T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:28,920 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:28,921 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:28,921 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:28,921 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:28,922 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:41:28,922 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:28,922 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:28,923 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:28,982 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:31,155 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:33,306 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:35,571 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:37,668 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:37,668 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:37,669 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:37,669 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-02T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:37,677 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-02T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:37.026000+00:00, run_end_date=2025-02-22 11:41:37.363219+00:00, run_duration=0.337219, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1173, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:28.915374+00:00, queued_by_job_id=7, pid=73923
2025-02-22 11:41:37,678 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:34.766672+00:00, run_end_date=2025-02-22 11:41:35.133689+00:00, run_duration=0.367017, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1172, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:41:28.915374+00:00, queued_by_job_id=7, pid=73904
2025-02-22 11:41:37,678 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:32.622224+00:00, run_end_date=2025-02-22 11:41:32.842272+00:00, run_duration=0.220048, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1171, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:28.915374+00:00, queued_by_job_id=7, pid=73885
2025-02-22 11:41:37,678 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:30.418787+00:00, run_end_date=2025-02-22 11:41:30.695669+00:00, run_duration=0.276882, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1170, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:28.915374+00:00, queued_by_job_id=7, pid=73866
2025-02-22 11:41:37,895 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-03T00:00:00+00:00, run_after=2024-12-04T00:00:00+00:00
2025-02-22 11:41:38,014 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-02 00:00:00+00:00: scheduled__2024-12-02T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:38,015 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-02 00:00:00+00:00, run_id=scheduled__2024-12-02T00:00:00+00:00, run_start_date=2025-02-22 11:41:06.432357+00:00, run_end_date=2025-02-22 11:41:38.015134+00:00, run_duration=31.582777, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-02 00:00:00+00:00, data_interval_end=2024-12-03 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:38,020 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-03T00:00:00+00:00, run_after=2024-12-04T00:00:00+00:00
2025-02-22 11:41:38,064 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:38,065 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:38,065 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:38,065 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:41:38,065 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-03T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:38,070 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:38,071 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:38,071 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:41:38,071 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:38,072 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:38,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:38,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:40,143 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:42,229 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:44,321 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:44,322 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:44,322 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-03T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:44,330 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-03T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:43.591073+00:00, run_end_date=2025-02-22 11:41:43.901034+00:00, run_duration=0.309961, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1176, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:38.066693+00:00, queued_by_job_id=7, pid=73981
2025-02-22 11:41:44,330 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:41.478460+00:00, run_end_date=2025-02-22 11:41:41.732278+00:00, run_duration=0.253818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1175, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:41:38.066693+00:00, queued_by_job_id=7, pid=73963
2025-02-22 11:41:44,331 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:39.472375+00:00, run_end_date=2025-02-22 11:41:39.707647+00:00, run_duration=0.235272, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1174, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:38.066693+00:00, queued_by_job_id=7, pid=73943
2025-02-22 11:41:44,535 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-04T00:00:00+00:00, run_after=2024-12-05T00:00:00+00:00
2025-02-22 11:41:44,647 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-03 00:00:00+00:00: scheduled__2024-12-03T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:44,648 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-03 00:00:00+00:00, run_id=scheduled__2024-12-03T00:00:00+00:00, run_start_date=2025-02-22 11:41:11.345541+00:00, run_end_date=2025-02-22 11:41:44.648446+00:00, run_duration=33.302905, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-03 00:00:00+00:00, data_interval_end=2024-12-04 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:44,654 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-04T00:00:00+00:00, run_after=2024-12-05T00:00:00+00:00
2025-02-22 11:41:44,730 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:44,731 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:44,731 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:44,731 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-04T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:44,736 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:41:44,737 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:44,737 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:44,737 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:44,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:47,009 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:49,247 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:49,248 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-04T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:49,255 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-04T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:48.530282+00:00, run_end_date=2025-02-22 11:41:48.780044+00:00, run_duration=0.249762, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1178, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:44.732481+00:00, queued_by_job_id=7, pid=74029
2025-02-22 11:41:49,256 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:46.203968+00:00, run_end_date=2025-02-22 11:41:46.517997+00:00, run_duration=0.314029, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1177, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:41:44.732481+00:00, queued_by_job_id=7, pid=74002
2025-02-22 11:41:49,497 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-05T00:00:00+00:00, run_after=2024-12-06T00:00:00+00:00
2025-02-22 11:41:49,598 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-04 00:00:00+00:00: scheduled__2024-12-04T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:49,598 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-04 00:00:00+00:00, run_id=scheduled__2024-12-04T00:00:00+00:00, run_start_date=2025-02-22 11:41:18.814567+00:00, run_end_date=2025-02-22 11:41:49.598606+00:00, run_duration=30.784039, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-04 00:00:00+00:00, data_interval_end=2024-12-05 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:49,605 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-05T00:00:00+00:00, run_after=2024-12-06T00:00:00+00:00
2025-02-22 11:41:49,647 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:49,648 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:49,648 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-05T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:49,652 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:41:49,652 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:49,690 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:51,754 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-05T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:51,761 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-05T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:51.088332+00:00, run_end_date=2025-02-22 11:41:51.341103+00:00, run_duration=0.252771, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1179, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:41:49.649440+00:00, queued_by_job_id=7, pid=74049
2025-02-22 11:41:52,016 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-06T00:00:00+00:00, run_after=2024-12-07T00:00:00+00:00
2025-02-22 11:41:52,087 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-05 00:00:00+00:00: scheduled__2024-12-05T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:41:52,088 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-05 00:00:00+00:00, run_id=scheduled__2024-12-05T00:00:00+00:00, run_start_date=2025-02-22 11:41:28.733190+00:00, run_end_date=2025-02-22 11:41:52.088544+00:00, run_duration=23.355354, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-05 00:00:00+00:00, data_interval_end=2024-12-06 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:41:52,095 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-06T00:00:00+00:00, run_after=2024-12-07T00:00:00+00:00
2025-02-22 11:41:53,482 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-07T00:00:00+00:00, run_after=2024-12-08T00:00:00+00:00
2025-02-22 11:41:53,676 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:53,676 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:53,677 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:53,680 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:53,681 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:53,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:55,868 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:41:55,876 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:55.070301+00:00, run_end_date=2025-02-22 11:41:55.385634+00:00, run_duration=0.315333, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1180, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:53.678097+00:00, queued_by_job_id=7, pid=74072
2025-02-22 11:41:56,035 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-08T00:00:00+00:00, run_after=2024-12-09T00:00:00+00:00
2025-02-22 11:41:56,212 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:56,212 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:41:56,212 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:41:56,212 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:41:56,215 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:41:56,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:56,215 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:41:56,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:56,239 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:41:58,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:00,477 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:00,477 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:00,485 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:59.744377+00:00, run_end_date=2025-02-22 11:41:59.959197+00:00, run_duration=0.21482, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1182, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:41:56.213000+00:00, queued_by_job_id=7, pid=74129
2025-02-22 11:42:00,485 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:41:57.680078+00:00, run_end_date=2025-02-22 11:41:57.996343+00:00, run_duration=0.316265, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1181, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:41:56.213000+00:00, queued_by_job_id=7, pid=74094
2025-02-22 11:42:00,781 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-09T00:00:00+00:00, run_after=2024-12-10T00:00:00+00:00
2025-02-22 11:42:00,937 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:00,937 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:00,937 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:00,937 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:00,937 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:00,941 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:00,941 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:00,942 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:00,942 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:00,942 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:00,942 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:00,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:03,376 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:05,499 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:07,776 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:07,777 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:07,777 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:07,785 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:06.950065+00:00, run_end_date=2025-02-22 11:42:07.345370+00:00, run_duration=0.395305, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1185, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:00.938513+00:00, queued_by_job_id=7, pid=74188
2025-02-22 11:42:07,785 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:04.735260+00:00, run_end_date=2025-02-22 11:42:05.014040+00:00, run_duration=0.27878, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1184, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:00.938513+00:00, queued_by_job_id=7, pid=74168
2025-02-22 11:42:07,785 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:02.337779+00:00, run_end_date=2025-02-22 11:42:02.837866+00:00, run_duration=0.500087, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1183, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:00.938513+00:00, queued_by_job_id=7, pid=74149
2025-02-22 11:42:07,842 INFO - Resetting orphaned tasks for active dag runs
2025-02-22 11:42:08,169 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-10T00:00:00+00:00, run_after=2024-12-11T00:00:00+00:00
2025-02-22 11:42:08,404 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:08,405 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:08,405 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:08,405 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:08,405 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:42:08,406 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-06T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:08,410 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:08,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:08,411 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:08,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:08,412 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:08,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:08,412 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:08,413 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:08,456 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:10,612 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:12,857 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:15,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:17,266 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:17,266 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:17,266 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:17,266 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-06T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:17,272 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-06T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:16.535345+00:00, run_end_date=2025-02-22 11:42:16.895474+00:00, run_duration=0.360129, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1189, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:08.406809+00:00, queued_by_job_id=7, pid=74266
2025-02-22 11:42:17,273 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:14.302190+00:00, run_end_date=2025-02-22 11:42:14.555965+00:00, run_duration=0.253775, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1188, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:08.406809+00:00, queued_by_job_id=7, pid=74247
2025-02-22 11:42:17,273 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:11.963019+00:00, run_end_date=2025-02-22 11:42:12.391438+00:00, run_duration=0.428419, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1187, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:08.406809+00:00, queued_by_job_id=7, pid=74228
2025-02-22 11:42:17,273 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:09.812132+00:00, run_end_date=2025-02-22 11:42:10.096025+00:00, run_duration=0.283893, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1186, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:08.406809+00:00, queued_by_job_id=7, pid=74209
2025-02-22 11:42:17,473 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-11T00:00:00+00:00, run_after=2024-12-12T00:00:00+00:00
2025-02-22 11:42:17,639 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-06 00:00:00+00:00: scheduled__2024-12-06T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:42:17,640 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-06 00:00:00+00:00, run_id=scheduled__2024-12-06T00:00:00+00:00, run_start_date=2025-02-22 11:41:53.549167+00:00, run_end_date=2025-02-22 11:42:17.640050+00:00, run_duration=24.090883, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-06 00:00:00+00:00, data_interval_end=2024-12-07 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:42:17,644 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-07T00:00:00+00:00, run_after=2024-12-08T00:00:00+00:00
2025-02-22 11:42:17,707 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:17,707 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:17,707 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:17,708 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:17,708 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:42:17,708 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-07T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:17,712 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:17,713 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:17,713 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:17,713 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:17,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:17,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:17,714 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:17,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:17,758 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:19,901 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:22,290 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:24,334 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:26,524 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:26,525 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:26,525 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:26,525 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-07T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:26,534 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-07T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:25.684037+00:00, run_end_date=2025-02-22 11:42:26.165467+00:00, run_duration=0.48143, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1193, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:17.709098+00:00, queued_by_job_id=7, pid=74345
2025-02-22 11:42:26,534 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:23.583578+00:00, run_end_date=2025-02-22 11:42:23.806957+00:00, run_duration=0.223379, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1192, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:17.709098+00:00, queued_by_job_id=7, pid=74325
2025-02-22 11:42:26,534 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:21.349414+00:00, run_end_date=2025-02-22 11:42:21.767404+00:00, run_duration=0.41799, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1191, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:17.709098+00:00, queued_by_job_id=7, pid=74306
2025-02-22 11:42:26,534 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:19.142710+00:00, run_end_date=2025-02-22 11:42:19.402806+00:00, run_duration=0.260096, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1190, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:17.709098+00:00, queued_by_job_id=7, pid=74287
2025-02-22 11:42:26,825 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-08T00:00:00+00:00, run_after=2024-12-09T00:00:00+00:00
2025-02-22 11:42:26,944 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-07 00:00:00+00:00: scheduled__2024-12-07T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:42:26,944 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-07 00:00:00+00:00, run_id=scheduled__2024-12-07T00:00:00+00:00, run_start_date=2025-02-22 11:41:56.101346+00:00, run_end_date=2025-02-22 11:42:26.944569+00:00, run_duration=30.843223, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-07 00:00:00+00:00, data_interval_end=2024-12-08 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:42:26,952 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-08T00:00:00+00:00, run_after=2024-12-09T00:00:00+00:00
2025-02-22 11:42:26,982 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:26,982 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:26,982 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:26,982 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:26,983 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-08T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:26,986 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:26,986 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:26,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:26,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:26,987 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:26,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:27,006 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:29,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:31,187 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:33,049 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:33,049 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:33,050 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-08T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:33,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-08T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:32.499222+00:00, run_end_date=2025-02-22 11:42:32.688489+00:00, run_duration=0.189267, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1196, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:26.983589+00:00, queued_by_job_id=7, pid=74411
2025-02-22 11:42:33,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:30.458528+00:00, run_end_date=2025-02-22 11:42:30.707100+00:00, run_duration=0.248572, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1195, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:26.983589+00:00, queued_by_job_id=7, pid=74392
2025-02-22 11:42:33,058 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:28.355094+00:00, run_end_date=2025-02-22 11:42:28.609504+00:00, run_duration=0.25441, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1194, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:26.983589+00:00, queued_by_job_id=7, pid=74373
2025-02-22 11:42:33,241 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-09T00:00:00+00:00, run_after=2024-12-10T00:00:00+00:00
2025-02-22 11:42:33,342 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-08 00:00:00+00:00: scheduled__2024-12-08T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:42:33,342 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-08 00:00:00+00:00, run_id=scheduled__2024-12-08T00:00:00+00:00, run_start_date=2025-02-22 11:42:00.850214+00:00, run_end_date=2025-02-22 11:42:33.342578+00:00, run_duration=32.492364, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-08 00:00:00+00:00, data_interval_end=2024-12-09 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:42:33,348 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-09T00:00:00+00:00, run_after=2024-12-10T00:00:00+00:00
2025-02-22 11:42:33,380 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:33,380 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:33,381 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:33,381 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-09T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:33,385 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:33,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:33,385 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:33,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:33,423 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:35,509 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:37,590 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:37,591 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-09T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:37,599 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-09T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:36.986430+00:00, run_end_date=2025-02-22 11:42:37.243778+00:00, run_duration=0.257348, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1198, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:33.381948+00:00, queued_by_job_id=7, pid=74450
2025-02-22 11:42:37,599 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:34.739988+00:00, run_end_date=2025-02-22 11:42:35.050248+00:00, run_duration=0.31026, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1197, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:33.381948+00:00, queued_by_job_id=7, pid=74431
2025-02-22 11:42:37,837 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-10T00:00:00+00:00, run_after=2024-12-11T00:00:00+00:00
2025-02-22 11:42:37,936 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-09 00:00:00+00:00: scheduled__2024-12-09T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:42:37,936 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-09 00:00:00+00:00, run_id=scheduled__2024-12-09T00:00:00+00:00, run_start_date=2025-02-22 11:42:08.267637+00:00, run_end_date=2025-02-22 11:42:37.936636+00:00, run_duration=29.668999, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-09 00:00:00+00:00, data_interval_end=2024-12-10 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:42:37,943 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-10T00:00:00+00:00, run_after=2024-12-11T00:00:00+00:00
2025-02-22 11:42:37,993 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:37,993 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:37,993 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-10T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:37,997 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:37,998 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:38,029 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:40,115 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-10T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:40,122 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-10T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:39.407438+00:00, run_end_date=2025-02-22 11:42:39.671733+00:00, run_duration=0.264295, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1199, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:37.994759+00:00, queued_by_job_id=7, pid=74478
2025-02-22 11:42:40,320 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-11T00:00:00+00:00, run_after=2024-12-12T00:00:00+00:00
2025-02-22 11:42:40,389 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-10 00:00:00+00:00: scheduled__2024-12-10T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:42:40,390 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-10 00:00:00+00:00, run_id=scheduled__2024-12-10T00:00:00+00:00, run_start_date=2025-02-22 11:42:17.563439+00:00, run_end_date=2025-02-22 11:42:40.390316+00:00, run_duration=22.826877, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-10 00:00:00+00:00, data_interval_end=2024-12-11 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:42:40,396 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-11T00:00:00+00:00, run_after=2024-12-12T00:00:00+00:00
2025-02-22 11:42:41,682 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-12T00:00:00+00:00, run_after=2024-12-13T00:00:00+00:00
2025-02-22 11:42:41,885 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:41,886 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:41,886 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:41,890 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:41,890 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:41,925 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:43,979 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:43,986 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:43.280459+00:00, run_end_date=2025-02-22 11:42:43.494984+00:00, run_duration=0.214525, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1200, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:41.887735+00:00, queued_by_job_id=7, pid=74508
2025-02-22 11:42:44,230 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-13T00:00:00+00:00, run_after=2024-12-14T00:00:00+00:00
2025-02-22 11:42:44,414 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:44,415 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:44,415 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:44,415 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:44,420 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:44,421 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:44,421 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:44,422 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:44,466 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:46,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:48,732 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:48,733 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:48,741 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:47.999931+00:00, run_end_date=2025-02-22 11:42:48.273324+00:00, run_duration=0.273393, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1202, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:44.416464+00:00, queued_by_job_id=7, pid=74549
2025-02-22 11:42:48,741 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:45.845957+00:00, run_end_date=2025-02-22 11:42:46.114937+00:00, run_duration=0.26898, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1201, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:44.416464+00:00, queued_by_job_id=7, pid=74529
2025-02-22 11:42:49,040 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-14T00:00:00+00:00, run_after=2024-12-15T00:00:00+00:00
2025-02-22 11:42:49,253 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:49,253 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:49,253 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:49,253 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:49,253 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:49,257 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:49,257 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:49,258 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:49,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:49,258 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:49,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:49,292 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:51,371 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:53,570 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:55,729 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:55,731 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:55,731 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:42:55,749 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:55.001412+00:00, run_end_date=2025-02-22 11:42:55.271781+00:00, run_duration=0.270369, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1205, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:49.254516+00:00, queued_by_job_id=7, pid=74608
2025-02-22 11:42:55,749 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:52.837907+00:00, run_end_date=2025-02-22 11:42:53.074314+00:00, run_duration=0.236407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1204, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:49.254516+00:00, queued_by_job_id=7, pid=74589
2025-02-22 11:42:55,750 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:50.656269+00:00, run_end_date=2025-02-22 11:42:50.890968+00:00, run_duration=0.234699, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1203, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:49.254516+00:00, queued_by_job_id=7, pid=74570
2025-02-22 11:42:55,967 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-15T00:00:00+00:00, run_after=2024-12-16T00:00:00+00:00
2025-02-22 11:42:56,186 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:56,186 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:42:56,186 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:42:56,187 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:42:56,187 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:42:56,187 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-11T00:00:00+00:00 [scheduled]>
2025-02-22 11:42:56,191 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:42:56,191 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:56,192 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:42:56,192 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:56,192 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:42:56,192 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:56,193 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:42:56,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:56,254 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:42:58,425 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:00,669 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:02,725 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:04,657 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:04,657 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:04,657 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:04,658 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-11T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:04,666 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-11T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:04.063011+00:00, run_end_date=2025-02-22 11:43:04.293736+00:00, run_duration=0.230725, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1209, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:42:56.187977+00:00, queued_by_job_id=7, pid=74694
2025-02-22 11:43:04,666 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:01.980481+00:00, run_end_date=2025-02-22 11:43:02.225603+00:00, run_duration=0.245122, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1208, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:42:56.187977+00:00, queued_by_job_id=7, pid=74675
2025-02-22 11:43:04,666 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:59.888831+00:00, run_end_date=2025-02-22 11:43:00.167275+00:00, run_duration=0.278444, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1207, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:42:56.187977+00:00, queued_by_job_id=7, pid=74656
2025-02-22 11:43:04,667 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:42:57.664340+00:00, run_end_date=2025-02-22 11:42:57.935430+00:00, run_duration=0.27109, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1206, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:42:56.187977+00:00, queued_by_job_id=7, pid=74629
2025-02-22 11:43:04,941 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-16T00:00:00+00:00, run_after=2024-12-17T00:00:00+00:00
2025-02-22 11:43:05,102 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-11 00:00:00+00:00: scheduled__2024-12-11T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:05,102 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-11 00:00:00+00:00, run_id=scheduled__2024-12-11T00:00:00+00:00, run_start_date=2025-02-22 11:42:41.775332+00:00, run_end_date=2025-02-22 11:43:05.102824+00:00, run_duration=23.327492, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-11 00:00:00+00:00, data_interval_end=2024-12-12 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:05,107 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-12T00:00:00+00:00, run_after=2024-12-13T00:00:00+00:00
2025-02-22 11:43:05,189 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:05,189 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:05,189 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:05,189 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:43:05,190 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:43:05,190 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-12T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:05,195 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:05,196 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:05,196 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:05,197 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:05,197 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:05,197 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:05,198 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:05,198 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:05,243 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:07,327 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:09,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:11,494 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:13,638 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:13,639 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:13,639 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:13,639 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-12T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:13,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-12T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:12.909317+00:00, run_end_date=2025-02-22 11:43:13.207339+00:00, run_duration=0.298022, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1213, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:05.191276+00:00, queued_by_job_id=7, pid=74779
2025-02-22 11:43:13,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:10.798327+00:00, run_end_date=2025-02-22 11:43:11.040424+00:00, run_duration=0.242097, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1212, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:05.191276+00:00, queued_by_job_id=7, pid=74760
2025-02-22 11:43:13,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:08.665433+00:00, run_end_date=2025-02-22 11:43:08.882873+00:00, run_duration=0.21744, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1211, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:05.191276+00:00, queued_by_job_id=7, pid=74733
2025-02-22 11:43:13,648 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:06.593228+00:00, run_end_date=2025-02-22 11:43:06.842617+00:00, run_duration=0.249389, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1210, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:05.191276+00:00, queued_by_job_id=7, pid=74715
2025-02-22 11:43:13,944 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-13T00:00:00+00:00, run_after=2024-12-14T00:00:00+00:00
2025-02-22 11:43:14,024 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-12 00:00:00+00:00: scheduled__2024-12-12T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:14,024 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-12 00:00:00+00:00, run_id=scheduled__2024-12-12T00:00:00+00:00, run_start_date=2025-02-22 11:42:44.304739+00:00, run_end_date=2025-02-22 11:43:14.024919+00:00, run_duration=29.72018, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-12 00:00:00+00:00, data_interval_end=2024-12-13 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:14,029 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-13T00:00:00+00:00, run_after=2024-12-14T00:00:00+00:00
2025-02-22 11:43:14,074 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:14,074 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:14,075 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:14,075 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:43:14,075 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-13T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:14,079 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:14,080 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:14,080 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:14,080 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:14,081 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:14,081 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:14,127 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:16,250 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:18,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:20,434 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:20,435 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:20,435 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-13T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:20,443 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-13T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:19.774640+00:00, run_end_date=2025-02-22 11:43:20.044542+00:00, run_duration=0.269902, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1216, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:14.076163+00:00, queued_by_job_id=7, pid=74847
2025-02-22 11:43:20,444 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:17.574206+00:00, run_end_date=2025-02-22 11:43:17.870474+00:00, run_duration=0.296268, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1215, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:14.076163+00:00, queued_by_job_id=7, pid=74820
2025-02-22 11:43:20,444 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:15.551175+00:00, run_end_date=2025-02-22 11:43:15.788802+00:00, run_duration=0.237627, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1214, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:14.076163+00:00, queued_by_job_id=7, pid=74801
2025-02-22 11:43:20,636 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-14T00:00:00+00:00, run_after=2024-12-15T00:00:00+00:00
2025-02-22 11:43:20,755 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-13 00:00:00+00:00: scheduled__2024-12-13T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:20,756 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-13 00:00:00+00:00, run_id=scheduled__2024-12-13T00:00:00+00:00, run_start_date=2025-02-22 11:42:49.134092+00:00, run_end_date=2025-02-22 11:43:20.756011+00:00, run_duration=31.621919, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-13 00:00:00+00:00, data_interval_end=2024-12-14 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:20,761 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-14T00:00:00+00:00, run_after=2024-12-15T00:00:00+00:00
2025-02-22 11:43:20,813 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:20,814 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:20,814 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:20,814 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-14T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:20,820 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:20,820 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:20,820 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:20,821 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:20,886 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:22,888 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:25,031 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:25,031 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-14T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:25,037 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-14T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:24.316578+00:00, run_end_date=2025-02-22 11:43:24.605672+00:00, run_duration=0.289094, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1218, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:20.815725+00:00, queued_by_job_id=7, pid=74886
2025-02-22 11:43:25,037 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:22.230617+00:00, run_end_date=2025-02-22 11:43:22.452964+00:00, run_duration=0.222347, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1217, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:20.815725+00:00, queued_by_job_id=7, pid=74867
2025-02-22 11:43:25,463 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-15T00:00:00+00:00, run_after=2024-12-16T00:00:00+00:00
2025-02-22 11:43:25,571 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-14 00:00:00+00:00: scheduled__2024-12-14T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:25,572 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-14 00:00:00+00:00, run_id=scheduled__2024-12-14T00:00:00+00:00, run_start_date=2025-02-22 11:42:56.062471+00:00, run_end_date=2025-02-22 11:43:25.572298+00:00, run_duration=29.509827, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-14 00:00:00+00:00, data_interval_end=2024-12-15 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:25,579 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-15T00:00:00+00:00, run_after=2024-12-16T00:00:00+00:00
2025-02-22 11:43:25,638 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:25,638 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:25,638 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-15T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:25,642 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:25,643 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:25,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:27,757 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-15T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:27,765 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-15T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:27.065636+00:00, run_end_date=2025-02-22 11:43:27.371196+00:00, run_duration=0.30556, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1219, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:25.639732+00:00, queued_by_job_id=7, pid=74916
2025-02-22 11:43:28,269 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-16T00:00:00+00:00, run_after=2024-12-17T00:00:00+00:00
2025-02-22 11:43:28,363 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-15 00:00:00+00:00: scheduled__2024-12-15T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:28,364 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-15 00:00:00+00:00, run_id=scheduled__2024-12-15T00:00:00+00:00, run_start_date=2025-02-22 11:43:05.024496+00:00, run_end_date=2025-02-22 11:43:28.364031+00:00, run_duration=23.339535, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-15 00:00:00+00:00, data_interval_end=2024-12-16 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:28,371 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-16T00:00:00+00:00, run_after=2024-12-17T00:00:00+00:00
2025-02-22 11:43:29,858 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-17T00:00:00+00:00, run_after=2024-12-18T00:00:00+00:00
2025-02-22 11:43:31,216 INFO - 1 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:31,217 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:31,217 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:31,220 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:31,220 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:31,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:33,324 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:33,332 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:32.643111+00:00, run_end_date=2025-02-22 11:43:32.886182+00:00, run_duration=0.243071, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1220, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:31.218329+00:00, queued_by_job_id=7, pid=74955
2025-02-22 11:43:33,636 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-18T00:00:00+00:00, run_after=2024-12-19T00:00:00+00:00
2025-02-22 11:43:33,836 INFO - 2 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:33,836 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:33,837 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:33,837 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:33,841 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:33,841 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:33,842 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:33,842 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:33,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:36,156 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:38,498 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:38,498 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:38,506 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:37.679737+00:00, run_end_date=2025-02-22 11:43:37.979872+00:00, run_duration=0.300135, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1222, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:33.837898+00:00, queued_by_job_id=7, pid=75003
2025-02-22 11:43:38,506 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:35.332590+00:00, run_end_date=2025-02-22 11:43:35.674924+00:00, run_duration=0.342334, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1221, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:33.837898+00:00, queued_by_job_id=7, pid=74976
2025-02-22 11:43:38,800 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-19T00:00:00+00:00, run_after=2024-12-20T00:00:00+00:00
2025-02-22 11:43:39,025 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:39,025 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:39,025 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:39,025 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:43:39,025 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:39,029 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:39,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:39,030 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:39,030 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:39,030 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:39,030 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:39,084 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:41,164 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:43,404 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:45,649 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:45,650 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:45,650 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:45,664 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:44.961701+00:00, run_end_date=2025-02-22 11:43:45.217246+00:00, run_duration=0.255545, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1225, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:39.026548+00:00, queued_by_job_id=7, pid=75062
2025-02-22 11:43:45,665 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:42.654260+00:00, run_end_date=2025-02-22 11:43:42.897113+00:00, run_duration=0.242853, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1224, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:39.026548+00:00, queued_by_job_id=7, pid=75043
2025-02-22 11:43:45,665 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:40.410836+00:00, run_end_date=2025-02-22 11:43:40.678921+00:00, run_duration=0.268085, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1223, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:39.026548+00:00, queued_by_job_id=7, pid=75023
2025-02-22 11:43:45,994 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-20T00:00:00+00:00, run_after=2024-12-21T00:00:00+00:00
2025-02-22 11:43:46,230 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:46,230 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:46,231 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:46,231 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:43:46,231 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:43:46,231 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-16T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:46,237 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:46,237 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:46,238 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:46,238 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:46,239 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:46,239 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:46,239 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:46,239 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:46,285 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:48,344 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:50,395 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:52,582 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:54,652 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:54,653 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:54,653 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:54,653 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-16T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:43:54,662 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-16T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:54.032403+00:00, run_end_date=2025-02-22 11:43:54.302093+00:00, run_duration=0.26969, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1229, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:46.232750+00:00, queued_by_job_id=7, pid=75149
2025-02-22 11:43:54,662 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:51.732192+00:00, run_end_date=2025-02-22 11:43:51.974412+00:00, run_duration=0.24222, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:46.232750+00:00, queued_by_job_id=7, pid=75130
2025-02-22 11:43:54,662 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:49.700083+00:00, run_end_date=2025-02-22 11:43:49.910845+00:00, run_duration=0.210762, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1227, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:46.232750+00:00, queued_by_job_id=7, pid=75111
2025-02-22 11:43:54,662 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:47.619826+00:00, run_end_date=2025-02-22 11:43:47.833992+00:00, run_duration=0.214166, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1226, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:46.232750+00:00, queued_by_job_id=7, pid=75092
2025-02-22 11:43:54,855 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-21T00:00:00+00:00, run_after=2024-12-22T00:00:00+00:00
2025-02-22 11:43:55,016 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-16 00:00:00+00:00: scheduled__2024-12-16T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:43:55,018 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-16 00:00:00+00:00, run_id=scheduled__2024-12-16T00:00:00+00:00, run_start_date=2025-02-22 11:43:30.176598+00:00, run_end_date=2025-02-22 11:43:55.018713+00:00, run_duration=24.842115, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-16 00:00:00+00:00, data_interval_end=2024-12-17 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:43:55,023 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-17T00:00:00+00:00, run_after=2024-12-18T00:00:00+00:00
2025-02-22 11:43:55,114 INFO - 4 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:55,115 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:43:55,115 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:43:55,115 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:43:55,116 INFO - DAG lead_scoring_data_pipeline has 3/16 running and queued tasks
2025-02-22 11:43:55,116 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.build_dbs scheduled__2024-12-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-17T00:00:00+00:00 [scheduled]>
2025-02-22 11:43:55,121 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='build_dbs', run_id='scheduled__2024-12-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-02-22 11:43:55,122 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:55,122 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:43:55,123 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:55,123 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:43:55,123 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:55,124 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:43:55,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:55,162 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'build_dbs', 'scheduled__2024-12-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:57,264 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:43:59,355 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:44:01,580 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:44:03,693 INFO - Executor reports execution of lead_scoring_data_pipeline.build_dbs run_id=scheduled__2024-12-20T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:44:03,694 INFO - Executor reports execution of lead_scoring_data_pipeline.load_data_into_db run_id=scheduled__2024-12-19T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:44:03,694 INFO - Executor reports execution of lead_scoring_data_pipeline.map_city_tier run_id=scheduled__2024-12-18T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:44:03,694 INFO - Executor reports execution of lead_scoring_data_pipeline.map_categorical_vars run_id=scheduled__2024-12-17T00:00:00+00:00 exited with status success for try_number 1
2025-02-22 11:44:03,702 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_categorical_vars, run_id=scheduled__2024-12-17T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:44:03.008729+00:00, run_end_date=2025-02-22 11:44:03.272795+00:00, run_duration=0.264066, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1233, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-02-22 11:43:55.117215+00:00, queued_by_job_id=7, pid=75234
2025-02-22 11:44:03,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=map_city_tier, run_id=scheduled__2024-12-18T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:44:00.821695+00:00, run_end_date=2025-02-22 11:44:01.069318+00:00, run_duration=0.247623, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1232, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-02-22 11:43:55.117215+00:00, queued_by_job_id=7, pid=75215
2025-02-22 11:44:03,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=load_data_into_db, run_id=scheduled__2024-12-19T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:58.608931+00:00, run_end_date=2025-02-22 11:43:58.899601+00:00, run_duration=0.29067, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1231, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-02-22 11:43:55.117215+00:00, queued_by_job_id=7, pid=75196
2025-02-22 11:44:03,703 INFO - TaskInstance Finished: dag_id=lead_scoring_data_pipeline, task_id=build_dbs, run_id=scheduled__2024-12-20T00:00:00+00:00, map_index=-1, run_start_date=2025-02-22 11:43:56.495637+00:00, run_end_date=2025-02-22 11:43:56.753661+00:00, run_duration=0.258024, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1230, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-02-22 11:43:55.117215+00:00, queued_by_job_id=7, pid=75177
2025-02-22 11:44:03,998 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-18T00:00:00+00:00, run_after=2024-12-19T00:00:00+00:00
2025-02-22 11:44:04,065 INFO - Marking run <DagRun lead_scoring_data_pipeline @ 2024-12-17 00:00:00+00:00: scheduled__2024-12-17T00:00:00+00:00, externally triggered: False> successful
2025-02-22 11:44:04,066 INFO - DagRun Finished: dag_id=lead_scoring_data_pipeline, execution_date=2024-12-17 00:00:00+00:00, run_id=scheduled__2024-12-17T00:00:00+00:00, run_start_date=2025-02-22 11:43:33.729950+00:00, run_end_date=2025-02-22 11:44:04.066263+00:00, run_duration=30.336313, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-17 00:00:00+00:00, data_interval_end=2024-12-18 00:00:00+00:00, dag_hash=28429f75d9b726b0b2bfda17f7b37588
2025-02-22 11:44:04,070 INFO - Setting next_dagrun for lead_scoring_data_pipeline to 2024-12-18T00:00:00+00:00, run_after=2024-12-19T00:00:00+00:00
2025-02-22 11:44:04,106 INFO - 3 tasks up for execution:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:44:04,106 INFO - DAG lead_scoring_data_pipeline has 0/16 running and queued tasks
2025-02-22 11:44:04,107 INFO - DAG lead_scoring_data_pipeline has 1/16 running and queued tasks
2025-02-22 11:44:04,107 INFO - DAG lead_scoring_data_pipeline has 2/16 running and queued tasks
2025-02-22 11:44:04,107 INFO - Setting the following tasks to queued state:
	<TaskInstance: lead_scoring_data_pipeline.load_data_into_db scheduled__2024-12-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_city_tier scheduled__2024-12-19T00:00:00+00:00 [scheduled]>
	<TaskInstance: lead_scoring_data_pipeline.map_categorical_vars scheduled__2024-12-18T00:00:00+00:00 [scheduled]>
2025-02-22 11:44:04,110 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='load_data_into_db', run_id='scheduled__2024-12-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-02-22 11:44:04,110 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:44:04,110 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_city_tier', run_id='scheduled__2024-12-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-02-22 11:44:04,111 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_city_tier', 'scheduled__2024-12-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:44:04,111 INFO - Sending TaskInstanceKey(dag_id='lead_scoring_data_pipeline', task_id='map_categorical_vars', run_id='scheduled__2024-12-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-02-22 11:44:04,111 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'map_categorical_vars', 'scheduled__2024-12-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
2025-02-22 11:44:04,131 INFO - Executing command: ['airflow', 'tasks', 'run', 'lead_scoring_data_pipeline', 'load_data_into_db', 'scheduled__2024-12-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/lead_scoring_data_pipeline.py']
